{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f8c346-4a0d-432d-be6c-097aa7ad6e24",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://gpt-index.readthedocs.io/en/latest/examples/index_structs/doc_summary/DocSummary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee32f39-21d7-4ca2-ae75-6ba7653edf66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91931b4-7676-4d8b-9ea0-f07303e8b5e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ To view the Phoenix app in your browser, visit http://127.0.0.1:6060/\n",
      "ðŸ“º To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "ðŸ“– For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe7b28b-9a30-46df-a13f-fb647c1b9b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from getpass import getpass\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from gcsfs import GCSFileSystem\n",
    "from llama_index import ServiceContext, StorageContext, load_index_from_storage, set_global_handler\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.graph_stores.simple import SimpleGraphStore\n",
    "from llama_index.llms import OpenAI\n",
    "from phoenix.experimental.evals import (\n",
    "    OpenAIModel,\n",
    "    compute_precisions_at_k,\n",
    "    run_relevance_eval,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a897b7-36fc-482c-8e50-709f0f1cf605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc11527c-04fe-467a-a7e3-9146ce73f65a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "060abc21-9542-4007-a663-96d2d7089385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1cd525-ac3e-4fbe-ad95-361626b3ce73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import json\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e9d4289-94e7-4235-9682-31de034bd515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc177fe4-347d-4405-a49c-831d85838fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "from llama_index.indices.document_summary import DocumentSummaryIndex\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feaf22a1-f8f7-4ba6-8742-ae56059fb8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_documents_from_transcription(json_file, chunk_sizes):\n",
    "    \"\"\"\n",
    "    Concatenates words from a given JSON data structure with maximum chunk sizes.\n",
    "\n",
    "    Parameters:\n",
    "        json_file (str): The path to the JSON file.\n",
    "        chunk_sizes (list of int): The list of maximum number of words allowed in each concatenated chunk.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of nodes. Each node contains concatenated text and metadata (start_time, end_time).\n",
    "\n",
    "    \"\"\"\n",
    "    def add_document_to_chunks(word_list, start_time, end_time, chunks,chunk_size):\n",
    "        \"\"\"Helper function to add a new Document to chunks.\"\"\"\n",
    "        text = \" \".join(word_list)\n",
    "        doc = Document(page_content=text, metadata={'start': start_time, \n",
    "                                              \"end\": end_time,\n",
    "                                             \"chunk_size\":chunk_size})\n",
    "        chunks.append(doc)\n",
    "\n",
    "    concatenated_chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "    current_start_time = None\n",
    "    current_end_time = None\n",
    "\n",
    "    # Load JSON data\n",
    "    with open(json_file, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # Initialize service context\n",
    "    llm = OpenAI(model=\"gpt-4\")\n",
    "    service_context = ServiceContext.from_defaults(llm=llm)\n",
    "    \n",
    "    if not isinstance(chunk_sizes, list):\n",
    "        chunk_sizes = [chunk_sizes]\n",
    "    for chunk_size in chunk_sizes:\n",
    "        for segment in json_data[\"segments\"]:\n",
    "            for word_info in segment[\"words\"]:\n",
    "                if current_word_count + 1 > chunk_size:\n",
    "                    add_document_to_chunks(current_chunk, current_start_time, current_end_time, concatenated_chunks, chunk_size)\n",
    "                    current_chunk = []\n",
    "                    current_word_count = 0\n",
    "                    current_start_time = None\n",
    "\n",
    "                current_chunk.append(word_info[\"word\"].strip())\n",
    "                current_word_count += 1\n",
    "\n",
    "                if current_start_time is None:\n",
    "                    current_start_time = word_info[\"start\"]\n",
    "                current_end_time = word_info[\"end\"]\n",
    "\n",
    "        if current_chunk:\n",
    "            add_document_to_chunks(current_chunk, current_start_time, current_end_time, concatenated_chunks, chunk_size)\n",
    "\n",
    "    return concatenated_chunks\n",
    "\n",
    "\n",
    "# Example usage\n",
    "chunk_sizes = [128, 256, 512, 1024]\n",
    "docs = get_documents_from_transcription(json_file=\"transcriptions/youtube_UyoXmHS-KGc.json\", chunk_sizes=chunk_sizes)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e089b3-65fe-404f-b39f-4e4309b460fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from llama_index import Document\n",
    "\n",
    "def load_json_file_and_extract_text(json_file_path):\n",
    "    \"\"\"Loads a JSON file and extracts the content of the \"text\" key.\n",
    "\n",
    "    Args:\n",
    "    json_file_path: The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    A list of Document objects, containing the extracted content of the \"text\" key.\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    with open(json_file_path, \"r\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        # return json_data\n",
    "        documents.append(Document(doc_id=json_file_path , text=json_data[\"text\"]))\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b440a4-ac13-4be4-8361-4bba96ce361c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf65dee-5b1d-43aa-b846-c96971d85c6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='transcriptions/youtube_5p248yoa3oE.json', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0', text=\" It is my pleasure to welcome Dr. Andrew Wu tonight. Andrew is the managing general partner of AI Fund, founder of Deep Learning AI, and learning and lending AI, chairman and co-founder of Coursera, and an adjunct professor of computer science here at Stanford. Previously he had started and led the Google Brain team, which had helped Google adopt modern AI, and he was also director of the Stanford AI lab. About 8 million people, one in 1,000 persons on the planet, have taken an AI class from him, and through both his education and his AI work, he has changed humor's lives. Please welcome Dr. Andrew Wu. Thank you Lisa, it's good to see everyone. So what I want to do today is chat to you about some opportunities in AI. So I've been saying AI is a new electricity. One of the difficult things to understand about AI is that it is a general purpose technology, meaning that it's not useful only for one thing, but it's useful for lots of different applications. Kind of like electricity. If I were to ask you what is electricity good for, you know, it's not any one thing, it's a lot of things. So what I'd like to do is start off sharing with you, high view the technology landscape, and just to lead into the set of opportunities. So a lot of hype, a lot of excitement about AI. And I think a good way to think about AI is as a collection of tools. So this includes a technique called supervised learning, which is very good at recognizing things or labeling things, and genitive AI, which is relatively new, exciting development. If you're familiar with AI, you may have heard of other tools, but I'm going to talk less about these additional tools and I'll focus today on what I think are currently the two most important tools which are supervised learning and genitive AI. So supervised learning is very good at labeling things or very good at computing input to outputs or A to B mappings given in B A, give me an output B. For example, given an email, we can use supervised learning to label a spam or not spam. The most lucrative application of this that I've ever worked on is probably online advertising, where I give it an ad, we can label the users likely to click on it and therefore show more relevant ads. For self-driving cars, given the sense of readings of a car, we can label it with where the other cars, one project that my team at AI and worked on was shift route optimization, where given a route to the ship is taking or considering taking, we can label that with how much fuel we think does to consume and uses the chips more fuel efficient. Still a lot of work in automated visual inspection in factories, so you can take a picture of a smartphone that was just manufactured and label is a scratch when you're defecting it. Or if you want to build a restaurant review reputation monitoring system, you can have little piece of software that looks at online restaurant reviews and labels that as positive or negative sentiment. So one nice thing, one cool thing about supervised learning is that it's not useful for one thing, it's useful for all of these different applications and many more besides. Let me just walk through concretely the workflow of one example of a supervised learning labeling things kind of project. If you want to build a system to label restaurant reviews, you then collect a few data points, a collective dataset, where it's say the best time you sandwich great, you say that is positive, several slow, there's negative, my favorite should be curry, there's positive. And here I've shown three data points, but you're building this, you may get thousands of data points like this, thousands of training examples, we call it. And the workflow of a machine learning project, when AI project is you get labeled data, maybe thousands of data points, then you have an AI entry team train an AI model to learn from this data. And then finally, you would find maybe a cloud service to run the trained AI model, and they can feed it, you know, let's both have a hat and that's positive sentiment. And so I think the last decade was maybe the decade of large scale supervised learning. What we found starting about 10, 15 years ago was if you were to train a small AI model, so train a small neural network, small deep learning algorithm, basically a small AI model, maybe not on a very powerful computer, then as you fed more data, as performance would get better for a little bit, but then it would flatten out, it would plateau, and it would stop being able to use the data to get better and better. But if you were to train a very large AI model, lots of compute on maybe powerful GPUs, then as we scaled up the amount of data we gave the machine learning model, its performance would kind of keep on getting better and better. So this is why when I started and led the Google Brain team, the primary mission that I directed the team to solve at the time was, let's just build really, really large neural networks that we then fed a lot of data to, and that recipe fortunately worked. And I think the idea of driving large compute and large scale of data, that recipes really helped us driven a lot of AI progress over the last decade. So if that was the last decade of AI, I think this decade is turning out to be also doing everything we had in supervised learning, but adding to it, the exciting two of Genes of AI. So many of you, maybe all of you, were played with charge GPD and bar and so on, but just you know, given a piece of text, which we call prompt, like I love eating, if you run this multiple times, maybe you get big old screen keys or my mother's me love or out of friends, and the AI system can generate output like that. Given the amounts of buzz and excitement about Genes of AI, I thought that'd take just half a slide to, you know, say a little bit about how this works. So it turns out that, Genes of AI, at least this type of text generation, the core of it is using supervised learning that inputs output mappings to repeatedly predict the next word. And so, if your system reads on the internet to sentence like, my favorite food is a bagel with cream cheese and locks, then this is translated into a few data points where if it sees my favorite food is a, in this case, try to guess that the right next word was bagel or my favorite food is a bagel, try to guess next word is worth. And similarly, if it sees that, you know, in this case, the right guess for the next word would have been cream. So by taking text that you find on the internet or other sources and by using this input output, supervised learning to try to repeatedly predict if you train a very large AI system on hundreds of billions of words, or in the case of the largest models, now more than a trillion words, then you get a large language model like chat GP. And, you know, there are additional other important technical details I talked about predicting the next word. Technically, these systems predict the next subword, a part of work called token, and then there are other techniques like RHS for further tuning the AI output to be more helpful on this and harmless. But at the heart of it is this using supervised learning to repeatedly predict the next word that that really was enabling the exciting, you know, really fantastic progress on large language models. So while many people have seen large language models as a fantastic consumer too, you can go to a website like chat GP's website or BODs or other large language models and use it. I think it's fantastic too. There's one of the trends I think is still underappreciated, which is the power of large language models, not as it can, not as it, not just as consumer too, but as it develop it too. So it turns out that there are applications that used to take me months to build that a lot of people can now build much faster by using a large language model. So specifically, the work though for supervised learning, building the restaurant review system would be that you need to get a bunch of label data and maybe that takes a month to get a few thousand data points. And then have an AI team train and tune and really get optimized performance on your AI model, maybe that'll take three months. Then find a cloud service to run it, make sure it's running robustly, make sure it's recognized, maybe that'll take another three months. So a pretty realistic timeline for building a commercial great machine learning system is like six to 12 months. So teams I've led will often talk roughly six to 12 months to build and deploy these systems and some of them turned out to be really valuable, but this is a realistic timeline for building and deploying a commercial great AI system. In contrast, with prompt-based AI, where you write a prompt, this is what the workflow looks like. You can specify a prompt that takes maybe minutes or hours and then you can deploy it to the cloud and that takes maybe hours or days. So there are now certain AI applications that used to take me literally six months, maybe a year to build that many teams around the world can now build in maybe a week. And I think this is already starting, but the best is still yet to come. This is starting to open up a flood of a lot more AI applications that can be built by a lot of people. So I think many people still underestimate the magnitude of the flood of custom AI applications that I think is going to come down the pipe. Now I know you probably were not expecting me to write code in this presentation, but that's what I'm going to do. So it turns out this is all the code I need in order to write a sentiment classifier. So I'm going to, you know, solve you with no Python, I guess, import some tools from OpenAI. And then I have this prompt that says, classified detects the low, delimited by three dashes, is having either a positive or negative sentiments. I don't know. I'm a fantastic time Stanford GSB. I ran to a lot and also made great new friends. So that's my prompt. And now just I run it. And I've never run it before. So I really hope thank goodness we got the right answer. And this is literally all the code that takes the build a sentiment classifier. And so today, you know, developers around the world can take literally maybe like 10 minutes to build a system like this. And that's a very exciting development. So one of the things I've been working on was trying to teach, you know, online classes about how to use prompting, not just as a consumer tool, but as a developer to. So start off with the technology landscape. Let me now share my thoughts on what are some of the AI opportunities I see. This shows what I think is the value of different AI technologies today. I don't talk about three years from now. But the vast majority of financial value from AI today is I think supervised learning where for a single company like Google can be worth more than $100 billion a year. And also there are millions of developers building supervised learning applications. So it's already massively valuable. And also with tremendous momentum behind it, just because of the sheer effort in, you know, finding applications and building applications. And in Genose of AI is the really exciting new entrance, which is much smaller right now. And then there are the other tools that I'm including for completeness. We can, the size of these circles represent the value today. This is what I think it might grow to in three years. So supervised learning already really massive may double, say in the next three years, from truly massive to even more massive. And Genose of AI, which is much smaller today, I think will much more than double in the next three years because of the number of amount of developer interest, the amount of venture capital investments, the number of large corporate exploring applications. And I also just want to point out three years is a very short time horizon. If it continues to compound anything near this rate, then in six years, you know, it'll be even faster larger. But just light shaded region in green or orange, that light shaded region is where the opportunities for either new startups or for large companies in companies to create and to enjoy value capture. But one thing I hope you take away from this slide is that all of these technologies are general purpose technologies. So in the case of supervised learning, a lot of the work that had to be done over the last decade, but it's continuing for the next decade, is to identify and to execute on the concrete use cases. And that process is also kicking off for Genose of AI. So for this part of the presentation, I hope you take away from it that general purpose technologies are useful for many different tasks. A lot of value remains to be created using supervised learning. And even though we're nowhere near finishing figure out the exciting use cases of supervised learning, where there's other fantastic two of Genose of AI, which further expands the set of things we can now do using AI. But one caveat, which is that there will be short term fads along the way. So I don't know if some of you might remember the app called Lenser. This is the app that will let you upload pictures of yourself and then render a cool picture of you as an astronaut or a scientist or something. And it was a good idea and people liked it. And Zeravius just took off like crazy like that through last December. And then it did that. And that's because Lenser was, it was a good idea. People liked it. But it was a relatively thin software layer on top of someone else's really powerful APIs. And so even though it was a useful product, it was in a defensive all-business. And when I, when I think about, you know, absolute Lenser, I'm actually reminded that when Steve Jobs gave us the iPhone, shortly after, someone wrote an app that I paid $1.199 for to do this, to turn on the LED, to turn the phone into flashlight. And that was also a good idea to write an app to turn on the LED light. But it also wasn't a defensible long term. It also didn't create very long term value because it was a easy replicated and underpriced and eventually incorporated into iOS. But with the rise of iOS, with the rise of iPhone, someone also figured out how to build things like Uber and Airbnb and Tinder, the very long term, very defensible businesses that created, you know, sustaining value. And I think with the rise of GENTAVI or the rise of new AI tools, I think what really, what excites me is the opportunity to create those really deep, really hard applications that hopefully can create very long term value. So the first trend I want to share is AI's general purpose technology and a lot of work that lies ahead of us is to find the very diverse use cases and to build them. There's a second trend I want to share with you, which relates to why AI is in more widely adopted yet. It feels like a bunch of us have been talking about AI for like 15 years or something. But if you look at where the value of AI is today, a lot of it is still very concentrated in consumer software internet. Once you go outside, you know, tech or consumer software internet, there's some air adoption but the law feels very early. So why is that? It turns out if you were to take all current and potential AI projects and sort them in decreasing order of value, then to the left of this curve, the head of this curve are the multi billion dollar projects like advertising or web search or for e-commerce, your product recommendations or company amazon. And it turns out that about 10, 15 years ago, you know, various of my friends and I, we figured out a recipe for how to hire say a hundred engineers to write one piece of software to serve more relevant ads and apply that one piece of software to bid end users and generate massive financial values. So that works. But once you go outside, consumer software internet, hardly anyone has a hundred million or a billion users that you can write and apply one piece of software to you. So once you go to other industries, as we go from the head of this curve on the left over to the long tail, these are some of the projects I see and I'm excited about. I was working with a piece of maker that was taking pictures of the pizza they were making because they needed to do things like make sure that the cheese is spread evenly. So this is about a five million dollar project. But that recipe of hiring a hundred engineers or dozens of engineers to work on a five million dollar project, that doesn't make sense. Or another very example, working with an agricultural company that, well, then we figured out that we used cameras to find out how tall is the wheat and wheat is often bento because of the wind or rain or something. And we can chop off the wheat at the right height. Then that results in more food for the farmer to sell and is also better for the environment. But this is another five million dollar project that that old recipe of having a large group of high school engineers to work on this one project that doesn't make sense. And similarly materials grading, cloth grading, sheet metal grading, many project like this. So whereas to the left in the head of this curve, there's a small number of, let's say, multi-billion dollar projects. And we know how to execute those, you know, still ring value. In other industries, I'm seeing a very long tail of tens of thousands of, let's call them five million dollar projects that until now have been very difficult to execute on because of the high cost of customization. The trend that I think is exciting is that the AI community has been building better tools that lets us aggregate these use cases and make it easy for the end user to do the customization. So specifically, I'm seeing a lot of exciting low code and no code tools that enable the user to customize the AI system. What does mean is this instead of me needing to worry that much about pictures of pizza, we have tools, we can start into C tools that can enable the IT department of the pizza making factory to train AI system on their own pictures of pizza to realize this five million dollars worth of value. And by the way, the pictures of pizza, you know, they don't exist on the internet. So Google and Bing don't have access to these pictures. We need tools that can be used by really the pizza factory themselves to build and deploy and maintain their own custom AI system that works on their own pictures of pizza. And broadly, the technology for enabling this, some of it is prompting, text prompting, visual prompting, but really large language models and similar tools like that. Or a technology called data centric AI whereby instead of asking the pizza factory to write a lot of code, you know, which is challenging, we can ask them to provide data which turns out to be more feasible. And I think the second trend is important because I think this is a key part of the recipe for taking the value of AI, which so far still feels very concentrated in the tech world and consume the software into that world and pushing this out to, you know, all industries really to the rest of the economy, which, you know, sometimes it's easy to forget. The rest of the economy is much bigger than the tech world. So, the two trends I shared, AI is a general purpose technology, lots of concrete use cases to be realized as well as local, no code, easy to use tools, enabling AI to be deployed in more industries. How do we go after these opportunities? So, about five years ago, there was a puzzle I wanted to solve, which is I felt that many valuable AI projects are now possible. I was thinking how do we get them done? And having led AI teams in, you know, Google and buy do in big tech companies, I had a hard time figuring out how I could operate a team in a big tech company to go off. There are a very diverse set of opportunities and everything from maritime shipping to education to financial services to healthcare and all and all. It's just very diverse use cases, very diverse, go to markets, very diverse, really, you know, customer bases and applications. And I felt that the most efficient way to do this would be we can start a lot of different companies to pursue these very diverse opportunities. So, that's why I ended up starting AI fun, which is a venture studio that built startups to pursue a diverse set of AI opportunities. And of course, in addition to lots of startups in company companies, also have a scene for incumbent businesses is distribution is often one of the cyclical advantages of incumbent companies that they play the cards right can allow them to integrate AI into into their products quite efficiently. But just to be concrete, where are the opportunities? So, I think of this as a, this is what I think of as the AI stack. At the bottom level is the hardware semiconductor layer. Fantastic opportunities there, but very capital intensive, very concentrated. So, these are a lot resources, relatively few winners. So, some people can and should play there. I personally don't like to play them myself. There's also the infrastructure layer. Also, fantastic opportunities, but very capital intensive, very concentrated. So, I tend not to play them myself either. And then there's a developer tool layer. What I showed you just now was I was actually using OpenAI's API as a developer tool. And then I think the developer tool sector is a hyper competitive. Look at all the startups chasing OpenAI right now. But there will be some mega winners. And so I sometimes play here, but primarily when I think of a meaningful technology advantage, because I think that earns you the right or earns you a better shot at being one of the mega winners. And then lastly, even though a lot of the media attention in the buzz is in the infrastructure and developer tooling layer, it turns out that that layer can be successful only if the application layer is even more successful. And we saw this with the rise of SaaS as well. A lot of the buzz excitement is on the technology, the tooling layer, which is fine, nothing wrong with that. But the only way for that to be successful is that the application layer is even more successful so that frankly, they can generate enough revenue to pay the infrastructure and the tooling layer. So actually, let me mention one example. ArmorRy is actually just texting the CEO yesterday, but ArmorRy is a complete rebuild that uses AI for romantic relationship coaching. And just to point out I'm an AI guy and I feel like I know nothing really about romance. And if you don't believe me, you can ask my wife, she will confirm that I know nothing about romance. But when we want to build this, we want to get together with the former CEO of Tinder, a Renata Nibble, and with my team's expertise in AI and her expertise in relationships. She ran Tinder. She knows more about relationships. I think anyone I know, we're able to build something pretty unique using AI for romantic relationship mentoring. And the interesting thing about applications like these is when we look around, how many teams in the world are simultaneously expert in AI and in relationships. And so at the application layer, I'm seeing a lot of exciting opportunities that seem to the very large market, but where the competition set is very light relative to the magnitude of the opportunity. It's not that there are no competitors, but it's just much less intense compared to the developer tool or the infrastructure layer. And so because I've spent a lot of time iterating on a process of building startups, what I'm going to do is just very transparently tell you the recipe we've developed for building startups. And so after many years of iteration and improvement, this is how we now build startups. My team's always had access to a lot of different ideas, internally generated ideas from partners. And I want to walk through this with one example of something we did, which is a company bearing AI, which uses AI to make ships more fuel efficient. So this idea came to me when a few years ago, a large Japanese conglomerate called Mitsui, that is a major shareholder in the sort of operator major shipping lines. They came to me and they said, hey, Andrew, you should build a business to use AI to make ships more fuel efficient. And the specific idea was, think of it as a Google Maps for ships. We can suggest a ship or tell a ship how to steer so that you still get to your destination on time, but using turns out about 10% less fuel. And so what we now do is we spend about a month validating the idea. So double check, this is idea even technically feasible and in top to perspective customers to make sure that it's marketing. So it's been up to about a month doing that. And if it passes this stage, then we will go and recruit a CEO to work with us on the project. When I was starting, I used to spend a long time working on the project myself before bringing on the CEO, but after iterating, we realized that bringing on the leader at the very beginning to work with us, it reduces the burden of having to transfer knowledge or having a CEO come in and have to revalidate whether we discover it. So the process is we've learned much more efficient, which is bringing the leader at the very start. And so in the case of bearing AI, we found a fantastic CEO, Dylan Kyle, who's repeat entrepreneur, one successful ex-report for. And then we spent three months, six two weeks sprints to work with them to build a prototype as well as do do deep customer validation. If it survives this stage and we have about a two thirds, 66 percent survival rate, we never had the first check in, which then gives the company resources to hire an executive team, you know, build the key team, get the MVP working, minimize our product working, and get some real customers. And then after that, you know, hopefully then successfully raises additional external rounds of funding that can keep on growing and scaling. So I'm really proud of the work that my team was able to do to support Mitsui's idea and Dylan Kyle as CEO. And today there are hundreds of ships on the high seas right now that are steering themselves differently because of bearing AI. And 10 percent fuel savings translates to rough order amounts to maybe $450,000 in savings in fuel per year. And of course, it's also frankly quite a bit better for the environment. And I think this is not up, I think would not have existed if not for Dylan's fantastic work. And then also, you know, Mitsui brainless idea to me. And I like this example because this is another one is like, you know, this is a thought of idea that just a point out I would never have come up with myself, right? Because, you know, I've been on a boat, but what do I know about maritime shipping? But is the deep subject matter expertise of Mitsui that had to zenzai together with Dylan and then my team's expertise in AI that made this possible? And so as I operate an AI, one thing I've learned is my swim lane is AI. And that's it because I don't have time. It's very difficult for me to be expert in maritime shipping and romantic relationships and healthcare and financial services and on and on and on and on. Actra technical validation and then use, you know, AI resources to make sure the AI tech has built quickly. Well, and I think we've always managed to help the companies build a strong technical team than partnering with subject matter experts often results in exciting new opportunities. And I want to share with you one other weird aspect of one of the weird lessons I've learned about, you know, building startups, which is I like to engage only when there's a concrete idea. And this runs counter to bother the advice you hear from the design thinking methodology, which often says don't rush to solutioning, right? Explore a lot of alternatives to avoid the solution. Honestly, we tried that. It was very slow. But what we've learned is that at the ideation stage, if someone comes to me and says, hey, Andrew, you should apply AI to financial services. Because I'm not a subject matter expert in financial services, it's very slow for me to learn enough about financial services that you can figure out what to do. I mean, eventually, you could get a good outcome, but it's a very labor intensive, very slow, very expensive process. So me to try to learn industry after industry. In contrast, one of my partners wrote his ideas that Tony Cheat, not really seriously, but you know, let's say the concrete idea is by GBT, let's eliminate commercials by automatically buying every product advertised in exchange for not having seen ads. It's not a good idea, but it is a concrete idea. And it turns out concrete ideas can be validated or falsified efficiently. They also give a team a clear direction to execute. And I've learned it in today's world, especially with the excitement and buzz and exposure to the AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world that have deeply thought about a problem for months, sometimes even one or two years, but they've not yet had a build partner. And when we get together with them and hear and they share the idea of us, it allows us to work with them to very quickly go into validation and building. And I find that this works because there are a lot of people that have already done the design thinking thing of exploring a lot of ideas and winning down to really good ideas. And there are, I find that there's so many good ideas sitting out there that no one is working on that finding those good ideas that someone has already had and wants to share of us and wants to build partner for that turns out to be much more efficient engine. So, before I wrap up, we'll go to the question second. Just a few slides to talk about risks and social impact. So, AI is a very powerful technology to state something you probably guess. My team's and I, we only work on projects that move humanity forward. And we have multiple times, killed projects that we assess that we financially sound based on ethical grounds. It turns out I've been surprising. Sometimes this made at the creativity of people to come up with good ideas, sorry to come up with really bad ideas that seem profitable, but really should not be built with a few projects on those grounds. And then I think it has to acknowledge that AI today does have problems with bias, fairness, accuracy, but also, you know, technology is improving quickly. So, I see that AI systems today less bias than six months ago and more fair than six months ago, which is not to dismiss the importance of these problems. They are problems and we should continue to work on them. But I'm also gratified at the number of AI tears working hard on these issues to make them much better. When I think of the biggest risk of AI, I think that the biggest risk, one of the biggest risk is the disruption to jobs. This is a diagram from a paper by our friend at the University of Pennsylvania and some folks at OpenAI, analyzing the exposure of different jobs to AI automation. And it turns out that whereas the previous wave of automation mainly the most exposed jobs were often the lower-wage jobs, such as when we put robots into factories. With this current wave of automation is actually the higher-wage jobs further the right of this axis that seems to have more of their tasks exposed to AI automation. So, even as we create tremendous value using AI, I feel like as citizens and our corporations and the governments and really our society, I feel a strong obligation to make sure that people, especially people who are lively, who are disrupted, are still well taken care of, are still treated well. And then lastly, it feels like every time there's a big wave of progress in AI, there's a big wave of hype about artificial gender intelligence as well. When deep learning started to work really well 10 years ago, there was a lot of hype about AI and now the gender of AI is working really well. There's another wave of hype about AI. But I think that artificial gender intelligence, AI didn't do anything human can do, it still decades away, maybe 30 to 50 years, maybe even longer. I hope we'll see in our lifetimes. But I don't think there's any time soon. One of the challenges is that the biological path to intelligence, like humans and the digital path to intelligence, AI, they've taken very different paths. And the funny thing about the definition of AI is benchmarking this very different digital path to intelligence with really the biological path to intelligence. So I think, you know, Russian-Gashmoldos are smarter than any of us in certain key dimensions, but much dumber than any of us in other dimensions. And so forcing it to do everything a human can do is like a funny comparison. But I hope we'll get there, maybe hopefully within a lifetimes. And then there's also a lot of, I think, overblown hype about AI creating extinction risk for humanity. Candidly, I don't see it. I just don't see how AI creates any meaningful extinction risk for humanity. I think that people worry we can't control AI, but we have lots of AI will be more powerful than any person. But we've lots of experience steering very powerful entities such as corporations or nation states that are far more powerful than any single person and making sure they for the most part benefit humanity. And also technology develops gradually. The so-called hot takeoff scenario, where it's not really working today, and then suddenly one day overnight, it works brilliantly with Chief Super Intelligence takes over the world. That's just not realistic. And I think AI technology will develop slowly, like all the technology, and then it gives us plenty of time to make sure that we provide oversight and can manage it to be safe. And lastly, if you look at the real extinction risk of humanity, such as fingers crossed an ex-pandemic or climate change leading to a massive depopulation of some parts of the planet, or much lower odds that maybe someday, and as there are doing to us, whether they're done to the dinosaurs, I think we look at the actual real extinction risk to humanity. AI, having more intelligence, even artificial intelligence in the world, would be a key part of the solution. So I feel like if you want humanity to survive and thrive for the next thousand years, rather than slowing AI down, which some people propose, I would rather make AI go as fast as possible. So with that, just to summarize, this is my last slide. I think that AI, as a general purpose technology, creates a lot of new opportunities for everyone, and a lot of the exciting and important work that lies ahead of us all is to go and build those concrete use cases. And hopefully in the future, hopefully I have opportunities to maybe engage with more of you on those opportunities as well. So that, let me just say thank you all very much.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = load_json_file_and_extract_text(\"transcriptions/youtube_5p248yoa3oE.json\")\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c8064-ac09-437f-a1e1-e3e8817e9e63",
   "metadata": {},
   "source": [
    "# Build Document Summary Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e5f1615-0d7f-453b-adfc-cc79ef97949d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM (gpt-3.5-turbo)\n",
    "chatgpt = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=chatgpt, chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "410fb8f8-24e3-475a-b0f2-8ba98b9f8c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363229a7fdbb4ee8ba27db627356899a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab417e5353ce4a0a91c2ec901322cfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: transcriptions/youtube_5p248yoa3oE.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c7598af3be4e8694eced4d7756c435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default mode of building the index\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "    docs,\n",
    "    service_context=service_context,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    show_progress=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a5b6a1-a8f5-4259-8389-6f6535295cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retreiver = doc_summary_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e8fe550-a65b-4cc6-a1a6-2f94c74cc714",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text is about various aspects of artificial intelligence (AI) and its impact on society. It discusses the current state and future potential of AI technology in various industries, the challenges of applying AI outside of the tech and consumer software internet sectors, and the importance of addressing bias and ethical considerations in AI systems. The text also touches upon the potential disruption to jobs caused by AI automation and the need to ensure that people affected by job displacement are well taken care of. It mentions the hype surrounding artificial general intelligence (AGI) and the challenges in achieving human-like intelligence in AI. The text also highlights the potential benefits of AI in addressing real extinction risks to humanity, such as pandemics or climate change.\n",
      "\n",
      "Some questions that this text can answer include:\n",
      "- What are the challenges of applying AI outside of the tech and consumer software internet sectors?\n",
      "- What progress has been made in reducing bias and increasing fairness in AI systems?\n",
      "- How does the author view the timeline for achieving artificial general intelligence?\n",
      "- What are the author's thoughts on the risks and benefits of AI for humanity?\n",
      "- What is the author's perspective on the role of AI in addressing real extinction risks?\n"
     ]
    }
   ],
   "source": [
    "print(doc_summary_index.get_document_summary(doc_id='transcriptions/youtube_5p248yoa3oE.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feca0042-e4f0-45bb-b649-ad43c1541d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_summary_index.storage_context.persist(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b476141-be40-4b13-8053-06b12bb66468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.loading import load_index_from_storage\n",
    "from llama_index import StorageContext\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"index\")\n",
    "doc_summary_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdccf19f-d25f-4b72-a991-4fce41a250c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The author acknowledges the risks associated with AI, particularly in terms of job disruption. They express a strong obligation to ensure that people who are affected by AI automation are well taken care of. However, the author does not see AI as a meaningful extinction risk for humanity and believes that with proper oversight, AI can be managed to be safe. They also highlight the potential benefits of AI, stating that it creates new opportunities for everyone and can be a key part of the solution to real extinction risks such as pandemics or climate change. Overall, the author sees AI as a general-purpose technology that has the potential to bring value and opportunities, but also recognizes the importance of addressing the challenges it presents.', source_nodes=[NodeWithScore(node=TextNode(id_='4c2ae659-5a8d-42fa-a6bd-5a7f46174978', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3fceb361-645a-46c0-851e-5aa942da0755', node_type=None, metadata={}, hash='a4482efccdcd88092b62d98ecd785ef5644b36e7273c301fdc3aabaa4a33440d')}, hash='c54d89aa394b5642a2fa6516d099aa189788091c6e3718261d6df7941816e2dc', text=\"It is my pleasure to welcome Dr. Andrew Wu tonight. Andrew is the managing general partner of AI Fund, founder of Deep Learning AI, and learning and lending AI, chairman and co-founder of Coursera, and an adjunct professor of computer science here at Stanford. Previously he had started and led the Google Brain team, which had helped Google adopt modern AI, and he was also director of the Stanford AI lab. About 8 million people, one in 1,000 persons on the planet, have taken an AI class from him, and through both his education and his AI work, he has changed humor's lives. Please welcome Dr. Andrew Wu. Thank you Lisa, it's good to see everyone. So what I want to do today is chat to you about some opportunities in AI. So I've been saying AI is a new electricity. One of the difficult things to understand about AI is that it is a general purpose technology, meaning that it's not useful only for one thing, but it's useful for lots of different applications. Kind of like electricity. If I were to ask you what is electricity good for, you know, it's not any one thing, it's a lot of things. So what I'd like to do is start off sharing with you, high view the technology landscape, and just to lead into the set of opportunities. So a lot of hype, a lot of excitement about AI. And I think a good way to think about AI is as a collection of tools. So this includes a technique called supervised learning, which is very good at recognizing things or labeling things, and genitive AI, which is relatively new, exciting development. If you're familiar with AI, you may have heard of other tools, but I'm going to talk less about these additional tools and I'll focus today on what I think are currently the two most important tools which are supervised learning and genitive AI. So supervised learning is very good at labeling things or very good at computing input to outputs or A to B mappings given in B A, give me an output B. For example, given an email, we can use supervised learning to label a spam or not spam. The most lucrative application of this that I've ever worked on is probably online advertising, where I give it an ad, we can label the users likely to click on it and therefore show more relevant ads. For self-driving cars, given the sense of readings of a car, we can label it with where the other cars, one project that my team at AI and worked on was shift route optimization, where given a route to the ship is taking or considering taking, we can label that with how much fuel we think does to consume and uses the chips more fuel efficient. Still a lot of work in automated visual inspection in factories, so you can take a picture of a smartphone that was just manufactured and label is a scratch when you're defecting it. Or if you want to build a restaurant review reputation monitoring system, you can have little piece of software that looks at online restaurant reviews and labels that as positive or negative sentiment. So one nice thing, one cool thing about supervised learning is that it's not useful for one thing, it's useful for all of these different applications and many more besides. Let me just walk through concretely the workflow of one example of a supervised learning labeling things kind of project. If you want to build a system to label restaurant reviews, you then collect a few data points, a collective dataset, where it's say the best time you sandwich great, you say that is positive, several slow, there's negative, my favorite should be curry, there's positive. And here I've shown three data points, but you're building this, you may get thousands of data points like this, thousands of training examples, we call it. And the workflow of a machine learning project, when AI project is you get labeled data, maybe thousands of data points, then you have an AI entry team train an AI model to learn from this data. And then finally, you would find maybe a cloud service to run the trained AI model, and they can feed it, you know, let's both have a hat and that's positive sentiment. And so I think the last decade was maybe the decade of large scale supervised learning. What we found starting about 10, 15 years ago was if you were to train a small AI model, so train a small neural network, small deep learning algorithm, basically a small AI model, maybe not on a very powerful computer, then as you fed more data, as performance would get better for a little bit, but then it would flatten out, it would plateau, and it would stop being able to use the data to get better and better.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='3fceb361-645a-46c0-851e-5aa942da0755', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4c2ae659-5a8d-42fa-a6bd-5a7f46174978', node_type=None, metadata={}, hash='c54d89aa394b5642a2fa6516d099aa189788091c6e3718261d6df7941816e2dc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c0450cf0-0592-42a6-baa3-73e654fe5eab', node_type=None, metadata={}, hash='f258653c4b073e9b9b8005ee5572385962e5b1bdb0c8e52acdc9cd9f7cd84449')}, hash='a4482efccdcd88092b62d98ecd785ef5644b36e7273c301fdc3aabaa4a33440d', text=\"But if you were to train a very large AI model, lots of compute on maybe powerful GPUs, then as we scaled up the amount of data we gave the machine learning model, its performance would kind of keep on getting better and better. So this is why when I started and led the Google Brain team, the primary mission that I directed the team to solve at the time was, let's just build really, really large neural networks that we then fed a lot of data to, and that recipe fortunately worked. And I think the idea of driving large compute and large scale of data, that recipes really helped us driven a lot of AI progress over the last decade. So if that was the last decade of AI, I think this decade is turning out to be also doing everything we had in supervised learning, but adding to it, the exciting two of Genes of AI. So many of you, maybe all of you, were played with charge GPD and bar and so on, but just you know, given a piece of text, which we call prompt, like I love eating, if you run this multiple times, maybe you get big old screen keys or my mother's me love or out of friends, and the AI system can generate output like that. Given the amounts of buzz and excitement about Genes of AI, I thought that'd take just half a slide to, you know, say a little bit about how this works. So it turns out that, Genes of AI, at least this type of text generation, the core of it is using supervised learning that inputs output mappings to repeatedly predict the next word. And so, if your system reads on the internet to sentence like, my favorite food is a bagel with cream cheese and locks, then this is translated into a few data points where if it sees my favorite food is a, in this case, try to guess that the right next word was bagel or my favorite food is a bagel, try to guess next word is worth. And similarly, if it sees that, you know, in this case, the right guess for the next word would have been cream. So by taking text that you find on the internet or other sources and by using this input output, supervised learning to try to repeatedly predict if you train a very large AI system on hundreds of billions of words, or in the case of the largest models, now more than a trillion words, then you get a large language model like chat GP. And, you know, there are additional other important technical details I talked about predicting the next word. Technically, these systems predict the next subword, a part of work called token, and then there are other techniques like RHS for further tuning the AI output to be more helpful on this and harmless. But at the heart of it is this using supervised learning to repeatedly predict the next word that that really was enabling the exciting, you know, really fantastic progress on large language models. So while many people have seen large language models as a fantastic consumer too, you can go to a website like chat GP's website or BODs or other large language models and use it. I think it's fantastic too. There's one of the trends I think is still underappreciated, which is the power of large language models, not as it can, not as it, not just as consumer too, but as it develop it too. So it turns out that there are applications that used to take me months to build that a lot of people can now build much faster by using a large language model. So specifically, the work though for supervised learning, building the restaurant review system would be that you need to get a bunch of label data and maybe that takes a month to get a few thousand data points. And then have an AI team train and tune and really get optimized performance on your AI model, maybe that'll take three months. Then find a cloud service to run it, make sure it's running robustly, make sure it's recognized, maybe that'll take another three months. So a pretty realistic timeline for building a commercial great machine learning system is like six to 12 months. So teams I've led will often talk roughly six to 12 months to build and deploy these systems and some of them turned out to be really valuable, but this is a realistic timeline for building and deploying a commercial great AI system. In contrast, with prompt-based AI, where you write a prompt, this is what the workflow looks like. You can specify a prompt that takes maybe minutes or hours and then you can deploy it to the cloud and that takes maybe hours or days. So there are now certain AI applications that used to take me literally six months, maybe a year to build that many teams around the world can now build in maybe a week. And I think this is already starting, but the best is still yet to come.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='c0450cf0-0592-42a6-baa3-73e654fe5eab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3fceb361-645a-46c0-851e-5aa942da0755', node_type=None, metadata={}, hash='a4482efccdcd88092b62d98ecd785ef5644b36e7273c301fdc3aabaa4a33440d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b7563833-e519-4296-aa25-088dcdd6a281', node_type=None, metadata={}, hash='d2b14be042adc5cfa30812c120b5ffa22571307ab95253e473cf4eb5fbf55446')}, hash='f258653c4b073e9b9b8005ee5572385962e5b1bdb0c8e52acdc9cd9f7cd84449', text=\"And I think this is already starting, but the best is still yet to come. This is starting to open up a flood of a lot more AI applications that can be built by a lot of people. So I think many people still underestimate the magnitude of the flood of custom AI applications that I think is going to come down the pipe. Now I know you probably were not expecting me to write code in this presentation, but that's what I'm going to do. So it turns out this is all the code I need in order to write a sentiment classifier. So I'm going to, you know, solve you with no Python, I guess, import some tools from OpenAI. And then I have this prompt that says, classified detects the low, delimited by three dashes, is having either a positive or negative sentiments. I don't know. I'm a fantastic time Stanford GSB. I ran to a lot and also made great new friends. So that's my prompt. And now just I run it. And I've never run it before. So I really hope thank goodness we got the right answer. And this is literally all the code that takes the build a sentiment classifier. And so today, you know, developers around the world can take literally maybe like 10 minutes to build a system like this. And that's a very exciting development. So one of the things I've been working on was trying to teach, you know, online classes about how to use prompting, not just as a consumer tool, but as a developer to. So start off with the technology landscape. Let me now share my thoughts on what are some of the AI opportunities I see. This shows what I think is the value of different AI technologies today. I don't talk about three years from now. But the vast majority of financial value from AI today is I think supervised learning where for a single company like Google can be worth more than $100 billion a year. And also there are millions of developers building supervised learning applications. So it's already massively valuable. And also with tremendous momentum behind it, just because of the sheer effort in, you know, finding applications and building applications. And in Genose of AI is the really exciting new entrance, which is much smaller right now. And then there are the other tools that I'm including for completeness. We can, the size of these circles represent the value today. This is what I think it might grow to in three years. So supervised learning already really massive may double, say in the next three years, from truly massive to even more massive. And Genose of AI, which is much smaller today, I think will much more than double in the next three years because of the number of amount of developer interest, the amount of venture capital investments, the number of large corporate exploring applications. And I also just want to point out three years is a very short time horizon. If it continues to compound anything near this rate, then in six years, you know, it'll be even faster larger. But just light shaded region in green or orange, that light shaded region is where the opportunities for either new startups or for large companies in companies to create and to enjoy value capture. But one thing I hope you take away from this slide is that all of these technologies are general purpose technologies. So in the case of supervised learning, a lot of the work that had to be done over the last decade, but it's continuing for the next decade, is to identify and to execute on the concrete use cases. And that process is also kicking off for Genose of AI. So for this part of the presentation, I hope you take away from it that general purpose technologies are useful for many different tasks. A lot of value remains to be created using supervised learning. And even though we're nowhere near finishing figure out the exciting use cases of supervised learning, where there's other fantastic two of Genose of AI, which further expands the set of things we can now do using AI. But one caveat, which is that there will be short term fads along the way. So I don't know if some of you might remember the app called Lenser. This is the app that will let you upload pictures of yourself and then render a cool picture of you as an astronaut or a scientist or something. And it was a good idea and people liked it. And Zeravius just took off like crazy like that through last December. And then it did that. And that's because Lenser was, it was a good idea. People liked it. But it was a relatively thin software layer on top of someone else's really powerful APIs. And so even though it was a useful product, it was in a defensive all-business.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='b7563833-e519-4296-aa25-088dcdd6a281', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c0450cf0-0592-42a6-baa3-73e654fe5eab', node_type=None, metadata={}, hash='f258653c4b073e9b9b8005ee5572385962e5b1bdb0c8e52acdc9cd9f7cd84449'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3f18f43f-a618-4ba3-8d24-454a9b6e4eb7', node_type=None, metadata={}, hash='60a19cf2f3f40cb3e3e3da0b504b02a7589b57ff3242ec8c93883f8cc407ab39')}, hash='d2b14be042adc5cfa30812c120b5ffa22571307ab95253e473cf4eb5fbf55446', text=\"And so even though it was a useful product, it was in a defensive all-business. And when I, when I think about, you know, absolute Lenser, I'm actually reminded that when Steve Jobs gave us the iPhone, shortly after, someone wrote an app that I paid $1.199 for to do this, to turn on the LED, to turn the phone into flashlight. And that was also a good idea to write an app to turn on the LED light. But it also wasn't a defensible long term. It also didn't create very long term value because it was a easy replicated and underpriced and eventually incorporated into iOS. But with the rise of iOS, with the rise of iPhone, someone also figured out how to build things like Uber and Airbnb and Tinder, the very long term, very defensible businesses that created, you know, sustaining value. And I think with the rise of GENTAVI or the rise of new AI tools, I think what really, what excites me is the opportunity to create those really deep, really hard applications that hopefully can create very long term value. So the first trend I want to share is AI's general purpose technology and a lot of work that lies ahead of us is to find the very diverse use cases and to build them. There's a second trend I want to share with you, which relates to why AI is in more widely adopted yet. It feels like a bunch of us have been talking about AI for like 15 years or something. But if you look at where the value of AI is today, a lot of it is still very concentrated in consumer software internet. Once you go outside, you know, tech or consumer software internet, there's some air adoption but the law feels very early. So why is that? It turns out if you were to take all current and potential AI projects and sort them in decreasing order of value, then to the left of this curve, the head of this curve are the multi billion dollar projects like advertising or web search or for e-commerce, your product recommendations or company amazon. And it turns out that about 10, 15 years ago, you know, various of my friends and I, we figured out a recipe for how to hire say a hundred engineers to write one piece of software to serve more relevant ads and apply that one piece of software to bid end users and generate massive financial values. So that works. But once you go outside, consumer software internet, hardly anyone has a hundred million or a billion users that you can write and apply one piece of software to you. So once you go to other industries, as we go from the head of this curve on the left over to the long tail, these are some of the projects I see and I'm excited about. I was working with a piece of maker that was taking pictures of the pizza they were making because they needed to do things like make sure that the cheese is spread evenly. So this is about a five million dollar project. But that recipe of hiring a hundred engineers or dozens of engineers to work on a five million dollar project, that doesn't make sense. Or another very example, working with an agricultural company that, well, then we figured out that we used cameras to find out how tall is the wheat and wheat is often bento because of the wind or rain or something. And we can chop off the wheat at the right height. Then that results in more food for the farmer to sell and is also better for the environment. But this is another five million dollar project that that old recipe of having a large group of high school engineers to work on this one project that doesn't make sense. And similarly materials grading, cloth grading, sheet metal grading, many project like this. So whereas to the left in the head of this curve, there's a small number of, let's say, multi-billion dollar projects. And we know how to execute those, you know, still ring value. In other industries, I'm seeing a very long tail of tens of thousands of, let's call them five million dollar projects that until now have been very difficult to execute on because of the high cost of customization. The trend that I think is exciting is that the AI community has been building better tools that lets us aggregate these use cases and make it easy for the end user to do the customization. So specifically, I'm seeing a lot of exciting low code and no code tools that enable the user to customize the AI system. What does mean is this instead of me needing to worry that much about pictures of pizza, we have tools, we can start into C tools that can enable the IT department of the pizza making factory to train AI system on their own pictures of pizza to realize this five million dollars worth of value.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='3f18f43f-a618-4ba3-8d24-454a9b6e4eb7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b7563833-e519-4296-aa25-088dcdd6a281', node_type=None, metadata={}, hash='d2b14be042adc5cfa30812c120b5ffa22571307ab95253e473cf4eb5fbf55446'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='42caeb58-5c83-41a3-9441-52ac7c5fbaa9', node_type=None, metadata={}, hash='e21b65841ae36cee11815aab0d469735c0ae2df7173fbedd758c58c318dfd421')}, hash='60a19cf2f3f40cb3e3e3da0b504b02a7589b57ff3242ec8c93883f8cc407ab39', text=\"And by the way, the pictures of pizza, you know, they don't exist on the internet. So Google and Bing don't have access to these pictures. We need tools that can be used by really the pizza factory themselves to build and deploy and maintain their own custom AI system that works on their own pictures of pizza. And broadly, the technology for enabling this, some of it is prompting, text prompting, visual prompting, but really large language models and similar tools like that. Or a technology called data centric AI whereby instead of asking the pizza factory to write a lot of code, you know, which is challenging, we can ask them to provide data which turns out to be more feasible. And I think the second trend is important because I think this is a key part of the recipe for taking the value of AI, which so far still feels very concentrated in the tech world and consume the software into that world and pushing this out to, you know, all industries really to the rest of the economy, which, you know, sometimes it's easy to forget. The rest of the economy is much bigger than the tech world. So, the two trends I shared, AI is a general purpose technology, lots of concrete use cases to be realized as well as local, no code, easy to use tools, enabling AI to be deployed in more industries. How do we go after these opportunities? So, about five years ago, there was a puzzle I wanted to solve, which is I felt that many valuable AI projects are now possible. I was thinking how do we get them done? And having led AI teams in, you know, Google and buy do in big tech companies, I had a hard time figuring out how I could operate a team in a big tech company to go off. There are a very diverse set of opportunities and everything from maritime shipping to education to financial services to healthcare and all and all. It's just very diverse use cases, very diverse, go to markets, very diverse, really, you know, customer bases and applications. And I felt that the most efficient way to do this would be we can start a lot of different companies to pursue these very diverse opportunities. So, that's why I ended up starting AI fun, which is a venture studio that built startups to pursue a diverse set of AI opportunities. And of course, in addition to lots of startups in company companies, also have a scene for incumbent businesses is distribution is often one of the cyclical advantages of incumbent companies that they play the cards right can allow them to integrate AI into into their products quite efficiently. But just to be concrete, where are the opportunities? So, I think of this as a, this is what I think of as the AI stack. At the bottom level is the hardware semiconductor layer. Fantastic opportunities there, but very capital intensive, very concentrated. So, these are a lot resources, relatively few winners. So, some people can and should play there. I personally don't like to play them myself. There's also the infrastructure layer. Also, fantastic opportunities, but very capital intensive, very concentrated. So, I tend not to play them myself either. And then there's a developer tool layer. What I showed you just now was I was actually using OpenAI's API as a developer tool. And then I think the developer tool sector is a hyper competitive. Look at all the startups chasing OpenAI right now. But there will be some mega winners. And so I sometimes play here, but primarily when I think of a meaningful technology advantage, because I think that earns you the right or earns you a better shot at being one of the mega winners. And then lastly, even though a lot of the media attention in the buzz is in the infrastructure and developer tooling layer, it turns out that that layer can be successful only if the application layer is even more successful. And we saw this with the rise of SaaS as well. A lot of the buzz excitement is on the technology, the tooling layer, which is fine, nothing wrong with that. But the only way for that to be successful is that the application layer is even more successful so that frankly, they can generate enough revenue to pay the infrastructure and the tooling layer. So actually, let me mention one example. ArmorRy is actually just texting the CEO yesterday, but ArmorRy is a complete rebuild that uses AI for romantic relationship coaching. And just to point out I'm an AI guy and I feel like I know nothing really about romance. And if you don't believe me, you can ask my wife, she will confirm that I know nothing about romance.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='42caeb58-5c83-41a3-9441-52ac7c5fbaa9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3f18f43f-a618-4ba3-8d24-454a9b6e4eb7', node_type=None, metadata={}, hash='60a19cf2f3f40cb3e3e3da0b504b02a7589b57ff3242ec8c93883f8cc407ab39'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f69f41ff-e9fd-4dda-99aa-e6aa7cec583a', node_type=None, metadata={}, hash='3ab2ad4224832b9ddfda3aa82df5801115f697f47f87044e5708bce0af27cc3f')}, hash='e21b65841ae36cee11815aab0d469735c0ae2df7173fbedd758c58c318dfd421', text=\"But when we want to build this, we want to get together with the former CEO of Tinder, a Renata Nibble, and with my team's expertise in AI and her expertise in relationships. She ran Tinder. She knows more about relationships. I think anyone I know, we're able to build something pretty unique using AI for romantic relationship mentoring. And the interesting thing about applications like these is when we look around, how many teams in the world are simultaneously expert in AI and in relationships. And so at the application layer, I'm seeing a lot of exciting opportunities that seem to the very large market, but where the competition set is very light relative to the magnitude of the opportunity. It's not that there are no competitors, but it's just much less intense compared to the developer tool or the infrastructure layer. And so because I've spent a lot of time iterating on a process of building startups, what I'm going to do is just very transparently tell you the recipe we've developed for building startups. And so after many years of iteration and improvement, this is how we now build startups. My team's always had access to a lot of different ideas, internally generated ideas from partners. And I want to walk through this with one example of something we did, which is a company bearing AI, which uses AI to make ships more fuel efficient. So this idea came to me when a few years ago, a large Japanese conglomerate called Mitsui, that is a major shareholder in the sort of operator major shipping lines. They came to me and they said, hey, Andrew, you should build a business to use AI to make ships more fuel efficient. And the specific idea was, think of it as a Google Maps for ships. We can suggest a ship or tell a ship how to steer so that you still get to your destination on time, but using turns out about 10% less fuel. And so what we now do is we spend about a month validating the idea. So double check, this is idea even technically feasible and in top to perspective customers to make sure that it's marketing. So it's been up to about a month doing that. And if it passes this stage, then we will go and recruit a CEO to work with us on the project. When I was starting, I used to spend a long time working on the project myself before bringing on the CEO, but after iterating, we realized that bringing on the leader at the very beginning to work with us, it reduces the burden of having to transfer knowledge or having a CEO come in and have to revalidate whether we discover it. So the process is we've learned much more efficient, which is bringing the leader at the very start. And so in the case of bearing AI, we found a fantastic CEO, Dylan Kyle, who's repeat entrepreneur, one successful ex-report for. And then we spent three months, six two weeks sprints to work with them to build a prototype as well as do do deep customer validation. If it survives this stage and we have about a two thirds, 66 percent survival rate, we never had the first check in, which then gives the company resources to hire an executive team, you know, build the key team, get the MVP working, minimize our product working, and get some real customers. And then after that, you know, hopefully then successfully raises additional external rounds of funding that can keep on growing and scaling. So I'm really proud of the work that my team was able to do to support Mitsui's idea and Dylan Kyle as CEO. And today there are hundreds of ships on the high seas right now that are steering themselves differently because of bearing AI. And 10 percent fuel savings translates to rough order amounts to maybe $450,000 in savings in fuel per year. And of course, it's also frankly quite a bit better for the environment. And I think this is not up, I think would not have existed if not for Dylan's fantastic work. And then also, you know, Mitsui brainless idea to me. And I like this example because this is another one is like, you know, this is a thought of idea that just a point out I would never have come up with myself, right? Because, you know, I've been on a boat, but what do I know about maritime shipping? But is the deep subject matter expertise of Mitsui that had to zenzai together with Dylan and then my team's expertise in AI that made this possible? And so as I operate an AI, one thing I've learned is my swim lane is AI. And that's it because I don't have time. It's very difficult for me to be expert in maritime shipping and romantic relationships and healthcare and financial services and on and on and on and on.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='f69f41ff-e9fd-4dda-99aa-e6aa7cec583a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='42caeb58-5c83-41a3-9441-52ac7c5fbaa9', node_type=None, metadata={}, hash='e21b65841ae36cee11815aab0d469735c0ae2df7173fbedd758c58c318dfd421'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='912704e8-deda-40f4-9f4e-57d22c7fd70b', node_type=None, metadata={}, hash='e1a02efac162db4091dc99273ef684985f10c053c8231397b51469487e45b586')}, hash='3ab2ad4224832b9ddfda3aa82df5801115f697f47f87044e5708bce0af27cc3f', text=\"Actra technical validation and then use, you know, AI resources to make sure the AI tech has built quickly. Well, and I think we've always managed to help the companies build a strong technical team than partnering with subject matter experts often results in exciting new opportunities. And I want to share with you one other weird aspect of one of the weird lessons I've learned about, you know, building startups, which is I like to engage only when there's a concrete idea. And this runs counter to bother the advice you hear from the design thinking methodology, which often says don't rush to solutioning, right? Explore a lot of alternatives to avoid the solution. Honestly, we tried that. It was very slow. But what we've learned is that at the ideation stage, if someone comes to me and says, hey, Andrew, you should apply AI to financial services. Because I'm not a subject matter expert in financial services, it's very slow for me to learn enough about financial services that you can figure out what to do. I mean, eventually, you could get a good outcome, but it's a very labor intensive, very slow, very expensive process. So me to try to learn industry after industry. In contrast, one of my partners wrote his ideas that Tony Cheat, not really seriously, but you know, let's say the concrete idea is by GBT, let's eliminate commercials by automatically buying every product advertised in exchange for not having seen ads. It's not a good idea, but it is a concrete idea. And it turns out concrete ideas can be validated or falsified efficiently. They also give a team a clear direction to execute. And I've learned it in today's world, especially with the excitement and buzz and exposure to the AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world that have deeply thought about a problem for months, sometimes even one or two years, but they've not yet had a build partner. And when we get together with them and hear and they share the idea of us, it allows us to work with them to very quickly go into validation and building. And I find that this works because there are a lot of people that have already done the design thinking thing of exploring a lot of ideas and winning down to really good ideas. And there are, I find that there's so many good ideas sitting out there that no one is working on that finding those good ideas that someone has already had and wants to share of us and wants to build partner for that turns out to be much more efficient engine. So, before I wrap up, we'll go to the question second. Just a few slides to talk about risks and social impact. So, AI is a very powerful technology to state something you probably guess. My team's and I, we only work on projects that move humanity forward. And we have multiple times, killed projects that we assess that we financially sound based on ethical grounds. It turns out I've been surprising. Sometimes this made at the creativity of people to come up with good ideas, sorry to come up with really bad ideas that seem profitable, but really should not be built with a few projects on those grounds. And then I think it has to acknowledge that AI today does have problems with bias, fairness, accuracy, but also, you know, technology is improving quickly. So, I see that AI systems today less bias than six months ago and more fair than six months ago, which is not to dismiss the importance of these problems. They are problems and we should continue to work on them. But I'm also gratified at the number of AI tears working hard on these issues to make them much better. When I think of the biggest risk of AI, I think that the biggest risk, one of the biggest risk is the disruption to jobs. This is a diagram from a paper by our friend at the University of Pennsylvania and some folks at OpenAI, analyzing the exposure of different jobs to AI automation. And it turns out that whereas the previous wave of automation mainly the most exposed jobs were often the lower-wage jobs, such as when we put robots into factories. With this current wave of automation is actually the higher-wage jobs further the right of this axis that seems to have more of their tasks exposed to AI automation. So, even as we create tremendous value using AI, I feel like as citizens and our corporations and the governments and really our society, I feel a strong obligation to make sure that people, especially people who are lively, who are disrupted, are still well taken care of, are still treated well. And then lastly, it feels like every time there's a big wave of progress in AI, there's a big wave of hype about artificial gender intelligence as well.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='912704e8-deda-40f4-9f4e-57d22c7fd70b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='transcriptions/youtube_5p248yoa3oE.json', node_type=None, metadata={}, hash='1dd6c2d04a5947bc4f30e51c9b0b71a2c7a4c7ec35a706ddd2ae404b324b54e0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f69f41ff-e9fd-4dda-99aa-e6aa7cec583a', node_type=None, metadata={}, hash='3ab2ad4224832b9ddfda3aa82df5801115f697f47f87044e5708bce0af27cc3f')}, hash='e1a02efac162db4091dc99273ef684985f10c053c8231397b51469487e45b586', text=\"When deep learning started to work really well 10 years ago, there was a lot of hype about AI and now the gender of AI is working really well. There's another wave of hype about AI. But I think that artificial gender intelligence, AI didn't do anything human can do, it still decades away, maybe 30 to 50 years, maybe even longer. I hope we'll see in our lifetimes. But I don't think there's any time soon. One of the challenges is that the biological path to intelligence, like humans and the digital path to intelligence, AI, they've taken very different paths. And the funny thing about the definition of AI is benchmarking this very different digital path to intelligence with really the biological path to intelligence. So I think, you know, Russian-Gashmoldos are smarter than any of us in certain key dimensions, but much dumber than any of us in other dimensions. And so forcing it to do everything a human can do is like a funny comparison. But I hope we'll get there, maybe hopefully within a lifetimes. And then there's also a lot of, I think, overblown hype about AI creating extinction risk for humanity. Candidly, I don't see it. I just don't see how AI creates any meaningful extinction risk for humanity. I think that people worry we can't control AI, but we have lots of AI will be more powerful than any person. But we've lots of experience steering very powerful entities such as corporations or nation states that are far more powerful than any single person and making sure they for the most part benefit humanity. And also technology develops gradually. The so-called hot takeoff scenario, where it's not really working today, and then suddenly one day overnight, it works brilliantly with Chief Super Intelligence takes over the world. That's just not realistic. And I think AI technology will develop slowly, like all the technology, and then it gives us plenty of time to make sure that we provide oversight and can manage it to be safe. And lastly, if you look at the real extinction risk of humanity, such as fingers crossed an ex-pandemic or climate change leading to a massive depopulation of some parts of the planet, or much lower odds that maybe someday, and as there are doing to us, whether they're done to the dinosaurs, I think we look at the actual real extinction risk to humanity. AI, having more intelligence, even artificial intelligence in the world, would be a key part of the solution. So I feel like if you want humanity to survive and thrive for the next thousand years, rather than slowing AI down, which some people propose, I would rather make AI go as fast as possible. So with that, just to summarize, this is my last slide. I think that AI, as a general purpose technology, creates a lot of new opportunities for everyone, and a lot of the exciting and important work that lies ahead of us all is to go and build those concrete use cases. And hopefully in the future, hopefully I have opportunities to maybe engage with more of you on those opportunities as well. So that, let me just say thank you all very much.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)], metadata={'4c2ae659-5a8d-42fa-a6bd-5a7f46174978': {}, '3fceb361-645a-46c0-851e-5aa942da0755': {}, 'c0450cf0-0592-42a6-baa3-73e654fe5eab': {}, 'b7563833-e519-4296-aa25-088dcdd6a281': {}, '3f18f43f-a618-4ba3-8d24-454a9b6e4eb7': {}, '42caeb58-5c83-41a3-9441-52ac7c5fbaa9': {}, 'f69f41ff-e9fd-4dda-99aa-e6aa7cec583a': {}, '912704e8-deda-40f4-9f4e-57d22c7fd70b': {}})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = doc_summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "response = query_engine.query(\"What are the author's thoughts on the risks and benefits of AI for humanity\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65445fb9-766e-4117-b507-05cebcabac09",
   "metadata": {},
   "source": [
    "# Perform Retrieval from Document Summary Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6a4934b-3cc6-4970-86b0-c3e85310ffd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = doc_summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e922aaf-7cdc-4808-9847-441f126e9928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = query_engine.query(\"bias and fairness in AI systems \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47154bba-ced0-4f92-b8c0-6d5669ca03d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Index Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf2d817c-97bc-40ec-adc0-fd3a2b68cd7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c34cb12a-c251-4a0d-8f08-e9299da341c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.schema import Node, Document\n",
    "from llama_index.indices.document_summary import DocumentSummaryIndex\n",
    "\n",
    "def index_json_file(json_file_path):\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    nodes = []\n",
    "    for segment in json_data[\"segments\"].values():\n",
    "        text = segment[\"text\"]\n",
    "        start = segment[\"start\"]\n",
    "        metadata = {\"start\": start}\n",
    "        node = Node(text=text, metadata=metadata)\n",
    "        nodes.append(node)\n",
    "    \n",
    "    docs = [Document(nodes=nodes)]\n",
    "    index = DocumentSummaryIndex.from_documents(docs)\n",
    "    index.storage_context.persist(\"index\")\n",
    "\n",
    "def json_file_document(json_file_path):\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    for segment in json_data[\"segments\"]:\n",
    "        text = segment[\"text\"]\n",
    "        start = segment[\"start\"]\n",
    "        metadata = {\"start\": start}\n",
    "        documents.append(Document(text=text,\n",
    "                                 metadata=metadata)\n",
    "                        )\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81e0501b-5e62-4aa4-904f-195f286db4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = json_file_document(\"transcriptions/youtube_5p248yoa3oE.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "887e0247-f1ec-4b8b-8214-680d9bd99f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9325ce38-4d7f-439b-b627-6b422dfcc73e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create client and a new collection\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "try:\n",
    "    chroma_collection = chroma_client.create_collection(\"quickstart\")\n",
    "except:\n",
    "    pass\n",
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70678b6f-1870-41b9-a284-df827a1ff4f7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='7f47d3d5-4409-4f45-be37-c363fb941920', embedding=None, metadata={'start': 4.999999999999998}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7b0d5cbaea75ebe4cd88b681e44129bd0181221b1f90613cb5bc7251bcd1268c', text=' It is my pleasure to welcome Dr. Andrew Wu tonight.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='775b4db5-fd43-438d-863c-145c0c82610e', embedding=None, metadata={'start': 11.28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='75ff31414aef3d654c85fff4f31f4bedadc847b3d1a37445c3c71ab30457e991', text=' Andrew is the managing general partner of AI Fund, founder of Deep Learning AI, and', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2058d552-24a9-4a47-8477-1206984b27f8', embedding=None, metadata={'start': 20.88}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3c06e505c7c219e6ac8d6286dff3dbce02f337efb27e2273b02c88a5233e6326', text=' learning and lending AI, chairman and co-founder of Coursera, and an adjunct professor of computer', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0a352469-a1cc-4355-898a-65567c6abc16', embedding=None, metadata={'start': 29.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6b9d2a3c83364956b0a2dd525a09125f30024d66464ae66296c6f0b72b16a17b', text=' science here at Stanford. Previously he had started and led the Google Brain team, which', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='859b0bf6-8c57-4ea5-abce-4f877f472dfb', embedding=None, metadata={'start': 36.9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3dfa906cffc7d885081166d9f016b4dc4cf19e5df5ef65151caf3da6d73b3c1b', text=' had helped Google adopt modern AI, and he was also director of the Stanford AI lab.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cf646c60-e32e-4e0f-b476-81ec962c38b5', embedding=None, metadata={'start': 43.28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='31d48f48f6070e45393d19d2fca4e0a2a36c61689c9f08b66aedf4831267ce48', text=' About 8 million people, one in 1,000 persons on the planet, have taken an AI class from him,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fb62df95-85dc-40d1-ada4-c3d549baa8d5', embedding=None, metadata={'start': 52.54}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='807376dace67dcff4b6ac103ece295a638c98db792606efe26289c18733c40a5', text=\" and through both his education and his AI work, he has changed humor's lives.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7263cc7b-4c89-45f7-a47d-193babba4faf', embedding=None, metadata={'start': 58.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b91e164160b592db383c04b655831cc9f99985ae9dcfc7b48680d782fd3cd6d4', text=' Please welcome Dr. Andrew Wu.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5d4eee68-9f96-46fe-88d0-ea7147a53c37', embedding=None, metadata={'start': 66.48}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='92d82a3c4a9cc8495ca8988f072958504a0ca3c856895eb932e89ebfc2ccffb4', text=\" Thank you Lisa, it's good to see everyone. So what I want to do today is\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='87fa79cb-1435-487f-a182-e98b4daf5788', embedding=None, metadata={'start': 71.28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5e99739605326dc3efb4aecf3d0daab2c8cb37bec21d935c526d2185c509b097', text=\" chat to you about some opportunities in AI. So I've been saying AI is a new electricity.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cab0c539-b1e8-4fea-8be6-fe4846a20f16', embedding=None, metadata={'start': 78.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c5da543dbbbe9653bd6e15b6a21a982f41e9436f5ed7d6f94069db5c64fcb189', text=' One of the difficult things to understand about AI is that it is a general purpose technology,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='51a4489a-2ed9-45df-8079-1f95e18a7ad2', embedding=None, metadata={'start': 83.72}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e9a906db8192e119cb73be42eb07c9fbdb311b4f2601c00738e15cefe82d1bd9', text=\" meaning that it's not useful only for one thing, but it's useful for lots of different applications.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='51fc5c24-31df-4b51-aa03-d13856cdfed4', embedding=None, metadata={'start': 88.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9b1fa146dd53ed5ebda9a4168f1c1299d951d82a7835e7008b84b05b951032d4', text=' Kind of like electricity. If I were to ask you what is electricity good for, you know,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6cfa8aab-caff-48cd-96ae-10a3411ac325', embedding=None, metadata={'start': 93.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1bc71bc5fd143a24cb76ceca562f44389174ee7bf2406dd2e0f5abfcefff006f', text=\" it's not any one thing, it's a lot of things. So what I'd like to do is start off sharing with you,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8da37050-3e1c-4f66-8aa8-3e1d6949ab73', embedding=None, metadata={'start': 97.4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='22d44e03e270275ee6017ab77d07bf8acfe9e52f3ff6ec83ba3a1023cac538d4', text=' high view the technology landscape, and just to lead into the set of opportunities. So a lot of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f624f437-50ec-45b8-a75b-8e6895df124c', embedding=None, metadata={'start': 104.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ab72c3503438e7b6c0c310969115b3bee1400519abac3fb54e142754b01bf51e', text=' hype, a lot of excitement about AI. And I think a good way to think about AI is as a collection of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6f4b529f-711b-4a62-b5b8-d26feac02231', embedding=None, metadata={'start': 110.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='42e0532055c6e8b50a9895253ad0c3c64ca2f5ead3b3f4ca3c8009adea20a88a', text=' tools. So this includes a technique called supervised learning, which is very good at recognizing', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e1c1b534-2d07-440c-90f9-3784e7ad5b04', embedding=None, metadata={'start': 115.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='86b7d643c8a78becadf1fe15e1f59fac6e7a1c49ba58fa859de958aeefabd72b', text=' things or labeling things, and genitive AI, which is relatively new, exciting development.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='71377f14-eda7-4c16-8f0b-9180c80ac7b7', embedding=None, metadata={'start': 120.94}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='20bc21f2e083e29dea0ff24a3370fdb9a13a94fba7fd1c41ecbee41e25291274', text=\" If you're familiar with AI, you may have heard of other tools, but I'm going to talk less about\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ca980205-32a1-45d1-9ab7-2f4d76bf5501', embedding=None, metadata={'start': 125.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c9624e53b1feeb48c622c6926a4d7919b114b16856df5072812003401463082f', text=\" these additional tools and I'll focus today on what I think are currently the two most important\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='666cde3b-5937-431a-b7d9-29d0573ce2c1', embedding=None, metadata={'start': 130.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bd90a95a5f76299bcf97b990d3d28b2b3a65d58fe78370bab3c6a7e7f86320bc', text=' tools which are supervised learning and genitive AI. So supervised learning is very good at labeling', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c4e90668-a919-4908-9897-90e8b1ebe7ca', embedding=None, metadata={'start': 136.5}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e92e0b26a006ef01e643f2c3b2f18783d5d54bed75c742c202b0559284c091f0', text=' things or very good at computing input to outputs or A to B mappings given in B A, give me an output B.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='74386d8b-238c-480d-a95a-cf0db7370eab', embedding=None, metadata={'start': 144.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0afe149566a28c2f9fe69189de086356c686c5a52a8a5175f46ffb27844162dc', text=' For example, given an email, we can use supervised learning to label a spam or not spam.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='91b43d04-e9a8-4eac-b30a-eed6351a8193', embedding=None, metadata={'start': 150.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='93c6e2e3b6b2432e3d29b4816fcf78318986fb051e7204ff64f7bc8665440523', text=\" The most lucrative application of this that I've ever worked on is probably online advertising,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b2543137-bb7b-4d18-8890-0a86fad0f617', embedding=None, metadata={'start': 154.54}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='aad9e5fc1551156331b3275bebb13c68d273d8106a5fdbd7d66f0df3fcfc8b42', text=' where I give it an ad, we can label the users likely to click on it and therefore show more relevant', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='05a7ab31-bd6f-4768-b722-cc3210e4635f', embedding=None, metadata={'start': 159.56}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0c903767dfbf5ca4361d15fd80f99b428420f07af74ccc36c31677f585fd5e04', text=' ads. For self-driving cars, given the sense of readings of a car, we can label it with where the other', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d18adad6-1af2-48ed-94ea-2b282a4a0180', embedding=None, metadata={'start': 165.04}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d586a3bfef1cc43cd3067595e320d36df566dc5d22cfd72c00d032f6f9c0f1b4', text=' cars, one project that my team at AI and worked on was shift route optimization, where given', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e2c8b555-f17e-4e75-87c7-209e64647b97', embedding=None, metadata={'start': 169.62}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bc56eeccf31efaad41ce1fa440b3fdb3ed8fa67a7c8017c48291c10853d73843', text=' a route to the ship is taking or considering taking, we can label that with how much fuel we think', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b638c89d-3271-4d29-baf0-4b5765844eac', embedding=None, metadata={'start': 174.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dcf9dcdcc452ec77d64f7d220c72c0bf0d877c48bcbb527e225b052d2e283a66', text=' does to consume and uses the chips more fuel efficient. Still a lot of work in automated visual', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0b027fca-cea5-4568-a7b1-d859a8190948', embedding=None, metadata={'start': 181.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cde6c7b10e998e0c10cb954331b1b72a335a29165ae1ecdcc0b539206bf75384', text=' inspection in factories, so you can take a picture of a smartphone that was just manufactured and', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='172815f7-b8a1-4649-81f1-8c48ce48ab75', embedding=None, metadata={'start': 185.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='655d7582210f22cbd8d811b3c5ade5a64accac3cd57278417a5c332ee5168425', text=\" label is a scratch when you're defecting it. Or if you want to build a restaurant review reputation\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6f42f44f-7674-4979-928d-4bbe82230e31', embedding=None, metadata={'start': 191.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='31aeb9a30ab6838a5966ea963a98360ecd1178daa02133e7cedc2ca0a67190ad', text=' monitoring system, you can have little piece of software that looks at online restaurant reviews', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3ec6db3-bd34-4bf2-9ad8-4e6fec5cf5d4', embedding=None, metadata={'start': 195.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4b17fbf70082d65934bf1e96084b2e0fb9993477a67074849e5feeeac328be1a', text=' and labels that as positive or negative sentiment. So one nice thing, one cool thing about supervised', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bf788025-4248-4e94-bc28-195ee6586689', embedding=None, metadata={'start': 201.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='449d7a1dd6a0161183151b85cfa78a0ca80b6909202fb96b1de6a0fac5152379', text=\" learning is that it's not useful for one thing, it's useful for all of these different applications\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5ade9131-1e80-4d03-b4bc-6bd66f8ca7da', embedding=None, metadata={'start': 205.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2d87333fd90e9ebef91aa7a3ac5373a6c256fd43aab392b08442f271f71e6900', text=' and many more besides. Let me just walk through concretely the workflow of one example of a', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='924c5f34-9454-4156-bfb3-6bfd89805da1', embedding=None, metadata={'start': 212.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a1b7f8c1ebeac380d0c8baefaad4c0032b2fa8a8af6ba9e97dafa8beeb42b36d', text=' supervised learning labeling things kind of project. If you want to build a system to label', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b0bebd49-75a8-4220-8179-d068e6c221eb', embedding=None, metadata={'start': 217.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fbb51033f63dfebae6d0452a001fc9fce62fc87c05e13f1db240020db99b8d6f', text=\" restaurant reviews, you then collect a few data points, a collective dataset, where it's say\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e68f9136-97fe-4585-8c83-ba2a3a169dfb', embedding=None, metadata={'start': 221.72}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c70e7c33655554f75c25a71bd5049a087d0b0b1ef28fcc9574d062bd7634b653', text=\" the best time you sandwich great, you say that is positive, several slow, there's negative,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d9247fe2-5ff7-497f-aed3-2ea984213399', embedding=None, metadata={'start': 227.72}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d15dc119543b68c918fa6309f6f98350032ee814ee7899f52832ad2ad48cb38f', text=\" my favorite should be curry, there's positive. And here I've shown three data points, but you're\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4b9ae2ea-c1e8-4445-b36d-67bb2dbfa37e', embedding=None, metadata={'start': 233.26}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bde2479d9bbf2400da1fa194d6ae7e58904cb5f38b5150f2ee8ea167a17e2dbf', text=' building this, you may get thousands of data points like this, thousands of training examples,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='099c4843-6e3f-4f50-b97b-7ce993a8dd33', embedding=None, metadata={'start': 237.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='955618dd761bcda42c1730cf65d82c28bb27c6f8a241639821a743230ad5c2d7', text=' we call it. And the workflow of a machine learning project, when AI project is you get labeled data,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='430c85d7-1de3-4cf2-adf0-b0ac8447bf20', embedding=None, metadata={'start': 243.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d20f569b4d0cafba645710f3a7bff93d44fe2a8953bf385109012cb22cdfdb37', text=' maybe thousands of data points, then you have an AI entry team train an AI model to learn from', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c1929c5c-4982-4c05-b127-2457bfb2bfa1', embedding=None, metadata={'start': 249.66}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5bf4442c9cfb0f81529481dfd7bbf9c54d6995d8aa54a60eb329664e7f6c82e3', text=' this data. And then finally, you would find maybe a cloud service to run the trained AI model,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='02c37772-45dd-41bb-8be0-832e079396e2', embedding=None, metadata={'start': 256.08}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dbc8906890a43ddfd41a0aa2ee44bdee6ef090db54d5ba1da39c27b5860a8d6a', text=\" and they can feed it, you know, let's both have a hat and that's positive sentiment. And so I\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1c5211c8-34a8-442a-8658-7aecb03e2288', embedding=None, metadata={'start': 261.9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1cf1f08df70b5a27d0e8e8213049fbfbcfbb47b653379feda8537328a84c0f76', text=' think the last decade was maybe the decade of large scale supervised learning. What we found starting', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='61f4f2ac-d16f-4e18-94cc-0986bf5af095', embedding=None, metadata={'start': 268.08}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='82f0fa4a2c9e89135786f9d00d0536120e155d2ed775ae19790318be9e77307d', text=' about 10, 15 years ago was if you were to train a small AI model, so train a small neural network,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f533b398-cc62-44aa-b1db-d284293cf2b6', embedding=None, metadata={'start': 273.92}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='259d97bf271ff39cdf7b7eb13e96911e3bade00b1563496e00f58d537878a6c5', text=' small deep learning algorithm, basically a small AI model, maybe not on a very powerful computer,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5c53cf90-e8dc-4489-9716-d68195590fe8', embedding=None, metadata={'start': 279.12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5fcfcc38c0be938f17c7ffeea2cb0df47a6ef4bd8677deeacabaef36701f5a96', text=' then as you fed more data, as performance would get better for a little bit, but then it would', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1c3e8584-c20c-4f46-bcb7-a93170bedb6a', embedding=None, metadata={'start': 283.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bafdd0408caa1201e5ce35ca6e3aa60fda56a4045305c6a3345c3ffb6ab29af3', text=' flatten out, it would plateau, and it would stop being able to use the data to get better and better.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fce2653f-b85f-4735-bc30-0ce03a47e115', embedding=None, metadata={'start': 289.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ddcb3defc06438e818ffc75e6edd789c9a75bdead17111ea3fb95085c92be73e', text=' But if you were to train a very large AI model, lots of compute on maybe powerful GPUs,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2d29438c-22c1-4605-b29a-952584862170', embedding=None, metadata={'start': 295.82}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='06eb962dbf17fc3293fdd89a6068c375658854fdd13837a727f712dcb527961e', text=' then as we scaled up the amount of data we gave the machine learning model,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f5024fdb-3bc2-46db-8a32-cc4880568464', embedding=None, metadata={'start': 300.38}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ae311cabc8ef9a20789657d82a364d9dfa24211080cf33429140624801a0193f', text=' its performance would kind of keep on getting better and better. So this is why when I started', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4a00c8b6-ec3a-4dc3-a3bc-6ab2a91f48f1', embedding=None, metadata={'start': 304.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e5301ce3e59ab0f4438a6eef8cb0bad2da6be7da485445a2b982185792b0fb09', text=' and led the Google Brain team, the primary mission that I directed the team to solve at the time was,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ba3c5a8c-1775-459c-8185-f9f216ceb2f5', embedding=None, metadata={'start': 310.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='96b2b18eb8706be01c0ba082cf2be8f30b926279f195bc7d50eefb757ce23fc0', text=\" let's just build really, really large neural networks that we then fed a lot of data to,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4fd1ac40-25ef-457e-aae3-ea04144508c8', embedding=None, metadata={'start': 314.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='23b068cef9bbd0331c03b31ec6cc4557acf7ae4aa4b0c7a5d9b6ec361166c6f9', text=' and that recipe fortunately worked. And I think the idea of driving large compute and', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='86e426f4-97f6-433e-a2ae-1d7cbd9f820c', embedding=None, metadata={'start': 319.86}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f36d3bf4c6a0a9cd4d141321f80a2cc83646a1b96f393598d12d8143679385a8', text=' large scale of data, that recipes really helped us driven a lot of AI progress over the last decade.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='683a3776-a5b2-4601-af2c-2e15ce41fc2f', embedding=None, metadata={'start': 327.36}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8b838909246e4eb876b25ed6614ddd753adfb89f4b181a7c4c3c2dc47f26f1ca', text=' So if that was the last decade of AI, I think this decade is turning out to be also doing', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9ecbbdfb-df70-489a-a854-c146cc2d3139', embedding=None, metadata={'start': 333.66}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8e84babc2f0b82f10c44a525ea7f858ab70f29fc6bfa4837c26bf6ce586a7af4', text=' everything we had in supervised learning, but adding to it, the exciting two of Genes of AI.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b95df2b7-112d-4453-98d2-28b7b443e55b', embedding=None, metadata={'start': 340.06000000000006}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e25a3bf1815ef7a2ec32b2888d645a4ce1687052464b497adc79262acdf349c7', text=' So many of you, maybe all of you, were played with charge GPD and bar and so on, but just', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5960bf57-4723-405c-9c27-0b0e3d585d4a', embedding=None, metadata={'start': 345.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='67e4b90b78103c40902fe8b68e11c7272756677f8cf4a8285ddfb703c9e30c29', text=' you know, given a piece of text, which we call prompt, like I love eating, if you run this multiple', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='590d1b35-4e2b-4759-89f3-7585bcc6c15d', embedding=None, metadata={'start': 350.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='80dae8e5eb7de65d2357d2437c034757f1730d8f2a7e25488ab2d130572af95a', text=\" times, maybe you get big old screen keys or my mother's me love or out of friends, and the AI\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fcf679d0-6895-45bd-bf30-2e6f0ec89c2e', embedding=None, metadata={'start': 356.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='659ffabede9e2b6074ad55bd7b375bfd63dfabdc7d8979735e02fa5b50127104', text=' system can generate output like that. Given the amounts of buzz and excitement about Genes of AI,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='02d381a3-8816-47e1-8e71-7e535f63951e', embedding=None, metadata={'start': 361.82}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c5610a8de8ff92deaf83ff6369e93405b9d6516e5bf10286423a2e274841659c', text=\" I thought that'd take just half a slide to, you know, say a little bit about how this works.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='24517728-1c06-4e36-ae29-bf3527b3f33e', embedding=None, metadata={'start': 366.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e7cf64fab7ee210bf2ebfffa0ee345bcc611016f1bb96e270cb81e487110601f', text=' So it turns out that, Genes of AI, at least this type of text generation, the core of it is', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='96004377-0c68-4244-a493-dca6826f491c', embedding=None, metadata={'start': 374.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9faef898b24c260c75b569a73391d54baead68d42498943cad60e0e2b59e2474', text=' using supervised learning that inputs output mappings to repeatedly predict the next word. And so,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='94f11703-df79-466b-b644-ae62ae3d6d3a', embedding=None, metadata={'start': 380.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cbc657bd07ef1b0119d47ab3ce64f85edc5a229696bbf457dd6aacbe7e5615d5', text=' if your system reads on the internet to sentence like, my favorite food is a bagel with cream', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='70500897-4beb-4614-a535-493aa1e7617b', embedding=None, metadata={'start': 385.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='417cf59914451f47c05874ac22dd25e3f7bc34088ab2e69f2499542cb48683b9', text=' cheese and locks, then this is translated into a few data points where if it sees my favorite food', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2fe01bc4-99e6-4ca3-acd9-e48bd4f5648a', embedding=None, metadata={'start': 392.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5230c2b1c1ea900c8a7e510c35ad558dea45a24b2c8bc5e14c22b72bceb723ec', text=' is a, in this case, try to guess that the right next word was bagel or my favorite food is a bagel,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='430927b3-e9ed-4f87-9cbe-36ae45f81704', embedding=None, metadata={'start': 399.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='80bd25fe6242ef9a2ade241a7c1d81573f37bf00bdff698480201ce211c47990', text=' try to guess next word is worth. And similarly, if it sees that, you know, in this case, the right', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='29f88e2f-7ee3-406e-9005-759dcc54b0c8', embedding=None, metadata={'start': 405.24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dec90795b49af5135d3924ba94a40aa928687c24ab9a3b7e53d5d2bfef4cf3a2', text=' guess for the next word would have been cream. So by taking text that you find on the internet or', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4d3e8b7b-ff6f-4e96-b590-69a6a728aca2', embedding=None, metadata={'start': 411.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='727b3f46efed85b000ea81f6a6277f84fa303596b8606b2945f4dc8a6316c15c', text=' other sources and by using this input output, supervised learning to try to repeatedly predict', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c4ae22bf-f4fa-40e0-8d66-58327e4d8f1e', embedding=None, metadata={'start': 416.66}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c6ef874adf852ced7c713baa78fb7b15d9995f5287fc93b850b769773b7fd13a', text=' if you train a very large AI system on hundreds of billions of words, or in the case of the largest', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b3783140-648e-489a-97e8-32ef41bc759a', embedding=None, metadata={'start': 423.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='067459bea08cec4c2513b36efa37bc32c47a220e90a54703271ca7db3824f482', text=' models, now more than a trillion words, then you get a large language model like chat GP. And,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='efb0f798-ffa1-4aaf-a359-f7c2fe515221', embedding=None, metadata={'start': 429.12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='917d82a544ae5fb8c4a9c75338f56f5f412bd1a9563eb6beb5c8228a836c1762', text=' you know, there are additional other important technical details I talked about predicting the', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='84cc14e0-fa79-40f0-942e-40c0a2403dfe', embedding=None, metadata={'start': 433.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='eec31680d49fcfe2b776d33af56e007b55030ae202c1358b06e3b4d48b17dea6', text=' next word. Technically, these systems predict the next subword, a part of work called token,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='921d3677-693a-42df-a35f-e783255c82e4', embedding=None, metadata={'start': 439.02}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6492eb883fb851b0ea2cc4674f7a9cf9463d92f9f7c60e411003d73369cbd64f', text=' and then there are other techniques like RHS for further tuning the AI output to be more', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8ff04f73-36d1-41bd-81f4-eb0ba767fdf5', embedding=None, metadata={'start': 444.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04f8fe3becf786ca8e71a08706fc2b6a2d8357e07c57695ca205229430cc0357', text=' helpful on this and harmless. But at the heart of it is this using supervised learning to', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d2fb8b92-a661-4eb2-8a80-4debdca314e5', embedding=None, metadata={'start': 450.74}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='46821bd633ec331b13ec4441778466f074c957c3e1b97229f644495cdd6f4608', text=' repeatedly predict the next word that that really was enabling the exciting, you know, really fantastic', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='98bc72e8-3989-4309-b7b2-f80016285cdc', embedding=None, metadata={'start': 456.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7217ecddcc6f15b001241f5edcea4ef42a46d7de238b5a75c307eea0a20d5f55', text=' progress on large language models. So while many people have seen large language models as a', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a49da807-5f6f-4a48-aa26-3f02d083861f', embedding=None, metadata={'start': 466.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4b01a61b9019674ad3756ff2f3cf8836891f830ed60fac1dcd8497a639c760f2', text=\" fantastic consumer too, you can go to a website like chat GP's website or BODs or other large\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9b1db7df-6eca-40e4-8877-505e4f364516', embedding=None, metadata={'start': 472.54}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='606a16cf0f0b4b8e64e1cf4df938ca2f530d0fa4f82df9b2dc41a059ed406e91', text=\" language models and use it. I think it's fantastic too. There's one of the trends I think is\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9fbf8bd9-2ed0-4828-a0ee-b9ee67604a56', embedding=None, metadata={'start': 476.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='abd7722581c192ab510c2bf7858ffd3c994096b1adae43bbd621f9ee2bdfc9d0', text=' still underappreciated, which is the power of large language models, not as it can, not as it,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b4fb7ca8-c7f1-4105-a260-06773fdfc70c', embedding=None, metadata={'start': 482.6}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0af97f85a86f5b9181c0580030653213293013b62e91ebb2075f12942e1479c8', text=' not just as consumer too, but as it develop it too. So it turns out that there are applications that', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7a147e09-74d3-49b3-85f4-87fd83652a39', embedding=None, metadata={'start': 489.82}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='aa2e36f7eb6c9b2b2aa747ba3953a205ce6af71db4afe05b8ec87daf3049d202', text=' used to take me months to build that a lot of people can now build much faster by using a large', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dc41a7b9-6c38-4a1c-a838-0be66bdf22c4', embedding=None, metadata={'start': 497.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1896fc0deae56e020debdd1bc746cfcdaa91e1890fa8150f1538237d866ff604', text=' language model. So specifically, the work though for supervised learning, building the restaurant', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7b2ffdab-b6fb-409c-80c1-28cb5389ec61', embedding=None, metadata={'start': 502.12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cddfd713e9e429eff44c7c87164f994ff6f92bdd9d2c1fe91e061c4959775d55', text=' review system would be that you need to get a bunch of label data and maybe that takes a month', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8cd02f32-8bd8-49e8-91b3-6eae6f594d5e', embedding=None, metadata={'start': 508.28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='33a45f68212a9acef584c73d9a4e443524abebb16fbf1517aaa89ecd19d77c5c', text=' to get a few thousand data points. And then have an AI team train and tune and really get optimized', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3140aecd-15c8-4b62-9547-e2f16a65a1de', embedding=None, metadata={'start': 515.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9b690b8625d2f01c2adfa76a7d82dd6d460ccc278d74256e5111066e0ddc9983', text=\" performance on your AI model, maybe that'll take three months. Then find a cloud service to run it,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ec3ef37a-9966-4414-bc83-ae003a371f52', embedding=None, metadata={'start': 522.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6161d376001fb436783fe1ae790a8ff57c76df6ebdf6d4fb8171648f36298b4c', text=\" make sure it's running robustly, make sure it's recognized, maybe that'll take another three\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='617d3dfc-02cd-4f7d-bb03-396e23861d10', embedding=None, metadata={'start': 525.9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fd287c9132f1c31f05df4cff79da998dae92e039386adf81a460ec3308cfaf28', text=' months. So a pretty realistic timeline for building a commercial great machine learning system', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='31ee0a9e-49bc-42f6-8893-6879a6d4a2b0', embedding=None, metadata={'start': 531.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1d95bd7bd15b8b559b6082b951a7badfd5b780be689cec3247f2fbe9220a9e8c', text=\" is like six to 12 months. So teams I've led will often talk roughly six to 12 months to build and\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4614c87d-df8e-438d-a95c-69111a66aa13', embedding=None, metadata={'start': 538.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cedccf16000896b5e11c77a19d10b03254c467a6d2f78b7ef99527e8afe8d3fc', text=' deploy these systems and some of them turned out to be really valuable, but this is a realistic', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7a446cb6-0c4f-4184-8d9e-1bd4339482f1', embedding=None, metadata={'start': 543.36}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dd61cd147b6e630aaa69b0b0b06b99e92f350c6f3a753d61877c9c4c4c949c01', text=' timeline for building and deploying a commercial great AI system. In contrast, with prompt-based AI,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b980e780-fbfd-491f-9dad-19616c376402', embedding=None, metadata={'start': 550.36}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='025a71cbf65a2d8155a721e9698d308b6256f3a384ca075b9f7bc7c61f49162e', text=' where you write a prompt, this is what the workflow looks like. You can specify a prompt that takes', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eea5b78b-2806-424b-a8f4-bf839f123353', embedding=None, metadata={'start': 556.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a6ba71d10d28dc7887a3831f129d38caf1abdd96e221a746d1b8a7e603388cc2', text=' maybe minutes or hours and then you can deploy it to the cloud and that takes maybe hours or days.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='83581065-d4fd-41e0-aa3e-d8fdc9013c14', embedding=None, metadata={'start': 563.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7032cd972035c48e7dd1a9dba70bf969c045ed8e9dd39ee71f5ad39b2e452e86', text=' So there are now certain AI applications that used to take me literally six months, maybe a year', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6897f430-13ec-43d3-a5f5-ac31d2bb51c0', embedding=None, metadata={'start': 569.92}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='23522e6e2fd848b0080b526bad12a02726d063f4b615553c2b4687eee8a6b6ec', text=' to build that many teams around the world can now build in maybe a week. And I think this is already', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eb5b8f52-8a53-4942-a8ed-f1497763a0af', embedding=None, metadata={'start': 576.04}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a199dacadf306f3f4bc1ad0871592023f4f8950b429885791bc2d0b786824506', text=' starting, but the best is still yet to come. This is starting to open up a flood of a lot more AI', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7f635b18-91d8-48c6-a903-b5f519ce3144', embedding=None, metadata={'start': 582.02}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5c0958b1e427804755029a3d7cecef4b053a95c5ce53de939a128880808375ac', text=' applications that can be built by a lot of people. So I think many people still underestimate the', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2ae26ecd-a990-49af-8769-0dc1bb40dee2', embedding=None, metadata={'start': 586.66}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fe7b67d6cda4bf6d00bc42a4d20a74ec494331f3778433c9e2f5f2a49b108f6c', text=' magnitude of the flood of custom AI applications that I think is going to come down the pipe.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a5d909d2-c6e9-4ee1-bdf8-22d023a845a3', embedding=None, metadata={'start': 592.7799999999999}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cb2d41f6f54df54f15c1604df32d0989c83509b8ceaa0795d244fd07c6ad1469', text=' Now I know you probably were not expecting me to write code in this presentation,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bc9a4fcd-e42b-4a7a-9057-e9b27c019ed4', embedding=None, metadata={'start': 598.6199999999999}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fba207bd32a194c0cd3c871b4ce91d5cab058afd54fa9f51a0c2f8d167ffc305', text=\" but that's what I'm going to do. So it turns out this is all the code I need\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9fbe0d97-a3d3-4e6e-a3a7-6d7c904e3972', embedding=None, metadata={'start': 606.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ce6a606453cbf577229f07c8b7be981533805492af2e0d347b6c1ffc96f0890a', text=\" in order to write a sentiment classifier. So I'm going to, you know, solve you with no Python,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='66c776cb-4b8e-4681-906b-6934433ddb8d', embedding=None, metadata={'start': 612.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='79b782bd2ecee480a5289e1be889a0ca854937fdadf5afa891c8cd90d560fa02', text=' I guess, import some tools from OpenAI. And then I have this prompt that says,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aebc79a5-3cf3-4199-9825-4e889dfa98ee', embedding=None, metadata={'start': 617.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e20942bb30c2ceccd8a06e09b6f0ae21b6a593d2799c1e365597b0a3e77c992d', text=' classified detects the low, delimited by three dashes, is having either a positive or negative', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cbc2be26-ec53-4c79-99dc-f6991d7409b5', embedding=None, metadata={'start': 623.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3075016a73a40d2562cb4ab955412a7a55f0cc3f409c0bed8bf4e82d81bdaa04', text=\" sentiments. I don't know. I'm a fantastic time Stanford GSB.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a21bb8d5-e51f-4788-8f17-fbf54784db42', embedding=None, metadata={'start': 636.24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b91f556c06e24bce3c271f7bbb79f87597e6087615f3f29fd386bac9c73ac0ea', text=\" I ran to a lot and also made great new friends. So that's my prompt.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a77af85b-7bd0-4356-9a8f-af7d7b27cd94', embedding=None, metadata={'start': 643.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6104bc052e280adfbe91f237a82b491d9c26b19c328ec68e1ff4504a72380a70', text=\" And now just I run it. And I've never run it before. So I really hope thank goodness we got\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c246d877-debd-4a26-ba8e-83831913cb0e', embedding=None, metadata={'start': 647.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5fe59e81d3ff477fc3a2bd2be9a7635c187eca1ab49070eb0b9768ec31c99326', text=' the right answer. And this is literally all the code that takes the build a sentiment classifier.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9194a0b0-b56c-4eb2-b1fd-5e0a585df3ff', embedding=None, metadata={'start': 657.48}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='575930920437852eb455845cd4ec74b483f82d84b5344cd9b93571c77e1ad611', text=' And so today, you know, developers around the world can take literally maybe like 10 minutes to', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='54470d38-34ab-4d32-9a66-ca5a4632d653', embedding=None, metadata={'start': 662.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3c23f6c22fc0c4f99c3780a25f1eb8855f3eec228ff3895bc61a9ed76559ca39', text=\" build a system like this. And that's a very exciting development. So one of the things I've been\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a5c7f1ba-6eeb-41c3-8184-0df359c63de5', embedding=None, metadata={'start': 676.08}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bd7e2c0b6f3b027fc2244446575ca5bdc062e0f9514e118e3dbae66b7e4f9038', text=' working on was trying to teach, you know, online classes about how to use prompting, not just as', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='79befc31-2874-4610-a452-228d9fdf4c34', embedding=None, metadata={'start': 682.88}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a3e972e0ca69af2558e0873d763e0add787760d2d536f3f1a50639c2de0dcebd', text=' a consumer tool, but as a developer to. So start off with the technology landscape. Let me now', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='306766bb-4ae9-4834-b581-4e89fc9f3b7b', embedding=None, metadata={'start': 689.88}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2f0c2f9842d463b565a6e34f1fdb71e2a44abda4bfc9085ff00d8f798dc030b0', text=' share my thoughts on what are some of the AI opportunities I see. This shows what I think is the', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6bd389a7-f232-4e23-a99d-cb92f957dbb9', embedding=None, metadata={'start': 696.98}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e95a080b8139d40e617c13a1d2ce279ffcdb09bdf25ee7b5baac847ce76c8f1c', text=\" value of different AI technologies today. I don't talk about three years from now. But the vast\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6e7ef957-c0b2-44d4-958f-5c6e33a3aa95', embedding=None, metadata={'start': 703.5}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d5e549ac2496877eb349bad744ff0e55cbbc365b037a30722651cd8aebdc6376', text=' majority of financial value from AI today is I think supervised learning where for a single company', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='237552f3-d993-4cf1-9191-851015f595c7', embedding=None, metadata={'start': 709.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ca41398c0c84e8a93763a21da8eb94dc9a646a92f325844aa913a1d6b5180ce1', text=' like Google can be worth more than $100 billion a year. And also there are millions of developers', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6b15c5ed-3abc-43fc-a5cf-6c6106a65d58', embedding=None, metadata={'start': 716.38}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='40e91e17a35a57ff2ee4e52ec89d0e8bbf79da3cf46bf4627af23ac602f883be', text=\" building supervised learning applications. So it's already massively valuable. And also with\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='737e4cc8-7c2a-4656-9389-ae81696dd625', embedding=None, metadata={'start': 721.66}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='af93462c10cf9b7a154afbd84f1e0a85650f4cf5e0535708fa587559a04a367f', text=' tremendous momentum behind it, just because of the sheer effort in, you know, finding applications', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b77b2cc2-5f88-462a-bd3d-05721c4ef004', embedding=None, metadata={'start': 726.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6eb9bdfe8eb0346537015af8e99843671921b7911f5a9be47cc278a61c57d7a3', text=' and building applications. And in Genose of AI is the really exciting new entrance, which is much', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dd496685-be34-40c9-b4ed-2b40eb7ee3da', embedding=None, metadata={'start': 732.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='06b75c1721bef009875f508883f1cfd0792164ddc80d953042057e1215adea97', text=\" smaller right now. And then there are the other tools that I'm including for completeness. We can,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4ccd1809-cd02-4dcd-9f80-1499a48395c7', embedding=None, metadata={'start': 737.24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='11f222ebc70fd586fe00ef7e0007d5d7e4791915d1957fe7ad6cc46886e04d6a', text=' the size of these circles represent the value today. This is what I think it might grow to in three years.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c08d092b-8c00-4cfe-a03e-29d929795295', embedding=None, metadata={'start': 744.54}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='80b1c3de3000e27aa458a4ad882c3fe1f310bc3a545b95e373b9d2ba2a7c9a20', text=' So supervised learning already really massive may double, say in the next three years, from', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cab4db74-ec7a-4976-8fce-f24f8c802e3c', embedding=None, metadata={'start': 750.5}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3263feab13db333a7e479b77d5310f4bb5fc2deb7d0d82249f3e88ea2c53269d', text=' truly massive to even more massive. And Genose of AI, which is much smaller today, I think will', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='30d59e4d-cdae-4f37-9731-4d9cfa4f874e', embedding=None, metadata={'start': 756.54}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0ff3d0951830f5f974d097e9b2d649c4e7a5e6ca61d5cc34c5afb0b7dec0d5af', text=' much more than double in the next three years because of the number of amount of developer', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5ef23f07-f3dd-4adc-8b3f-5812c4d771d0', embedding=None, metadata={'start': 760.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='042695503011bd2a0b2e0b968bf7be4cbfad9dda4f771f5b095aa5a376dabce5', text=' interest, the amount of venture capital investments, the number of large corporate', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='552e34a7-21aa-4d39-a7af-5986e2470567', embedding=None, metadata={'start': 764.82}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='32968b4aa91fd47a1289daf45affb3ae10441db5abe99d08e4a066fb39103ff1', text=' exploring applications. And I also just want to point out three years is a very short time horizon.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ebefab84-af05-496e-a12d-67a5d11a8fe4', embedding=None, metadata={'start': 770.26}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7d3bddf7f77f103d28b31eb14c8393610988b921f2cc3211f5b320c340bb1635', text=\" If it continues to compound anything near this rate, then in six years, you know, it'll be\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dadad1ee-1d0e-462f-b94c-1ef9fc2b2bd2', embedding=None, metadata={'start': 774.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='aef3b2efcad80a80fb7574bb6f5386b2f16c17db78afb000743583af57d7899b', text=' even faster larger. But just light shaded region in green or orange, that light shaded region', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4b3636ec-d90b-4530-b6c1-dd3b0f8918be', embedding=None, metadata={'start': 781.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='36489a48d75639f29396f25a5ca72db1784d681a5b39007d62795435811b1823', text=' is where the opportunities for either new startups or for large companies in companies to create', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aba7a325-4fc4-4a2e-81c8-a0b8132b9066', embedding=None, metadata={'start': 787.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5b24dab3ed161221067c356acf6e0dbfcdeb032803b3c6d3c247c3fb1a06cef2', text=' and to enjoy value capture. But one thing I hope you take away from this slide is that all of these', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='61e2d262-64b0-4008-9c99-178dc789a241', embedding=None, metadata={'start': 793.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8f18660901638950742917ec017a9ff6de38ca1118df84b76186087a258d733e', text=' technologies are general purpose technologies. So in the case of supervised learning, a lot of the work', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6939a453-650d-4b06-80ba-6627129a2021', embedding=None, metadata={'start': 798.92}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b0894c6e08ba294099b0d3f3d4e5f0d045edfb598a81dee97c292ad891d3b771', text=\" that had to be done over the last decade, but it's continuing for the next decade, is to identify\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='42e1ad9a-0dc4-42d9-a91f-9f73f7208e58', embedding=None, metadata={'start': 804.4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='964d4527666b146180127cd21af14273901801fa7ffcd8c7f3a08cf245c6b3ae', text=' and to execute on the concrete use cases. And that process is also kicking off for Genose of AI.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9a7e070d-8b2e-4934-b4ed-d0b957295f01', embedding=None, metadata={'start': 812.48}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5d0f0df1913603a80eaef003081d0c773dcbbf0e871a1b379304308026091519', text=' So for this part of the presentation, I hope you take away from it that general purpose', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='10d29319-1487-4ada-a6fb-be983c173e22', embedding=None, metadata={'start': 816.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4320438ad031e1853518ea8c8e3455bdbd13f3e3eabfc60cd7acfb7904b45420', text=' technologies are useful for many different tasks. A lot of value remains to be created using', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='18d39e01-fd03-4a06-ac67-072a942bdea2', embedding=None, metadata={'start': 820.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a240691394fe6e23aec0858f6a98f8858c7fe4768807806926b49a970f1a03eb', text=\" supervised learning. And even though we're nowhere near finishing figure out the exciting use\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5094bef-7ab6-4175-bf63-b0fbf555933e', embedding=None, metadata={'start': 825.56}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='073f6b9b3a35c9d09b71e8a7dfd3407ae0bb0c1d83566d88cd1df5247db4a177', text=\" cases of supervised learning, where there's other fantastic two of Genose of AI, which further\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8e28887d-f9f4-4c35-9abc-cc25e1c9b829', embedding=None, metadata={'start': 831.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ba42c34ec677997b9d7f8f78875ffb0929c9433147497197bae28c26b613f20c', text=' expands the set of things we can now do using AI. But one caveat, which is that there will be short', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d0c412fc-6828-4fa6-8641-10e96ece2fa9', embedding=None, metadata={'start': 837.82}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8bccf333c13254683014e1275c98021545e3741636f854e898101933cbea2784', text=\" term fads along the way. So I don't know if some of you might remember the app called Lenser.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5305394-846b-4a1c-a464-c2bedc592f9c', embedding=None, metadata={'start': 844.88}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8d8654874b1d61c48053d75176a56966148729724445063e287e9c8eebafef81', text=' This is the app that will let you upload pictures of yourself and then render a cool picture of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e5fe8094-ddfd-451d-b06d-6de80c057239', embedding=None, metadata={'start': 849.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b8cb2d898311564d849ad0266183a2b2537c2d2c40a311967aa450ae05ce70f8', text=' you as an astronaut or a scientist or something. And it was a good idea and people liked it. And', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='815119ee-d42b-46d9-b5cb-6120dd7b6e50', embedding=None, metadata={'start': 855.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ceb93f121a6dbe1794897f33fbe817bf86f40cd081ba1c90b18a5b9f78ab90f6', text=' Zeravius just took off like crazy like that through last December. And then it did that.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ec3fe610-66e1-4176-8553-6238b7d6b80f', embedding=None, metadata={'start': 861.48}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a4caeeb6e0b48cb0572bc915d3af93c50c249c112cb0c574ad2f3144de4a3a80', text=\" And that's because Lenser was, it was a good idea. People liked it. But it was a relatively thin\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d919f076-2caf-4ca0-bb82-17a7d78b93e5', embedding=None, metadata={'start': 867.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e88e5a9305eb5e27de641c3b684c5c5808232b86523d06f2b01f523d76def437', text=\" software layer on top of someone else's really powerful APIs. And so even though it was a\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6318f5da-caba-4235-8045-b1ec6c5565cf', embedding=None, metadata={'start': 874.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d1610bfa3ee94b55a3d167dc481a660346fd0ad5e4fd422b338f2945be7b85e6', text=' useful product, it was in a defensive all-business. And when I, when I think about, you know,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6074970b-0f0e-4682-b694-dc38a0ad8a7f', embedding=None, metadata={'start': 880.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4873754d372cd068054c264512c2d2499823aa81bae606f3680ed1d8df66d249', text=\" absolute Lenser, I'm actually reminded that when Steve Jobs gave us the iPhone,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9e20f138-50cf-4fcc-9811-91bfa231b108', embedding=None, metadata={'start': 886.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7d379d1b88b0f6784da2391512c1908247da932e33fb9e60239d936b7c84a0ea', text=' shortly after, someone wrote an app that I paid $1.199 for to do this, to turn on the LED,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='284c9db5-4780-4ae1-bc54-d53a604d98fb', embedding=None, metadata={'start': 894.52}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='899b3cbf5c460902072124ba85f64a02b026f2fbcbde5154c2cf8e699c76a174', text=' to turn the phone into flashlight. And that was also a good idea to write an app to turn on', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b721dc85-7426-4f52-9b9c-06f607feacf8', embedding=None, metadata={'start': 900.38}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8d3b8a0e1218efad8d3b866c03aa0ec11b1b9c4a899567974d1c5e0c4438f6a8', text=\" the LED light. But it also wasn't a defensible long term. It also didn't create very long term\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='98b72a76-8ae5-4ad9-ae6e-119268f6cb29', embedding=None, metadata={'start': 905.4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d57be5483a6c584c0a9b2408378f3787c68746e111f4b433fc30c0ea5d5fd7b9', text=' value because it was a easy replicated and underpriced and eventually incorporated into iOS.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='786f1a66-9a16-4fab-85a9-51d3bca550de', embedding=None, metadata={'start': 911.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='61fa90c6d7c90163fe2dc57c7f44e03efbc5ab9d24285df881b5fa6945895f96', text=' But with the rise of iOS, with the rise of iPhone, someone also figured out how to build things', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='66001505-e726-4bdf-bec4-4013cf641fad', embedding=None, metadata={'start': 916.9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e77962d7f117d3cd7aac1784fa9b15292150615a42601cbf57907c51dd1512be', text=' like Uber and Airbnb and Tinder, the very long term, very defensible businesses that created,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='725f4b08-9fa5-482e-8574-90a751395fcc', embedding=None, metadata={'start': 923.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bc586fb0496f08c9c05fca10f8b14df68f660be6728a7fa84096789543e86310', text=' you know, sustaining value. And I think with the rise of GENTAVI or the rise of new AI tools,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='33094153-0f98-4172-8680-6f43a674c976', embedding=None, metadata={'start': 929.92}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='72b7d681108b74fa067b1aa7745e391dde38ca106e8eda7d8c44b182756ae621', text=' I think what really, what excites me is the opportunity to create those really deep,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ba64eb14-908b-4f45-9c54-b375a2a2e99a', embedding=None, metadata={'start': 935.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c42e5b439e4b91e1a831ef2a84af87fa04f19311bf898c17d76cd6ec0cd5df44', text=' really hard applications that hopefully can create very long term value.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ad4856aa-53bd-440c-a866-dd5149265b91', embedding=None, metadata={'start': 942.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d63b4b8653faec7780b829b5bc93d518d3b09aae1bd90e2810612fb5bd32b863', text=\" So the first trend I want to share is AI's general purpose technology and a lot of work that\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2503a1bb-07cd-49a8-9cce-b9dfa3b53d16', embedding=None, metadata={'start': 946.4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1cd4a3cd249669f6880f0a1d14958151ff3b20a0934f7e32829c6054e6264147', text=' lies ahead of us is to find the very diverse use cases and to build them.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9d3e8918-0d01-4c49-88df-ce2dcfce568b', embedding=None, metadata={'start': 951.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bc58987f2333901ba27705bb6c335e0d7ce95cfa33c94e775334ce33900ced9c', text=\" There's a second trend I want to share with you, which relates to why AI is in more widely\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='68afd651-b512-46a0-8ebe-f4d63f3be78e', embedding=None, metadata={'start': 956.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a39dac9aabc4b0c397257468d1e6710e9a3010357ac96859aaaa276c75786c4d', text=' adopted yet. It feels like a bunch of us have been talking about AI for like 15 years or something.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fb8cd390-d5b5-4330-b015-b28d7c56b050', embedding=None, metadata={'start': 961.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='70a1b942daeb0ca0d39a2c5e1d716d8ce0807ef396cb1bbd219667744349b854', text=' But if you look at where the value of AI is today, a lot of it is still very concentrated in', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='898c7f34-d4a7-46ee-8150-f74f6acabb73', embedding=None, metadata={'start': 967.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8a11eb4a247edcb86d2915f81e9af4168924b50f7bd7f1a0c0198a2d8569da5a', text=' consumer software internet. Once you go outside, you know, tech or consumer software internet,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9fb4808c-85a6-4b84-b41f-7139c411d58a', embedding=None, metadata={'start': 972.04}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='96981fe540a7eff4a7b7b5fe484ed534fd9ef2b5e081e8125eea09791eebe119', text=\" there's some air adoption but the law feels very early. So why is that? It turns out if you were\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8b545e22-ad11-44bb-b51b-9a93e78bcb4d', embedding=None, metadata={'start': 979.08}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5a8db7180461ee9b6559a44ade6943f9cd424a5f1155d2d6996f922ac91b506d', text=' to take all current and potential AI projects and sort them in decreasing order of value,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='80f0233f-f29e-41fa-8c3a-c6f7a39bbaf1', embedding=None, metadata={'start': 984.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4cbf76c0833fc841abffe7039e7da58d87906daeab7cf3e39481e40d41a5b067', text=' then to the left of this curve, the head of this curve are the multi billion dollar projects like', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='210c4cbb-0f0a-4470-a23f-9094b0da4750', embedding=None, metadata={'start': 990.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5145df436ad3da05c73123ee6c420eb3538ef7760e1dff37c5a556331675ead2', text=' advertising or web search or for e-commerce, your product recommendations or company', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b8b361c8-1d1e-4d3b-81ba-adcf9ff27a5b', embedding=None, metadata={'start': 996.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c15bfb722307021828a15bf49f7c0bdcd20fdb147d858395e3fdc7cb81d20a43', text=' amazon. And it turns out that about 10, 15 years ago, you know, various of my friends and I,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dbd0bec8-3194-4e28-8940-a562bbf25224', embedding=None, metadata={'start': 1001.62}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='219443917ccb415997d565fe72639aeaa0a105e6d277e9998ba6236ef9a2fe65', text=' we figured out a recipe for how to hire say a hundred engineers to write one piece of software', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d55d45c5-c1ec-4fda-8ab6-1046cd5bd732', embedding=None, metadata={'start': 1007.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6913badd0cb9845351f1c70c28ca5a74bb7443ca1721817e23919c7c919c33f9', text=' to serve more relevant ads and apply that one piece of software to bid end users and generate', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='899e9b93-7cc5-4864-b3fb-aca85363f735', embedding=None, metadata={'start': 1012.98}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f1098d8db19bc6574e1e47b4e81465418fffb81d7b75d0462eb80c96fe4a52da', text=' massive financial values. So that works. But once you go outside, consumer software internet,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4ba08f52-b0d4-43f1-9a08-967ab3c69bbd', embedding=None, metadata={'start': 1019.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='793793737818837aacbc0feb34ce062d89960d34bd2745b34877f1f39000edbc', text=' hardly anyone has a hundred million or a billion users that you can write and apply one piece of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f8b85cf0-42e1-4713-90a2-ef8500342cc4', embedding=None, metadata={'start': 1025.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c170bcfe51b1df69e1b7e7f3faed7f618f8fcbd24e7dc75db1cb69f54770f778', text=' software to you. So once you go to other industries, as we go from the head of this curve on the left', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7fa9d22a-8f67-4b10-8c24-6b6758486473', embedding=None, metadata={'start': 1032.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8f6b45d3a544751b1b3175aae526a73cb73e4bfcda7799aa67fd9d9b63438fd5', text=\" over to the long tail, these are some of the projects I see and I'm excited about. I was working\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ad4cf25a-a10b-42ab-b72f-19b9f77afe06', embedding=None, metadata={'start': 1038.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3db3e9f36d4f8d3d7befb2884e2d99e47d41892df59dc699751b5cfec1429b9b', text=' with a piece of maker that was taking pictures of the pizza they were making because they needed to', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cfbff6ea-b4a3-429b-acad-e98129eb9039', embedding=None, metadata={'start': 1044.98}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='01b2f283e0a240c81acb47eff1e803cb2626a8126dc6e952a1bbb138c712126c', text=' do things like make sure that the cheese is spread evenly. So this is about a five million dollar project.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a7bce85a-3c26-4e17-b7cf-4dda0123e756', embedding=None, metadata={'start': 1051.04}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d59c5b34d1e3edf5de277d175fa2dc7a4a8ad82dc23baec511fe64f792b462b8', text=' But that recipe of hiring a hundred engineers or dozens of engineers to work on a five million', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='83277998-9eaa-4f6c-87a7-c8cc2120eca6', embedding=None, metadata={'start': 1057.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='30b702caa89a4d3619bf9f37bcc735b4a5eed1bd89b532fd510015726d21fd3f', text=\" dollar project, that doesn't make sense. Or another very example, working with an agricultural company\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9b181543-f011-474e-8a3c-6cca6d43837b', embedding=None, metadata={'start': 1064.98}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3be62aa597d3cea30ab19c35176cf259215d7272c4c98fa68568fd4714a8a172', text=' that, well, then we figured out that we used cameras to find out how tall is the wheat and wheat is', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='13f913c0-f2f3-4030-9b00-d937c679422a', embedding=None, metadata={'start': 1070.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2c5bd07d3d7abbb2b0fb6f3788a32ca2d5a1d8bcb9bc179d3547526ac729f143', text=' often bento because of the wind or rain or something. And we can chop off the wheat at the right', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='77b78b69-ba94-4be4-ba22-1ee0949710b5', embedding=None, metadata={'start': 1074.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='72dc6cd631da0a522f5eaa918d922bd2e83c39f0fe0c439dc4601006c5071b34', text=' height. Then that results in more food for the farmer to sell and is also better for the environment.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fb9037be-00a2-412b-aa11-af1191e989a9', embedding=None, metadata={'start': 1080.24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='db57266ce6db310c45b66a65e6111bc22616497a3eb04c347d5c9bf8dd176f84', text=' But this is another five million dollar project that that old recipe of having a large group of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c85cc690-0034-4299-a78c-86cbb7030adb', embedding=None, metadata={'start': 1086.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='24d2c841479eae79eb99a2a4e0aadfce18b11c9c27211fa98648b7f7bf344578', text=\" high school engineers to work on this one project that doesn't make sense. And similarly materials\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cdb9f646-11cb-4eaa-b91e-3c9de4e67e63', embedding=None, metadata={'start': 1091.4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cb53266c6a81ed33e5f171dfb74b03ed3a0ee62dbb75d90a3e5a9f1569f6ea8a', text=' grading, cloth grading, sheet metal grading, many project like this. So whereas to the left in the', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1a01afb7-0bcb-4074-bb33-73e167a37812', embedding=None, metadata={'start': 1097.02}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='83f5ff0b828b4bcd64613db73d3fbcdb573f5aab338150c5b2f6b8f6658862aa', text=\" head of this curve, there's a small number of, let's say, multi-billion dollar projects. And we\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='090cb5f6-79c8-4e6c-9700-d062aab2ac23', embedding=None, metadata={'start': 1102.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='428aa03cba8bbe1a5be54f3e46f1a8199ee009035d25acd1c296cfe977513654', text=\" know how to execute those, you know, still ring value. In other industries, I'm seeing a very long\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='765f8cd4-3b1f-44cc-8005-dcb252371a52', embedding=None, metadata={'start': 1107.94}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2438bdfbb5d4444dea07cd020eee14adfabb47e8191202d32ca5c43fbe116ab5', text=\" tail of tens of thousands of, let's call them five million dollar projects that until now have been\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='94370a89-8997-49a3-8a29-7d31e36e9b2c', embedding=None, metadata={'start': 1114.28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7d96dda31606b2e6087f7ff0a1c32e17e394d13afc9558b6e834e1898d55cdb7', text=' very difficult to execute on because of the high cost of customization. The trend that I think', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='734374c8-d18a-4caf-9988-3195ef6e34ac', embedding=None, metadata={'start': 1119.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='15ecd5c98b711602d331c21589cf7318119a53973ba6782d1e889b0450d2132e', text=' is exciting is that the AI community has been building better tools that lets us aggregate these', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b2c75dcf-c97c-4ae5-8ead-bf9208aa6afd', embedding=None, metadata={'start': 1125.62}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fb63106eeb9e14b7bd3e0f0ca7f9601734cf13c47a85e0de4707579092ecd32e', text=\" use cases and make it easy for the end user to do the customization. So specifically, I'm seeing a\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6e7c3d68-1929-428d-b9a9-6f7ced40e150', embedding=None, metadata={'start': 1131.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='eedc15f981d241b8c3a35b89f05372bfeec4db6dd9449647629f81507d4b2862', text=' lot of exciting low code and no code tools that enable the user to customize the AI system. What', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9ff5b95e-88d2-43ed-916d-8e31b7277dd6', embedding=None, metadata={'start': 1138.98}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bb04251d0a809da213d3e3b185c980aa015322b3fef57dd07161282e838b11a8', text=' does mean is this instead of me needing to worry that much about pictures of pizza, we have tools,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='84c28837-1756-4639-a872-b93413158bdd', embedding=None, metadata={'start': 1145.36}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='48f8df5ec8b95474c3b388b011586b612cff57eb65f476800c66a9593ad56274', text=' we can start into C tools that can enable the IT department of the pizza making factory to train', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fc7f57af-8d90-458f-bdae-b572aac3c392', embedding=None, metadata={'start': 1151.52}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e89faf83e92b502707da0a0aee126473186c0fd835f22cff5093ed07395d223c', text=' AI system on their own pictures of pizza to realize this five million dollars worth of value.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3926fca2-aaa2-4d62-a3cf-26e6eab074ab', embedding=None, metadata={'start': 1156.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3eaa64e0b1aa4639f19a27556f59b2575b3d8cdc6355b204eb5163d237e46f84', text=\" And by the way, the pictures of pizza, you know, they don't exist on the internet. So Google and\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9f58f9dd-2e3d-4077-b48e-718d4dcc8255', embedding=None, metadata={'start': 1161.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='602d456d4c5d234fd041c05eb104e9d2070ce7eb8e935e2c26e9088d2ab80841', text=\" Bing don't have access to these pictures. We need tools that can be used by really the pizza factory\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='555f4922-1bdf-4766-8b8e-51e825f244b4', embedding=None, metadata={'start': 1166.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1c31abd3d4767cac952a8c88c26a304c06d6b34c4ef4f492a30114cd09705af6', text=' themselves to build and deploy and maintain their own custom AI system that works on their own', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9191661c-4952-462b-8fd5-a45bcb3fe5ac', embedding=None, metadata={'start': 1172.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9f55bef5943dd01e86602f1a5863a9b604b60a1a171c8d2d7b3f64e0a467184f', text=' pictures of pizza. And broadly, the technology for enabling this, some of it is prompting, text prompting,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c443bba-7824-4d91-ab38-7d7acc3013a4', embedding=None, metadata={'start': 1181.56}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a6eff77db24fd728b565e03cb200d6f12746df73c6948acf43dc98ecfb0a6d81', text=' visual prompting, but really large language models and similar tools like that. Or a technology', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a673cd25-342e-4878-924f-7be4ba7767f7', embedding=None, metadata={'start': 1187.12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0f9d41a2aa3cc00ba6a186635b290b51c7f4b0d13b005bf89368127f35b74f6a', text=' called data centric AI whereby instead of asking the pizza factory to write a lot of code,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='29b8495b-3704-413d-962a-cf23be1faf86', embedding=None, metadata={'start': 1194.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='db110db56823e92f7a453f06ed14164f3952101c524e5caad45c037ba66be00a', text=' you know, which is challenging, we can ask them to provide data which turns out to be more feasible.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5d7f9e9f-519b-4fed-8a72-d79cc77be7f8', embedding=None, metadata={'start': 1201.6799999999998}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='aaa4d170ca2d2b5d4be4f41071256c63e5ece6bfb52de0aebc012f42cbbb49be', text=' And I think the second trend is important because I think this is a key part of the recipe for', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2afdd596-f4d8-488b-80f6-ad5653011af7', embedding=None, metadata={'start': 1206.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d909f8c5f28b3c6a10cd10070c92cf19c381d1541fce3cf71d4289d4a3258769', text=' taking the value of AI, which so far still feels very concentrated in the tech world and', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='11985239-2002-40af-956d-20a8b3f35b2b', embedding=None, metadata={'start': 1211.36}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6ba0959d501d9aac3679f6c854976086817fb0028ae3bd20b9729c6b9dd0e43e', text=' consume the software into that world and pushing this out to, you know, all industries really to', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='89ce0a63-e497-4eef-b867-c0ede0a28c24', embedding=None, metadata={'start': 1216.12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ac4788c7a56442aea6322f36e46f76a4975d04ddbce38cda81ac9a0ed17d70df', text=\" the rest of the economy, which, you know, sometimes it's easy to forget. The rest of the economy is\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='27dcc905-a82a-4486-addf-a29a5ac52f13', embedding=None, metadata={'start': 1220.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cf5ca4f5fce3c8181341e0f3ef9c9672fbdbd56c070862206ccb3e57b7f57e43', text=' much bigger than the tech world. So, the two trends I shared, AI is a general purpose technology,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8298f37d-43ff-4289-845a-a2ffd773422d', embedding=None, metadata={'start': 1228.12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='72d47a342cb5ec80e77ef996641a07b9cd136e4b3e8ba01e75ea08f28eda150b', text=' lots of concrete use cases to be realized as well as local, no code, easy to use tools,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d2a4ffaf-e840-4f7a-9fdd-49eb15dcc27d', embedding=None, metadata={'start': 1234.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e211f2442b2fdacb8fbefbd4d4f073ac9a1b4dd4450c932a9efdbee916bcb43c', text=' enabling AI to be deployed in more industries. How do we go after these opportunities?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='53c9d179-fc2f-4445-a82b-c9e8ef8d5696', embedding=None, metadata={'start': 1241.44}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0e4995ae8ca7f5b2da134decc9a2d7ec699b8d915de0258c5e933d154c0c69d0', text=' So, about five years ago, there was a puzzle I wanted to solve, which is I felt that many valuable', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eb218693-44d8-44e8-a25c-caa892a795a7', embedding=None, metadata={'start': 1246.08}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f5fd8b4e5b3e566d218709f42385816eac77abdbb5a7e640b4c2ba7cfdfcabb3', text=' AI projects are now possible. I was thinking how do we get them done? And having led AI teams in,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d9947ca9-9eb0-4b16-bbe6-44c6c8671be5', embedding=None, metadata={'start': 1252.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8c06216cd474e87b3491ccf894034fb6e882d016ed3e4022bdf21a06869a2843', text=' you know, Google and buy do in big tech companies, I had a hard time figuring out how I could operate', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='254defd7-6f74-44d3-9d78-652915cb685c', embedding=None, metadata={'start': 1258.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2eda2493277224db8691695b4e1ca95c81066df16bce7d7614b7b1a08741e708', text=' a team in a big tech company to go off. There are a very diverse set of opportunities and everything', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='908e3abc-6cc2-471e-a613-cd113cd70dda', embedding=None, metadata={'start': 1264.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3ca8f38e35c237d38aab4ad008860ad1682fcfbdaef57d311bbcfd54b84da2a7', text=\" from maritime shipping to education to financial services to healthcare and all and all. It's just\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7d8df7dc-2152-488e-9892-375bdd03f653', embedding=None, metadata={'start': 1269.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ba8b540927d9203cebf4613dfac8a09e1f1a256b46359f49cec4570d00cd0e6a', text=' very diverse use cases, very diverse, go to markets, very diverse, really, you know, customer', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e8af54ef-1ff6-4284-b983-727d5264c772', embedding=None, metadata={'start': 1275.02}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='34bcfb63f78c4bea524f0c966fb87673eb7650b1948a94aad100e3baff5eb52f', text=' bases and applications. And I felt that the most efficient way to do this would be we can start a', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='66ef60ff-1422-4bd4-8787-0f6abfc6d7ba', embedding=None, metadata={'start': 1282.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e52f43f929e26bd35bf9d84b9f7e2ab70a0dfe6a29a42eb2417ebb9ce7cd1d54', text=\" lot of different companies to pursue these very diverse opportunities. So, that's why I ended up\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='736fe2a6-94d0-4668-bed7-a93eb3b43a49', embedding=None, metadata={'start': 1288.04}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2364bacb7a84b9ea914bf1529a54d53b3449b224f7bd008a9458d7397fc674a6', text=' starting AI fun, which is a venture studio that built startups to pursue a diverse set of AI', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b2feda43-dc88-49f9-ae00-c6a456396970', embedding=None, metadata={'start': 1293.4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='85cf332dd38bf0a17b296d17d7fc1b362ae29bf23003b9f95c70de2e62076c6f', text=' opportunities. And of course, in addition to lots of startups in company companies, also have a', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='79588897-d57d-4b4d-a9ad-d5269403b40d', embedding=None, metadata={'start': 1305.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='53d9060b11cedd7a17a7199f3049439494d4c238e29dd8cf7d1373e88eeef6d0', text=' scene for incumbent businesses is distribution is often one of the cyclical advantages of incumbent', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8b06a3df-27f0-4a70-b279-7abf78dfbada', embedding=None, metadata={'start': 1313.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bbdbabfee29de811aeafe195d98c92ec9458bb699edbe31d71b29c3e54108a65', text=' companies that they play the cards right can allow them to integrate AI into into their products', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='72e1439c-098f-4caf-a88f-d8e602ee7a75', embedding=None, metadata={'start': 1318.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6774c5932589603412106b8c203ec958225555b8ad1269c7a06703365dcc7f66', text=' quite efficiently. But just to be concrete, where are the opportunities? So, I think of this as a,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9b94a1da-e6ea-46f2-81d2-5f112a4abb20', embedding=None, metadata={'start': 1323.66}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c0fe665127c26c544d732195fa79fcc45dfaaeebda1524042b213a7f06ab5745', text=' this is what I think of as the AI stack. At the bottom level is the hardware semiconductor layer.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b83adca0-827d-4528-88fe-1c6f632fdb35', embedding=None, metadata={'start': 1329.4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ea4aa6211adb744fa1d215c6581d701b71b9731a94ac0bc6e6321f7ed5d6ce8c', text=' Fantastic opportunities there, but very capital intensive, very concentrated. So, these are a lot', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e88b8044-57a5-44d1-bf86-90d1757f9241', embedding=None, metadata={'start': 1335.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1a0b9460ea46c9bbb7c5028a77027e78bc6717e1ff21259d275e409ef6d75bb8', text=\" resources, relatively few winners. So, some people can and should play there. I personally don't like to\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6f03adfd-5aa5-476d-909a-7fd6480e844a', embedding=None, metadata={'start': 1339.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f2a925c65060e7fe3ac85442528a7da4bd33c5ac5bfa74731f4386799eb2da0c', text=\" play them myself. There's also the infrastructure layer. Also, fantastic opportunities, but very\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cbec3df9-68f8-4bba-82ae-201c372c945c', embedding=None, metadata={'start': 1345.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ced1896974f7fc1d8c1903f0feabd63c1e3d071a9e7bc09f4827c558c38e8141', text=\" capital intensive, very concentrated. So, I tend not to play them myself either. And then there's\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='07f54cf9-87e1-4fb0-b9d0-ba50ed7aeb57', embedding=None, metadata={'start': 1351.54}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d173d71c4dcfbadc82f7211cf9379ac6eb2b6d1e881bdfc997e945a15df32aa8', text=\" a developer tool layer. What I showed you just now was I was actually using OpenAI's API as a\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9db38ca0-c581-4fba-972a-ec0f1c444114', embedding=None, metadata={'start': 1357.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c49a5ec30f1d834ac148dbbf415263bd4bc0da1b64eea3d5c25363fb001dfd61', text=' developer tool. And then I think the developer tool sector is a hyper competitive. Look at all the', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3b7efbd5-2d65-4e4c-8f22-8f9a097464aa', embedding=None, metadata={'start': 1364.24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e44266958d68b58dd629e36962a799b91d02ff86f286736076d2934e9a69cb40', text=' startups chasing OpenAI right now. But there will be some mega winners. And so I sometimes play here,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f194f231-f7af-4652-9309-f83f69c17659', embedding=None, metadata={'start': 1371.26}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dee738175afb1308e343347ea4e91badfbcd40a1b9849c7c4db1a05974555652', text=' but primarily when I think of a meaningful technology advantage, because I think that earns you', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='94d1821f-6717-4a68-8b6e-23b0495711ab', embedding=None, metadata={'start': 1376.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='979514c2a60b48bfa670bdbc2c32adec9c674406d2cb76c2fae109d1e5efabfe', text=' the right or earns you a better shot at being one of the mega winners. And then lastly, even though', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='07744eb2-931d-4852-a46e-682d40d8ef28', embedding=None, metadata={'start': 1382.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c8160fc77b9c945af6c6c6240a85b0fe1252b194cd43cfb3f032a0645ce793fe', text=' a lot of the media attention in the buzz is in the infrastructure and developer tooling layer, it turns', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d209ec0f-632a-40c7-b742-e914604c405b', embedding=None, metadata={'start': 1388.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='af4bb29b6e8f8ba88f0b30bedb327fb24e2578e99c793f56df32dd79f3630dd9', text=' out that that layer can be successful only if the application layer is even more successful. And we', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e37a3151-7949-49ec-b663-c5852b9b45e8', embedding=None, metadata={'start': 1395.98}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='65f1cc61f4478156fba976db751540dcb2b35640d22a92b1092c6a74bf70967d', text=' saw this with the rise of SaaS as well. A lot of the buzz excitement is on the technology, the tooling', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dffd6336-a619-450d-a3dc-ad8631c39a22', embedding=None, metadata={'start': 1401.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f0be3972d1112292cec4d8aba237d0fd8f7297194696f857ff821d1a41166a0f', text=' layer, which is fine, nothing wrong with that. But the only way for that to be successful is that', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4fd6b991-bdda-4f0a-9ff6-ccb135d6b342', embedding=None, metadata={'start': 1405.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='168fbe245c8a9614579687d67d14f1c47fcdc23a45f9033a21c01fdedf01473e', text=' the application layer is even more successful so that frankly, they can generate enough revenue', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='be570859-1199-4df7-9730-a52e29ae0f51', embedding=None, metadata={'start': 1409.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a128dad0cb5c8cba64f83ab0f29bdba07e85cf0c02958f2d118c5977996bec84', text=' to pay the infrastructure and the tooling layer. So actually, let me mention one example.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2f8a043f-4577-4a39-94ce-4aeed57ca004', embedding=None, metadata={'start': 1416.7600000000002}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9e733c689aacc1991e5942aa0a352b84ba8160f51df39df7d1719489de2dbaeb', text=' ArmorRy is actually just texting the CEO yesterday, but ArmorRy is a complete rebuild that', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='19b07fe4-b644-4134-a03e-64e6dd82dbec', embedding=None, metadata={'start': 1422.94}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='45bf4519fb77a7f1bf48526959b963520eff100102420efd7ac3d18b4211b06a', text=\" uses AI for romantic relationship coaching. And just to point out I'm an AI guy and I feel like I know\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='059154fd-36cb-447f-8c73-19cd7a7a3905', embedding=None, metadata={'start': 1432.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0d70c908b9eeeba759eea633291757066a3f0f38a9627b70818f837d469d32bf', text=\" nothing really about romance. And if you don't believe me, you can ask my wife, she will confirm that\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5a72b9c4-6d30-4603-9937-b2888aeee585', embedding=None, metadata={'start': 1441.08}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6bcae211e3f7e4a3a1101b0c9ff59baadcb06dd4e9939cebadeec1f5b86a6064', text=' I know nothing about romance. But when we want to build this, we want to get together with the', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9e68367b-4aaf-4c11-8637-ba3248c4913b', embedding=None, metadata={'start': 1447.14}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6e6fd039bb54d7058a0e29a419c837d462fa96ec25739c7c5f0468c42857e042', text=\" former CEO of Tinder, a Renata Nibble, and with my team's expertise in AI and her expertise in\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c7d4ca9b-146d-4a68-bacb-8e1668cd25e5', embedding=None, metadata={'start': 1454.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dc79593e902ebb676ad3ab8e1a4efb92c936a15fd38c94c0f1b9837c742b2129', text=' relationships. She ran Tinder. She knows more about relationships. I think anyone I know,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='efc3b1f3-8dae-4bbb-90f4-7149315fafa0', embedding=None, metadata={'start': 1458.72}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b291aeea1d08012a7345e9a4448d750fa4a5082058b9801a8c9fba743241d47d', text=\" we're able to build something pretty unique using AI for romantic relationship mentoring.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='944115cd-ac86-4c80-a8c7-fa6ec535a51d', embedding=None, metadata={'start': 1466.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='08e26d204c0ee04e4442b94328b719cf5c2d1e1902c9a4f71d2964b1476dccc3', text=' And the interesting thing about applications like these is when we look around,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a0d4ceec-2de1-476a-8dda-1970f4e6e625', embedding=None, metadata={'start': 1471.08}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0d0ae8c15964a8574cee0b40dda0d98864c39e7e455e7219ac631e60c1a27d66', text=' how many teams in the world are simultaneously expert in AI and in relationships.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eebe9697-d1d0-44fe-81fb-158ba4dfbeb6', embedding=None, metadata={'start': 1477.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='dfca48705af35179227ae8dae4e4275ca13332e54b4434f3b5537740929f92b6', text=\" And so at the application layer, I'm seeing a lot of exciting opportunities that seem to\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd9b7234-d054-4598-b0f7-df2778e41bbc', embedding=None, metadata={'start': 1482.56}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3536350bc397f904d68d4cdc183e0503f45718684d170d77949432157fe0bd85', text=' the very large market, but where the competition set is very light relative to the magnitude of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ba4041d2-9cde-44f0-8f85-20b63b499982', embedding=None, metadata={'start': 1488.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1717a59550a8fc4cc604e9d139d7ac2f8d1b518b81e2b06e2da3dc3ea752348e', text=\" the opportunity. It's not that there are no competitors, but it's just much less intense compared to\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6c2a3e11-ca8a-40dc-8aa3-11575f6c93ad', embedding=None, metadata={'start': 1493.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c00f68a9f6b53164877e312b3685712eb931c4f9a15ebcc153a97646a5e24ac8', text=\" the developer tool or the infrastructure layer. And so because I've spent a lot of time iterating\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='43aa7497-fce6-4c56-ac42-9a2fab9f6ccf', embedding=None, metadata={'start': 1500.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5bebf59b038e30c71f9ab9811a749a3890940c3d8b396e3a6a958f9c032c919b', text=\" on a process of building startups, what I'm going to do is just very transparently tell you\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6ab65746-71f0-44b7-b44d-11dddd989d60', embedding=None, metadata={'start': 1505.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='db791b3717a4b0d77173f4f431641d7df205830e0b0831d0a74a5199c0ace2a5', text=\" the recipe we've developed for building startups. And so after many years of iteration and improvement,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c99fd2c1-7a2e-497c-b050-2f4fc8ab50df', embedding=None, metadata={'start': 1511.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4ec6501f3c31c768703a30c642f8eba405304df4d1bf7e09070a524ab4ebe695', text=\" this is how we now build startups. My team's always had access to a lot of different ideas,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c439be62-7d50-4b2a-9b43-8241878ca368', embedding=None, metadata={'start': 1516.94}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='367a66f37b1aab61589d5d41932dad9f0aff840aa9906b6d942abab9aeb3696e', text=' internally generated ideas from partners. And I want to walk through this with one example', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='852f70c0-9e5c-4224-a863-06611795f451', embedding=None, metadata={'start': 1522.68}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bb1afd497564edf7b9938b24b647f9605f37eca37ab70e741090740c9e90e63e', text=' of something we did, which is a company bearing AI, which uses AI to make ships more fuel efficient.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c0faed19-3914-4595-af02-3c8d9f89345d', embedding=None, metadata={'start': 1528.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a4bdb390a99cc084d31244561c15ffeb1f3c5352e24fbc3e0574ad6632ba1bff', text=' So this idea came to me when a few years ago, a large Japanese conglomerate called Mitsui,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='df90864f-8f61-4689-87b2-d43678b4d590', embedding=None, metadata={'start': 1535.66}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='591092d51b5ca657dbaf8d1d68fd803e4cdafc364acc462cc1c60d10634d6a3a', text=' that is a major shareholder in the sort of operator major shipping lines. They came to me and', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0d7bc2ef-3217-40a4-ab4e-162342a24162', embedding=None, metadata={'start': 1540.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='81e5638bfb13cac28e022affc09b97fd18c3f5c55501f5342183d625c2ed04dd', text=' they said, hey, Andrew, you should build a business to use AI to make ships more fuel efficient.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='72096e88-3225-42eb-8b2c-2c2ae1560656', embedding=None, metadata={'start': 1546.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bb2d9e04c42d27d64aaca015e072dec44d950fdba22c7a66d1723fede435d3d9', text=' And the specific idea was, think of it as a Google Maps for ships. We can suggest a ship or', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1834b24b-e69c-4f80-91b3-f2d61a870dd1', embedding=None, metadata={'start': 1552.12}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='be836c5ef16f73b2ade5a55d222134e6d41b0c8c6df3e30790fba655a340ae9e', text=' tell a ship how to steer so that you still get to your destination on time, but using turns out', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='369e7b82-15d5-4711-89e0-041ec3a4d7a6', embedding=None, metadata={'start': 1557.82}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2e1582cc7296dd329ea25f95bdf3cb50a8aaf1697ecfa9525b28410b15ed8757', text=' about 10% less fuel. And so what we now do is we spend about a month validating the idea. So', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='87cebbde-e5ae-48e2-941f-41c33d5aa93d', embedding=None, metadata={'start': 1565.74}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='36c4c66260b5e5608c5d6c45dbd2316014776e5574cbdb9b439dc2bd58961d5d', text=' double check, this is idea even technically feasible and in top to perspective customers to', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='45021c6f-ac58-48b9-9583-c9c1caae9518', embedding=None, metadata={'start': 1570.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1bf0e30f9e68c2211dafd7eecc61cb1c92fec6e185ab59c63dea81707a4b459d', text=\" make sure that it's marketing. So it's been up to about a month doing that. And if it passes this\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8fdb3cda-b077-4e9e-a111-50149a773bab', embedding=None, metadata={'start': 1575.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='03acc76d957dfb45efa46c7ec9a87f0da22ea7e5cceaa163840979be069062cb', text=' stage, then we will go and recruit a CEO to work with us on the project. When I was starting,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a9248ed6-6d0c-4195-9f56-aa242cc25c45', embedding=None, metadata={'start': 1581.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='46bb9085480b5c3a0293fbff1bb11b5ef5e928ed9f43339e5ca9e7fa8088ab24', text=' I used to spend a long time working on the project myself before bringing on the CEO, but after', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='80bfd4c6-f20a-45f7-b7b0-5efef6a2c548', embedding=None, metadata={'start': 1586.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='05a15db6a648408917879d3ea46f234a36c5db51c322abcc65d622cb46754274', text=' iterating, we realized that bringing on the leader at the very beginning to work with us,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3de9451b-09b0-4979-8999-ac8e1e16ed19', embedding=None, metadata={'start': 1591.5}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='33615e472578bdcf550b11c9c602cc05a19e36f52796568344277346ea1da8aa', text=' it reduces the burden of having to transfer knowledge or having a CEO come in and', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='21531bec-e41a-48d8-a780-80e70646d783', embedding=None, metadata={'start': 1596.6}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='88b47b03de587783dd43e7c2c8b7f3f472638a6c838e71ecfa0389c16f01775e', text=\" have to revalidate whether we discover it. So the process is we've learned much more efficient,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='aa5fef36-3083-4076-8f01-f66da6910457', embedding=None, metadata={'start': 1601.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c6a50787fbd65bf98bf2dd063882a947189e730ac9fefda979d619c794fc9120', text=' which is bringing the leader at the very start. And so in the case of bearing AI, we found a fantastic', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='93891e4e-6369-47bf-ad36-f09d69a7d47d', embedding=None, metadata={'start': 1607.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7044fcb66ea611812326dc020b8bb5db6650967ddcf6c3506ac3124b3a9e6a66', text=\" CEO, Dylan Kyle, who's repeat entrepreneur, one successful ex-report for. And then we spent three\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a446e2a3-acc0-4608-8678-f5e1271cf8d9', embedding=None, metadata={'start': 1612.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2f0b667e4b6c4707171970350bfea4ab0e07ee93bb65e068fd0aa141595fa6c9', text=' months, six two weeks sprints to work with them to build a prototype as well as do do deep customer', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a960e573-902d-4520-ba5f-faae419a38ac', embedding=None, metadata={'start': 1620.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cbeb58468f81718abeb9c617c1dfcfb422750a12079775f64ebf2a158da8afa0', text=' validation. If it survives this stage and we have about a two thirds, 66 percent survival rate,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='53b7eb24-7d7d-4801-8557-1ece52cbf567', embedding=None, metadata={'start': 1627.14}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a1d6520fe7e442b215c0df0829c23e0a6a29e0956823f02e0a432d175af8fdb8', text=' we never had the first check in, which then gives the company resources to hire an executive team,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1676bd7b-0eb1-40f5-8e2f-570aeefce602', embedding=None, metadata={'start': 1632.74}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='33e806f44b976ebb6c0545dbd33c731844c5fd27acbbe8c62e425b65f2538720', text=' you know, build the key team, get the MVP working, minimize our product working, and get some', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd78c144-4777-4d2a-af20-0d2a05697533', embedding=None, metadata={'start': 1637.5}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e842cdb82aab4238bd9edc48c408b5f604eab920775ac5431beed648a45aef62', text=' real customers. And then after that, you know, hopefully then successfully raises additional', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6fd30dbf-cdbc-4a6e-8b36-4bda360da35d', embedding=None, metadata={'start': 1642.68}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='054a6f09838097fccdbc48fee07387e03e50cf4094743eb30567682f1043b7fe', text=\" external rounds of funding that can keep on growing and scaling. So I'm really proud of the work\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='89a0f2ba-4ec4-4f0f-8564-83aa2f242a07', embedding=None, metadata={'start': 1648.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='51da387acbcf4795093420086a2516e8b0920ede4ad44d0e511e40e83fc52ee6', text=\" that my team was able to do to support Mitsui's idea and Dylan Kyle as CEO. And today there are\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2c14e217-a943-4ecc-a463-ec4004676484', embedding=None, metadata={'start': 1655.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='da87d15a70215221b9bcb8c305aaa0527480f0f1f6afcb0c5ac73cfe6757157d', text=' hundreds of ships on the high seas right now that are steering themselves differently because of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='40edd234-d1c7-4bca-adb0-e97fafcd6124', embedding=None, metadata={'start': 1660.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6892f6b9a61ada9b6b1f32028c8f5a6516706e43f1f61ac0132fe915d0954a2b', text=' bearing AI. And 10 percent fuel savings translates to rough order amounts to maybe $450,000 in savings', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='674d49da-0817-40e9-98ba-4a3382930a63', embedding=None, metadata={'start': 1668.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a698b5863476f0da2afe3ba9d3db1f71f61ed6c7572710a6008dc9e009ab5a5c', text=\" in fuel per year. And of course, it's also frankly quite a bit better for the environment. And I think\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='140bbf08-ec3a-4302-945a-b2be568b91e8', embedding=None, metadata={'start': 1674.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='408cf08405446a504398021b269422aa3ffaac0715cdf76f2181f3e23332311d', text=\" this is not up, I think would not have existed if not for Dylan's fantastic work. And then also,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='33a5fc8c-7576-46c5-a4b8-b65c87ffbd74', embedding=None, metadata={'start': 1681.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='742c063eea9071a0b3642e3716270314f026617dc42d50d4fdb92bea24cba966', text=' you know, Mitsui brainless idea to me. And I like this example because this is another one is like,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7c1a02b8-7688-4629-8648-b520a82025e8', embedding=None, metadata={'start': 1688.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b8ccfcf200cf1dd6c81cbc9491a3903529fbf0b7d27564d95a13f68af422bb7e', text=' you know, this is a thought of idea that just a point out I would never have come up with myself,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b74f1463-98d6-4848-9214-40c89173f113', embedding=None, metadata={'start': 1693.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8bacaf67990e70dbfca852309ad5d0cb17be9e896f36744502de9899d37635d2', text=\" right? Because, you know, I've been on a boat, but what do I know about maritime shipping?\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd148d94-1285-47dc-b4f2-bdcd2d1c1f42', embedding=None, metadata={'start': 1699.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ce8f3e17e4adbe0e6c83ba04a5087e82c02f0f26501f8a6acdc6e4263456a1cd', text=' But is the deep subject matter expertise of Mitsui that had to zenzai together with Dylan and then', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='04fd039a-8eb1-42e2-8c78-d41b6ee503ad', embedding=None, metadata={'start': 1706.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ecedec55a65a1e4b7eafeb3c5d1c51ef5bac48e0cda07880af7e147b08518ed8', text=\" my team's expertise in AI that made this possible? And so as I operate an AI, one thing I've learned\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='78dc28b9-9de1-4285-a702-efef6b07f947', embedding=None, metadata={'start': 1713.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ea81b8add214886bac340a2d19d1039246a81ba328e70b0540fc03faa4f5c5eb', text=\" is my swim lane is AI. And that's it because I don't have time. It's very difficult for me to be\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2a8294c9-709c-4181-b55e-eb8347a8e061', embedding=None, metadata={'start': 1719.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c95c34a823a72a9378805575f57c57c0b93bfd24ca0ef472d51fcda0f215e4fd', text=' expert in maritime shipping and romantic relationships and healthcare and financial services and on and on and on and on.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='630483c4-bbb6-42f4-b9a0-5d9a198b7118', embedding=None, metadata={'start': 1729.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6348aa7d65f4acaf940932070c39d3deb2ea07de70cee50d03eec9930755beb1', text=' Actra technical validation and then use, you know, AI resources to make sure the AI tech has built quickly.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='00e80a46-d633-4b81-a01c-f28e419002ae', embedding=None, metadata={'start': 1735.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='862f573ee59fd8aa61d55507683bcac6a5a3f0ef6248b89c965e9e9fb0d271de', text=\" Well, and I think we've always managed to help the companies build a strong technical team\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d5c8b4df-1c50-4031-9aa9-92ad0072a1d5', embedding=None, metadata={'start': 1739.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ea8ffc6b283a313bc5a6a08457dced7939192efea789804786c8a29955ab9112', text=' than partnering with subject matter experts often results in exciting new opportunities.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c28ef79a-07ad-4470-838d-fd7e4876e70a', embedding=None, metadata={'start': 1745.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7a615c1979837067ef4d4930c76db76d790a12e903e7e0f700c78c984a1327e9', text=\" And I want to share with you one other weird aspect of one of the weird lessons I've learned\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='743e1f4d-e51e-45ee-90f4-401565dca136', embedding=None, metadata={'start': 1750.28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c533d906ab935c737107c04c12f07afc573c7c21c2da304a3e8de59348dbefa1', text=\" about, you know, building startups, which is I like to engage only when there's a concrete idea.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e66c443e-cc11-4bc7-9b83-172734fe8cb4', embedding=None, metadata={'start': 1756.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e8431c49a40819bd66d9cf308d2879bb9e9432ad6b4e098ca98b0fb7a76818b9', text=' And this runs counter to bother the advice you hear from the design thinking methodology,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4bdbd64b-46ee-4cca-8a20-21b948092d28', embedding=None, metadata={'start': 1762.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='43044e211ccaf160ad5ad004f6f2e1c190b57f251626183803f50e25852816bd', text=\" which often says don't rush to solutioning, right? Explore a lot of alternatives to avoid the solution.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='982c40e8-3efa-4861-9381-5e1f87c8ea5d', embedding=None, metadata={'start': 1768.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='15c738582f4cc0c769bf3cb5b6c8de496b00bb4d24daaa75f794caccb34b173d', text=\" Honestly, we tried that. It was very slow. But what we've learned is that at the ideation stage,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0d54493e-84d9-4edc-a985-8f55a50dd9b8', embedding=None, metadata={'start': 1775.52}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a1c6ab65416a1cd58b99594f1e11f1cf671a194647f04f210a256268923fc836', text=' if someone comes to me and says, hey, Andrew, you should apply AI to financial services.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='059fa6b7-81e3-4281-9225-274fd902d684', embedding=None, metadata={'start': 1780.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='34f5e1c37c3c348f890565624ccdf4827bda48b03484e25e3bd60a6686c2e9b7', text=\" Because I'm not a subject matter expert in financial services, it's very slow for me to\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='27e5416c-053a-46bc-8f02-2d71c7232119', embedding=None, metadata={'start': 1785.34}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='789a6ac1906b215d8859179e6d48edc939c130a3c89cd25f380c8882f301b44e', text=' learn enough about financial services that you can figure out what to do. I mean, eventually,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3d4613df-f7fb-4053-bc7d-c22b14f009dc', embedding=None, metadata={'start': 1789.36}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0387d23fd913ef65f8be85307f4b1ca14fa45ae897bd08bf5885a162ae83a27c', text=\" you could get a good outcome, but it's a very labor intensive, very slow, very expensive process.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1ba0f254-517d-4146-9fad-ec13213ed89e', embedding=None, metadata={'start': 1794.52}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='439ec2b8cfc8d77623543ac260435c5e6112902d80be717a5f3781cb47370a4d', text=' So me to try to learn industry after industry. In contrast, one of my partners wrote his ideas', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a9b024d4-c0ce-4401-b63a-4d4681278fc5', embedding=None, metadata={'start': 1800.98}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='052ccf8503e1bac62ae86e11e6e1cc54abe48f024fd06abd22d209e0c3e8d446', text=\" that Tony Cheat, not really seriously, but you know, let's say the concrete idea is by GBT,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e58e0790-7811-40a9-a38b-044a189656c8', embedding=None, metadata={'start': 1806.38}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='03001a7c41d62373d2a2540dbcf5a9c089eea7ebebb32cc8809fa0faa6dfb54a', text=\" let's eliminate commercials by automatically buying every product advertised in exchange for not\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a29befd8-1afb-4e6c-88dc-a324e603128c', embedding=None, metadata={'start': 1810.88}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0ac4aed76c30bd16b1dc87fd2018d12ef0e9bc3143d9422f4900911f7dcbc757', text=\" having seen ads. It's not a good idea, but it is a concrete idea. And it turns out concrete ideas\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c80997c-acbe-43ab-bd05-1106104363d1', embedding=None, metadata={'start': 1817.86}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='48506dd6c7d128af29f93a39482ef9cf43c4f24fcd4b5251e763aa4b0e4430ce', text=' can be validated or falsified efficiently. They also give a team a clear direction to execute.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5bd3f227-5cc8-4c1a-ad23-a3622c037d58', embedding=None, metadata={'start': 1825.52}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='31eae5363a1e27d4fbce970fa2184b3c816216e0310046dbd1a045d30535d14c', text=\" And I've learned it in today's world, especially with the excitement and buzz and exposure to the\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='49b9d32d-f22e-4a30-93e2-41b11c01af90', embedding=None, metadata={'start': 1829.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b2eba6bcf9cbed665ffe5ea0ca0b1306ceb8e48b49ebfe1813c503bbf07bc5ae', text=\" AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='667a7a38-33ad-4a34-83d3-602d62e09373', embedding=None, metadata={'start': 1834.88}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a8f9b719b41e5ae956dc1e422e6a7aabe56895e158d05fa5b6a342564a30d14b', text=\" that have deeply thought about a problem for months, sometimes even one or two years, but they've\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1e53b12c-0d49-4b10-9ed2-69dc245ef302', embedding=None, metadata={'start': 1841.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8d2d2946839bc92c73df485788c7833366d3df6392486a3b640d5d7090c438e8', text=' not yet had a build partner. And when we get together with them and hear and they share the idea', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3936f559-d394-4f40-af33-b04cbc404ccf', embedding=None, metadata={'start': 1846.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='13f22e8470d583d25ef0f50db5ce95da17825ece1da9040284bc53cdb76a830c', text=' of us, it allows us to work with them to very quickly go into validation and building. And I find', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d89685f9-06cc-42ab-bb6f-d32055e0db73', embedding=None, metadata={'start': 1851.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='aec2566a67edff23454d28fe04f20f9b3028a0425aa21b2f9c0ba890972adc63', text=' that this works because there are a lot of people that have already done the design thinking thing', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b8fe4685-7c2f-47ef-8903-e010a9835540', embedding=None, metadata={'start': 1858.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='41f95b9c45291d1209a3faabcd45ede9fc08d2006bc716d17eac53f13c241ae8', text=' of exploring a lot of ideas and winning down to really good ideas. And there are, I find that', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='51d7b946-b560-4eb8-bc25-8f6976033069', embedding=None, metadata={'start': 1863.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d8bf523e9bbac53b9b1da57c61dcf7b4ec1fd49cabb80329d7f41631004fd91b', text=\" there's so many good ideas sitting out there that no one is working on that finding those good\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8112de4d-d8ed-4c13-b0ce-ec9c7217e1cc', embedding=None, metadata={'start': 1868.28}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='11a1fa0b0d659bae65e98bbc0670b68ee0af98a27cd2df6728d7dc32d5031e0c', text=' ideas that someone has already had and wants to share of us and wants to build partner for that', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1b480bb4-ef3f-4f8e-9016-2dd84fde095f', embedding=None, metadata={'start': 1873.9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c157fb26f30189176289b48045d6dd88b51ce1d78c4498ee93810475d3d12ece', text=\" turns out to be much more efficient engine. So, before I wrap up, we'll go to the question\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2b5f1858-db2d-4236-85ac-37b0aa1556df', embedding=None, metadata={'start': 1881.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cc3b6f40182c9b03fb500c47b57eead316d7ce09158ebe07e8a189906203b396', text=' second. Just a few slides to talk about risks and social impact. So, AI is a very powerful', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bbe561c4-5617-4331-8af5-385aa9779dca', embedding=None, metadata={'start': 1887.68}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1e58f888829417678ea4c4793af56bb34ea5aa6708769edbdf89576b8aa6be3a', text=\" technology to state something you probably guess. My team's and I, we only work on projects that\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1702e969-0db3-4fc0-8049-459f95a561a1', embedding=None, metadata={'start': 1892.84}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='97e7e7889a961cbedf9d8ca29499558b4b75b11e19c7c43dc243731d57e1d219', text=' move humanity forward. And we have multiple times, killed projects that we assess that we', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='962217f8-2d64-40c3-82b6-38e41ed1edca', embedding=None, metadata={'start': 1899.02}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='71ecd1f64afc1480a28c036229f626a08987f941ed80df49a7af4d223edd4285', text=\" financially sound based on ethical grounds. It turns out I've been surprising. Sometimes this made\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8313f42b-b0c8-4725-b54b-5b9507401377', embedding=None, metadata={'start': 1905.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='94c6fce19a15ca31b56ef4ce19406901c7eab9a83687a427755a8b5ae56ef5fc', text=' at the creativity of people to come up with good ideas, sorry to come up with really bad ideas', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9dc5e8eb-ef98-44e2-b776-96822250350b', embedding=None, metadata={'start': 1911.24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='63f9b871d94cde0ce65218083a26d765df5989a592e1e89a2c57849122a65f52', text=' that seem profitable, but really should not be built with a few projects on those grounds.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e9fee0bc-6a09-456a-a032-db023040eee8', embedding=None, metadata={'start': 1918.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f6e38b7cf940260d43af7a4397935a1683cb22561847a4f12849b2aefa665ca4', text=' And then I think it has to acknowledge that AI today does have problems with bias, fairness,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='007da142-6c30-47a6-8691-74ad6bd0b98f', embedding=None, metadata={'start': 1923.64}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6c0e22a78313c5327849ed70483213ad02ccd888c15f8fa30290841722de1831', text=' accuracy, but also, you know, technology is improving quickly. So, I see that AI systems today', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='84046c11-1569-4b38-8ee2-a1a9a82e6918', embedding=None, metadata={'start': 1930.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='55d0354db04b1cd590f4e271f9e629249a69fcefbf116572c921a664240f43a3', text=' less bias than six months ago and more fair than six months ago, which is not to dismiss the importance', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c6fa945b-18f4-45e2-bc7b-8e4eae8db828', embedding=None, metadata={'start': 1936.02}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9cf6af361ed19f5cfc674a5dd19559d361cabfb49276d4edf452e9abd37c44b7', text=\" of these problems. They are problems and we should continue to work on them. But I'm also\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8bc33805-7d16-419c-989a-c87529b7a56d', embedding=None, metadata={'start': 1940.72}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1f1a911272a28c839bb335c1927ccc2cf2181b5c6ce4e60468d134ae883293ab', text=' gratified at the number of AI tears working hard on these issues to make them much better.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0f9d2062-a198-4621-9bec-b9a43e73af0f', embedding=None, metadata={'start': 1945.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='30cc4f6de5f5ded4f3a42b15c3e14c734c0d4ed2327625c97d1e1b30e27ed0a7', text=' When I think of the biggest risk of AI, I think that the biggest risk, one of the biggest', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9147756b-c6eb-4d76-825f-4f3cf59bac53', embedding=None, metadata={'start': 1949.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a50f38f9389948593a4273e8c6e62a97289c4a081d0834256afe0416539927b8', text=' risk is the disruption to jobs. This is a diagram from a paper by our friend at the University of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='44d4cf88-419e-4841-9e44-5ca727f7b19b', embedding=None, metadata={'start': 1957.16}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ebfd54928a2d893d7c43d8736697bd54b53025e38092c429a87a1a6739752d42', text=' Pennsylvania and some folks at OpenAI, analyzing the exposure of different jobs to AI automation.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b55193f8-ebac-487f-a838-76ba3cc02214', embedding=None, metadata={'start': 1964.36}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f71cde9105e109192dabb982da6716f894030e29982e3fa51307301582682559', text=' And it turns out that whereas the previous wave of automation mainly the most exposed jobs', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='881436d2-a34e-471d-aa3a-8db89cdc3b71', embedding=None, metadata={'start': 1970.74}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ee190defba8f2377eab1b8d2ad5ceba4e8c5fa7667346adea9bc4a2396739dfa', text=' were often the lower-wage jobs, such as when we put robots into factories. With this current', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3d8b2aaa-3fed-4e16-ad8c-b5c44e392204', embedding=None, metadata={'start': 1977.14}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='04aa3dda5d78cd2007e3f03758730164446547a208f2671bf86f942e9ccb83f8', text=' wave of automation is actually the higher-wage jobs further the right of this axis that seems', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='708148ba-a778-4be8-a913-9a70912678ea', embedding=None, metadata={'start': 1983.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d378e3540443ba841f07563d1ac07e3f33161888c3b580d0db2ee830226d3eab', text=' to have more of their tasks exposed to AI automation. So, even as we create tremendous value using AI,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='38ef9266-9cb4-4654-9820-3cd994c07038', embedding=None, metadata={'start': 1990.72}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3d1c300c7601c78d5bad8f05a76a6453362d12fc104baa499d9d3f5f1fecf50e', text=' I feel like as citizens and our corporations and the governments and really our society,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5777e54f-f340-4218-bab1-2e86bc13bab4', embedding=None, metadata={'start': 1996.78}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6f8cdde668193dba3c84d93dfeddb2536e655f73607ba2579e3a653597de889d', text=' I feel a strong obligation to make sure that people, especially people who are lively, who', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='23ff924a-731a-4ce7-9b7f-f0431f02d63e', embedding=None, metadata={'start': 2002.82}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fde2aa2073e212b78d10c0a57b52c02d37a160a48347097b5b6991fafddc89e7', text=' are disrupted, are still well taken care of, are still treated well. And then lastly,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c0803b78-80d7-4859-9f53-69f7fd3adb58', embedding=None, metadata={'start': 2012.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ac3b7441e708525f3d8c7dd64ddb3e73315b74cc2ee4b686fb525900304948fa', text=\" it feels like every time there's a big wave of progress in AI, there's a big wave of hype\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='55d6cb7d-6f09-4739-9fe0-02c612c98e45', embedding=None, metadata={'start': 2018.04}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7c1bb393a10efb51679b663d0700558c744922dfdd39d48abedb4dbe79f7a4bf', text=' about artificial gender intelligence as well. When deep learning started to work really well 10', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='16f0062a-fa89-457c-bba7-7f9470c52660', embedding=None, metadata={'start': 2022.48}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0f64eaa2a4b0bed11babce6629af8d9be2c8ad88adadfbd708388b2ba723ae56', text=' years ago, there was a lot of hype about AI and now the gender of AI is working really well.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9050f1e0-40e1-44e6-b564-061ad6b3e381', embedding=None, metadata={'start': 2026.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2e13f463bec8d2f4821bcd4e167c6393fcd2165b425d04118b9c4b2af27fe4aa', text=\" There's another wave of hype about AI. But I think that artificial gender intelligence,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='13c9f6a3-d7b9-4ab6-a44e-03f60030fb75', embedding=None, metadata={'start': 2033.1}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d7e344e62696385838becdd101448d9212a1a952518150b0a9b2b4828f499218', text=\" AI didn't do anything human can do, it still decades away, maybe 30 to 50 years, maybe even longer.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e910d7b9-b655-4056-8056-d773d673c9cd', embedding=None, metadata={'start': 2038.48}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5c574b3ab95de858fa09721502661b35b8a077df91a318e862c699c832e590a5', text=\" I hope we'll see in our lifetimes. But I don't think there's any time soon. One of the challenges\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='85f3f999-020f-4bbd-83fa-bd92ddc30ae0', embedding=None, metadata={'start': 2043.86}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1a56ddfbc6da9ba5a0456702fc0fee2cf86ac0e9cc0f59b1e917d04969bc486e', text=' is that the biological path to intelligence, like humans and the digital path to intelligence,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='eef836d0-cdc1-4075-8ce5-3a8aa645d792', embedding=None, metadata={'start': 2049.9}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='cc61ce1ff28e13cf72357c8ae0453094247a70ca0c5cf14c0ca2b36822484c7b', text=\" AI, they've taken very different paths. And the funny thing about the definition of AI is\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='894ce01f-ee40-4258-9eb9-1fb1f8276273', embedding=None, metadata={'start': 2057.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='482aa5a2101c9e92d7bae95c1d02cb038df4ca6faa044099776ec0291d431f97', text=' benchmarking this very different digital path to intelligence with really the biological path', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f2c7689d-93b6-41a5-8915-680ba076b285', embedding=None, metadata={'start': 2061.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9faf6123ec470e08f93600f6ebfc31fd8d996f2f2315194c465c9d6a1d75ca71', text=' to intelligence. So I think, you know, Russian-Gashmoldos are smarter than any of us in certain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='940aa01b-4ba7-4cd6-bf4f-d4bb222c2167', embedding=None, metadata={'start': 2067.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='aa039e0173fea80921ed4a2065e2262db1324b841273fb8a40c2fa6bb6a1885a', text=' key dimensions, but much dumber than any of us in other dimensions. And so forcing it to do', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6c800efb-d615-4b9b-8b29-50f4d8b77115', embedding=None, metadata={'start': 2072.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fb47d0720452d33cbf42e024f05e5c2a4355ee5d79a837b0bb5f3acd41b168bc', text=\" everything a human can do is like a funny comparison. But I hope we'll get there, maybe hopefully\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d152ecc6-895c-447d-99e3-4516e1b5aa89', embedding=None, metadata={'start': 2077.38}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='35576cf38559c7fe34431186a5cd5abd076d11c7e6cf850e47bb8d5688dda16a', text=\" within a lifetimes. And then there's also a lot of, I think, overblown hype about AI creating\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fd3a87d1-6b3f-4f48-88ee-6a5476aad671', embedding=None, metadata={'start': 2083.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8cb309f81430412a16176879d1688bcefb35067e2ad066e635a801ae07ec0917', text=\" extinction risk for humanity. Candidly, I don't see it. I just don't see how AI creates any\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ed890fb1-7555-46e8-bd4c-220423854127', embedding=None, metadata={'start': 2088.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e4872cfaa3054be9387a77c40752021dd325b30cc3d87caeca52f3707a11245c', text=\" meaningful extinction risk for humanity. I think that people worry we can't control AI,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='147c3db7-2066-4e5a-8720-b8b4ddb10b0f', embedding=None, metadata={'start': 2096.38}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b0e7d2698ae141b37c5c8a4c0ee2e1b1fe6757dab722d94f1fa9d0b445c6e59f', text=\" but we have lots of AI will be more powerful than any person. But we've lots of experience steering\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1bae598c-fe73-475c-bf68-d911d7a34316', embedding=None, metadata={'start': 2102.14}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='8615088f2bc25b855dbbf3cc3fb1ea6f5c3a9b55346f86faa630acd02d07ebff', text=' very powerful entities such as corporations or nation states that are far more powerful than any', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3d8c56b2-a164-4d82-b224-d128d759aefd', embedding=None, metadata={'start': 2106.58}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='566b3fb86bbf98f5518696dcd1f7bb5fcd342cfdf8f05f69891cd79298ca4e76', text=' single person and making sure they for the most part benefit humanity. And also technology', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b5e8c0e3-3087-4232-b00e-d79370d73979', embedding=None, metadata={'start': 2112.96}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='09baf91b5697bdcff53b57bfbb17357864b42b64bfe6ba164d8a8487c9699d66', text=\" develops gradually. The so-called hot takeoff scenario, where it's not really working today,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fab27ecd-7de9-4e59-a2eb-655c8a5f476c', embedding=None, metadata={'start': 2118.92}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ab64bbc0467f6ce0932418ff69b0cddf9dbac870d47bd2ffb2c3dd21ad8c5911', text=' and then suddenly one day overnight, it works brilliantly with Chief Super Intelligence takes', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f099eb07-f878-4c60-b514-d0435279502c', embedding=None, metadata={'start': 2123.24}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='16b2bb98bbd966b5c7b9b2115aeb983ba79bad51d416f663f33c6299e15086e9', text=\" over the world. That's just not realistic. And I think AI technology will develop slowly,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6a48a5f4-5f2d-4053-ac17-53ee3293d680', embedding=None, metadata={'start': 2128.76}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6fe5b9f2a637b1aee2367d89112d01854be821bcb52481e0abe3a2687ed3353f', text=' like all the technology, and then it gives us plenty of time to make sure that we provide', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='5d701199-47cb-45ad-b1b3-a0b2890122e0', embedding=None, metadata={'start': 2133.42}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='68624c6426a68cc02916b9eed7703a200a64880c5d92b2e11cbb02c1f2ade582', text=' oversight and can manage it to be safe. And lastly, if you look at the real extinction risk of', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='771982bf-654f-4b6c-819a-60c2d30847d6', embedding=None, metadata={'start': 2139.0}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='023357b387f02de9c21743e7dff4be458d1718794b54047be6c582eddcddfe71', text=' humanity, such as fingers crossed an ex-pandemic or climate change leading to a massive', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0955e5b6-7d44-4d20-a430-96230386b8a3', embedding=None, metadata={'start': 2146.18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='19d37ff462b1ea9d7be0f645f9430e285d42f8ef80cdecc5099e10225c4a4565', text=' depopulation of some parts of the planet, or much lower odds that maybe someday,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='04ab3ba6-f2aa-445f-a7f0-b4b65f5e27fe', embedding=None, metadata={'start': 2151.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='76b009658d99ea96fa318872ef52c16aefdfc51f437e70f84995f64756fffefc', text=\" and as there are doing to us, whether they're done to the dinosaurs, I think we look at the actual\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fb4ef8ae-7008-474d-b8f2-db18412a7871', embedding=None, metadata={'start': 2156.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c7e11472ffda07df7bfda3f9b6b38552d055fc6bf6630f2de6cbb7c2a574a33f', text=' real extinction risk to humanity. AI, having more intelligence, even artificial intelligence', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='58c0fc5c-6a56-4fdb-8f8a-e6c449f2284d', embedding=None, metadata={'start': 2162.46}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5b5eb783437141c229b1d9beec8f63a8cb871e2df5c7deda43c0e81b7cf81b60', text=' in the world, would be a key part of the solution. So I feel like if you want humanity to', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='15c6b633-56db-46df-98a5-0c9ce9fa5f18', embedding=None, metadata={'start': 2167.22}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3766513dce31ee05a90e27ada9c2f417291c1e02b668c9e65c75a6d0573ead66', text=' survive and thrive for the next thousand years, rather than slowing AI down, which some people', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0b9ffaf6-52ee-4bfe-896a-fd2348540635', embedding=None, metadata={'start': 2172.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7257e004d027912b3b03188ada88f10b2cf595aa95e6492b9fd0f4d4aa2048f6', text=' propose, I would rather make AI go as fast as possible. So with that, just to summarize,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d6fc5af5-b2d7-4d64-9611-1474ae9015b0', embedding=None, metadata={'start': 2180.52}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d9b9bc1f16825a553b646481d8456710cb6e71ded9a800d4b97a313dff35fcc3', text=' this is my last slide. I think that AI, as a general purpose technology,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ded66290-f22f-4284-978b-4cd060b8d819', embedding=None, metadata={'start': 2185.86}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3d4642116bee4f951841a22fe0fdad004635d7230b6424125c6ff4d04a9b509e', text=' creates a lot of new opportunities for everyone, and a lot of the exciting and important work that', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='269e7e64-8f9f-4f0b-9f65-c11c28c7a12f', embedding=None, metadata={'start': 2191.6}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c4c2669111b110a1594c4acc6c55bf3cfbe65d3100ab39e454258d7a87b386e9', text=' lies ahead of us all is to go and build those concrete use cases. And hopefully in the future,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9475566c-5c1e-4d1d-bc0a-95d8140cd0e9', embedding=None, metadata={'start': 2198.8}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='9acf03fc693c84bc2a92c650d46964cdbbc7149c6f0964856f6a956304add030', text=' hopefully I have opportunities to maybe engage with more of you on those opportunities as well.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='16ab7098-0e3c-4ff8-8b12-8163671f1a13', embedding=None, metadata={'start': 2204.06}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d04ede67416d1792fce7a2748cd8503ac9459ca8eb150ccc971e5c7b167d52b0', text=' So that, let me just say thank you all very much.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ece272c-fc56-4073-9d08-365e04970839",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import ChromaVectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5bdf6fae-7d25-4c75-b96d-4855e2628cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9cf8c82fee45f985587c89f15a646a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1200b69ff45a4a6188b39f5bbd18e4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# set up ChromaVectorStore and load in data\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    docs, storage_context=storage_context, service_context=service_context,\n",
    "show_progress=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce184f23-5c6e-470b-be35-6353e011ae34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retreiver = index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84f7533f-4d06-41d4-8cfb-80bf4dd2f3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='1d632109-971a-48eb-a04e-50e19ec0a5a1', embedding=None, metadata={'start': 2088.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e8b06bf6-4bbc-48f4-8a07-59dbe67f6808', node_type=None, metadata={'start': 2088.7}, hash='e4872cfaa3054be9387a77c40752021dd325b30cc3d87caeca52f3707a11245c')}, hash='472f3b5f3877567d9843336ec4c83ec8c2408a404f9115a600eeddd297f27ea1', text=\"meaningful extinction risk for humanity. I think that people worry we can't control AI,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=7.585418697260143e-64),\n",
       " NodeWithScore(node=TextNode(id_='da3984c2-e333-4f16-b4fa-f7cb46cf1e2b', embedding=None, metadata={'start': 2088.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e8b06bf6-4bbc-48f4-8a07-59dbe67f6808', node_type=None, metadata={'start': 2088.7}, hash='e4872cfaa3054be9387a77c40752021dd325b30cc3d87caeca52f3707a11245c')}, hash='472f3b5f3877567d9843336ec4c83ec8c2408a404f9115a600eeddd297f27ea1', text=\"meaningful extinction risk for humanity. I think that people worry we can't control AI,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=7.585418697260143e-64),\n",
       " NodeWithScore(node=TextNode(id_='d435ea5f-050a-4742-94d9-31f944b5b74b', embedding=None, metadata={'start': 2088.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e8b06bf6-4bbc-48f4-8a07-59dbe67f6808', node_type=None, metadata={'start': 2088.7}, hash='e4872cfaa3054be9387a77c40752021dd325b30cc3d87caeca52f3707a11245c')}, hash='472f3b5f3877567d9843336ec4c83ec8c2408a404f9115a600eeddd297f27ea1', text=\"meaningful extinction risk for humanity. I think that people worry we can't control AI,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=7.585418697260143e-64),\n",
       " NodeWithScore(node=TextNode(id_='767778bd-742c-4503-9953-ac55195b7442', embedding=None, metadata={'start': 2088.7}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ed890fb1-7555-46e8-bd4c-220423854127', node_type=None, metadata={'start': 2088.7}, hash='e4872cfaa3054be9387a77c40752021dd325b30cc3d87caeca52f3707a11245c')}, hash='472f3b5f3877567d9843336ec4c83ec8c2408a404f9115a600eeddd297f27ea1', text=\"meaningful extinction risk for humanity. I think that people worry we can't control AI,\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=7.585418697260143e-64),\n",
       " NodeWithScore(node=TextNode(id_='9c5772ca-daf1-4a36-98cf-ded785c814cc', embedding=None, metadata={'start': 2156.32}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='0744acfb-f4bc-4588-b7e4-5354b2ee2141', node_type=None, metadata={'start': 2156.32}, hash='c7e11472ffda07df7bfda3f9b6b38552d055fc6bf6630f2de6cbb7c2a574a33f')}, hash='3ca7be8af19db0b9acfd56e6b7c77c2816b89311bd3cd2981aaae83f41b104b8', text='real extinction risk to humanity. AI, having more intelligence, even artificial intelligence', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=1.2374790184879472e-70)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreiver.retrieve(\"What are the author's thoughts on the risks and benefits of AI for humanity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a1ea1a2b-b5fe-40d8-9da7-c79fc7fcd1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "999750f6-3a15-4614-a47e-dbb53b3c5a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd21a3e7-9315-4b15-bf5b-770b329a545f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author expresses concern about the risks associated with AI, specifically the potential for it to pose a meaningful extinction risk to humanity. They mention that people worry about our ability to control AI. However, the author also suggests that AI, with its greater intelligence, may have benefits for humanity.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What are the author's thoughts on the risks and benefits of AI for humanity\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75099fee-a538-402b-baa8-5fe58320c681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GPTSimpleVectorIndex' from 'llama_index' (/Users/saazizi/miniconda3/lib/python3.10/site-packages/llama_index/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_loader, GPTSimpleVectorIndex\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GPTSimpleVectorIndex' from 'llama_index' (/Users/saazizi/miniconda3/lib/python3.10/site-packages/llama_index/__init__.py)"
     ]
    }
   ],
   "source": [
    "from llama_index import download_loader, GPTSimpleVectorIndex\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain224",
   "language": "python",
   "name": "langchain224"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
