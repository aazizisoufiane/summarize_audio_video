{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac945a05-1cf6-442d-a708-dcaff22eef11",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nb_black in /Users/saazizi/miniconda3/lib/python3.10/site-packages (1.0.7)\n",
      "Requirement already satisfied: nbdime in /Users/saazizi/miniconda3/lib/python3.10/site-packages (3.2.1)\n",
      "Requirement already satisfied: black>='19.3' in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nb_black) (23.7.0)\n",
      "Requirement already satisfied: ipython in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nb_black) (8.12.0)\n",
      "Requirement already satisfied: jupyter-server-mathjax>=0.2.2 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (0.2.6)\n",
      "Requirement already satisfied: jupyter-server in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (2.5.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (3.1.2)\n",
      "Requirement already satisfied: nbformat in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (5.7.0)\n",
      "Requirement already satisfied: tornado in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (6.2)\n",
      "Requirement already satisfied: pygments in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (2.15.1)\n",
      "Requirement already satisfied: GitPython!=2.1.4,!=2.1.5,!=2.1.6 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (3.1.37)\n",
      "Requirement already satisfied: colorama in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (0.4.6)\n",
      "Requirement already satisfied: requests in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbdime) (2.28.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from black>='19.3'->nb_black) (3.10.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from black>='19.3'->nb_black) (23.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from black>='19.3'->nb_black) (0.11.2)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from black>='19.3'->nb_black) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from black>='19.3'->nb_black) (8.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from black>='19.3'->nb_black) (1.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from GitPython!=2.1.4,!=2.1.5,!=2.1.6->nbdime) (4.0.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jinja2>=2.9->nbdime) (2.1.1)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (0.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (5.3.0)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (6.5.4)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (5.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (0.17.1)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (8.1.0)\n",
      "Requirement already satisfied: send2trash in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (1.8.0)\n",
      "Requirement already satisfied: websocket-client in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (0.58.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (0.14.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (3.5.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (0.4.4)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (25.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-server->nbdime) (21.3.0)\n",
      "Requirement already satisfied: fastjsonschema in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbformat->nbdime) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbformat->nbdime) (4.17.3)\n",
      "Requirement already satisfied: decorator in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (4.4.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (3.0.36)\n",
      "Requirement already satisfied: pickleshare in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (0.7.5)\n",
      "Requirement already satisfied: backcall in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (0.2.0)\n",
      "Requirement already satisfied: appnope in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (0.1.2)\n",
      "Requirement already satisfied: stack-data in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from ipython->nb_black) (0.18.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from requests->nbdime) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from requests->nbdime) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from requests->nbdime) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from requests->nbdime) (2023.5.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server->nbdime) (1.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=2.1.4,!=2.1.5,!=2.1.6->nbdime) (5.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jedi>=0.16->ipython->nb_black) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbdime) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbdime) (22.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-client>=7.4.4->jupyter-server->nbdime) (2.8.2)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server->nbdime) (0.1.1)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server->nbdime) (0.1.4)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server->nbdime) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server->nbdime) (6.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (0.5.13)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (0.8.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (4.12.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (1.2.1)\n",
      "Requirement already satisfied: lxml in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (4.9.2)\n",
      "Requirement already satisfied: bleach in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime) (0.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from pexpect>4.3->ipython->nb_black) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->nb_black) (0.2.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from argon2-cffi->jupyter-server->nbdime) (21.2.0)\n",
      "Requirement already satisfied: pure-eval in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from stack-data->ipython->nb_black) (0.2.2)\n",
      "Requirement already satisfied: executing in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from stack-data->ipython->nb_black) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from stack-data->ipython->nb_black) (2.0.5)\n",
      "Requirement already satisfied: six in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from websocket-client->jupyter-server->nbdime) (1.16.0)\n",
      "Requirement already satisfied: uri-template in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbdime) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbdime) (2.1)\n",
      "Requirement already satisfied: fqdn in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbdime) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbdime) (20.11.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->nbdime) (1.13)\n",
      "Requirement already satisfied: nest-asyncio in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert>=6.4.4->jupyter-server->nbdime) (1.5.6)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server->nbdime) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server->nbdime) (2.4)\n",
      "Requirement already satisfied: webencodings in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from bleach->nbconvert>=6.4.4->jupyter-server->nbdime) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server->nbdime) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/saazizi/miniconda3/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat->nbdime) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nb_black nbdime ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d89427-b702-4b11-b6f4-0408fa6447c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip3 install git+https://github.com/linto-ai/whisper-timestamped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed34abd-d38b-4c3a-a2c7-4524a3cd1e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload module is not an IPython extension.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15387cf6-42c3-4b39-b8a9-3ae9e7bd514d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "import whisper_timestamped as whisper\n",
    "from pydub import AudioSegment\n",
    "from logger import logger\n",
    "from pytube import YouTube\n",
    "\n",
    "import whisper\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b661336-e592-4782-aed5-940c2569751a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path_youtube = \"YoutubeAudios\"\n",
    "output_path_transcription = \"transcriptions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced2d1e4-69ec-430b-a8c3-41a5537c6dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 17:12:35,305 ./logs/auto-labeler INFO extract_main_domain_and_video_id [3050587144.py]\n",
      "2023-10-10 17:12:35,307 ./logs/auto-labeler INFO download_youtube [3050587144.py]\n",
      "2023-10-10 17:12:37,157 ./logs/auto-labeler INFO Audio downloaded to YoutubeAudios/youtube_5p248yoa3oE.mp3 [3050587144.py]\n",
      "2023-10-10 17:12:37,157 ./logs/auto-labeler INFO transcribe_audio [3050587144.py]\n",
      "/Users/saazizi/miniconda3/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "2023-10-10 17:15:33,343 ./logs/auto-labeler INFO merge_segments [3050587144.py]\n",
      "2023-10-10 17:15:33,346 ./logs/auto-labeler INFO write_to_json [3050587144.py]\n",
      "2023-10-10 17:15:33,393 ./logs/auto-labeler INFO Transcription downloaded to transcriptions/youtube_5p248yoa3oE.json [3050587144.py]\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "import json\n",
    "import whisper  # Assuming you have a package or module named whisper\n",
    "from logger import logger\n",
    "\n",
    "\n",
    "class YouTubeTranscriber:\n",
    "    def __init__(self, url, output_path_youtube, output_path_transcription):\n",
    "        self.output_path_youtube = output_path_youtube\n",
    "        self.yt = YouTube(url)\n",
    "        self.transcription = None\n",
    "        self.url = url\n",
    "        self.filename_path = None\n",
    "        self.output_path_transcription = output_path_transcription\n",
    "\n",
    "    def extract_main_domain_and_video_id(self):\n",
    "        parsed_url = urlparse(self.url)\n",
    "        domain_parts = parsed_url.netloc.split(\".\")\n",
    "        main_domain = domain_parts[-2] if len(domain_parts) >= 2 else None\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        video_id = query_params.get(\"v\", [None])[0]\n",
    "        self.video_id = f\"{main_domain}_{video_id}\"\n",
    "\n",
    "    def download_youtube(self):\n",
    "        self.filename = f\"{self.video_id}.mp3\"\n",
    "\n",
    "        audio_stream = self.yt.streams.filter(only_audio=True).first()\n",
    "\n",
    "        audio_stream.download(\n",
    "            output_path=self.output_path_youtube, filename=self.filename\n",
    "        )\n",
    "        logger.info(f\"Audio downloaded to {self.output_path_youtube}/{self.filename}\")\n",
    "\n",
    "    def transcribe_audio(self, model_name, device):\n",
    "        audio = whisper.load_audio(f\"{self.output_path_youtube}/{self.filename}\")\n",
    "        model = whisper.load_model(model_name, device=device)\n",
    "        self.transcription = whisper.transcribe(model, audio, word_timestamps=True)\n",
    "\n",
    "    def write_to_json(self):\n",
    "        with open(f\"{self.output_path_transcription}/{self.video_id}.json\", \"w\") as f:\n",
    "            json.dump(self.transcription, f)\n",
    "        logger.info(\n",
    "            f\"Transcription downloaded to {self.output_path_transcription}/{self.video_id}.json\"\n",
    "        )\n",
    "\n",
    "    def merge_segments(self, num_to_merge):\n",
    "        merged_segments = []\n",
    "        segments = self.transcription[\"segments\"]\n",
    "        for i in range(0, len(segments), num_to_merge):\n",
    "            merged_dict = {}\n",
    "            slice_ = segments[i : i + num_to_merge]\n",
    "\n",
    "            # Merging the 'text' fields\n",
    "            merged_dict[\"text\"] = \" \".join(item[\"text\"] for item in slice_)\n",
    "\n",
    "            # Get the 'start' time from the first dictionary and the 'end' time from the last dictionary\n",
    "            merged_dict[\"start\"] = int(slice_[0][\"start\"])\n",
    "            merged_dict[\"end\"] = int(slice_[-1][\"end\"])\n",
    "\n",
    "            merged_segments.append(merged_dict)\n",
    "\n",
    "        self.transcription[\"merged_segments\"] = merged_segments\n",
    "\n",
    "    def run(self, num_to_merge=4, model_name=\"base\", device=\"cpu\"):\n",
    "        logger.info(\"extract_main_domain_and_video_id\")\n",
    "        self.extract_main_domain_and_video_id()\n",
    "\n",
    "        logger.info(\"download_youtube\")\n",
    "        self.download_youtube()\n",
    "\n",
    "        logger.info(\"transcribe_audio\")\n",
    "        self.transcribe_audio(model_name=model_name, device=device)\n",
    "\n",
    "        logger.info(\"merge_segments\")\n",
    "        self.merge_segments(num_to_merge)\n",
    "\n",
    "        logger.info(\"write_to_json\")\n",
    "        self.write_to_json()\n",
    "\n",
    "\n",
    "# Usage\n",
    "output_path = output_path_youtube\n",
    "url = \"https://www.youtube.com/watch?v=5p248yoa3oE\"\n",
    "# url = \"https://www.youtube.com/watch?v=UyoXmHS-KGc\"\n",
    "yt_transcriber = YouTubeTranscriber(\n",
    "    url=url,\n",
    "    output_path_youtube=output_path_youtube,\n",
    "    output_path_transcription=output_path_transcription,\n",
    ")\n",
    "\n",
    "yt_transcriber.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abc88d-2058-49f3-b376-f41d435ca3d7",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c2ec9e6-1463-48a2-aec4-194d32cba807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd0ae106-43d5-44bf-992f-9d8b17f7459e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# success = load_dotenv(find_dotenv())\n",
    "# print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8b5e26bf-7c8b-437b-bd4f-e6d7fd733144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa2550-4f15-4fe9-81c9-66380ea806bd",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fced361f-b189-436d-acd4-8b46ba73900f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c499fad-52de-4910-9454-2eef52065dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18d8dc91-8885-48bc-9e7a-52d10086e4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file=\"transcriptions/youtube_5p248yoa3oE.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1701eac0-4037-4cec-bc6f-5684119fb846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open (json_file, \"r\") as f:\n",
    "    docs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f185938-a201-4be0-ba38-51a54dbeb435",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9566329e-7073-4a30-9f18-2db8920ea850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32662f-ed8a-4bc0-8bab-db8d9074fef4",
   "metadata": {},
   "source": [
    "### Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "989494db-b833-44f0-8a74-ddce14c0c673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9532e584-e4f1-4947-b9b0-3b99d6907b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_prompt_template = \"\"\"\n",
    "                      Write a summary of this chunk of text that includes the main points and any important details.\n",
    "                      {text}\n",
    "                      \"\"\"\n",
    "\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "text: {text}\n",
    "Your task is to produce both a concise, entity-dense summary and a bullet-point list of key entities or ideas from the following transcribed text of a webinar or conference. This should be done over five iterative rounds.\n",
    "\n",
    "For each round, execute these steps:\n",
    "\n",
    "- **Step 1**: Identify salient entities from the transcribed text that have not been covered in prior summaries or bullet-point lists. These can be pivotal quotes, crucial events, or key technical terms. Use semicolons to separate multiple entities.\n",
    "\n",
    "- **Step 2**: Create a revised summary that incorporates all the details and entities from the previous summary, with the aim of keeping the summary as concise as possible while maintaining clarity and detail.\n",
    "\n",
    "**Guidelines**:\n",
    "\n",
    "- **Initial Summary**: Begin with a summary that appropriately reflects the length and complexity of the transcribed text. The focus should be on overarching themes.\n",
    "\n",
    "- **Impactful Writing**: Revise each summary to improve its flow and coherence, making room for the inclusion of new important entities.\n",
    "\n",
    "- **Efficient Language**: Utilize techniques like sentence fusion, idea compression, and the removal of redundant phrases to make the summary more streamlined.\n",
    "\n",
    "- **Self-Containment**: Aim for each summary to stand alone, providing a comprehensive understanding without requiring access to the full transcript.\n",
    "\n",
    "After the final round of summary revisions, list all the key entities or important ideas identified during the five rounds in bullet-point form:\n",
    "\n",
    "**Key Entities and Important Ideas:**\n",
    "- Bullet point 1\n",
    "- Bullet point 2\n",
    "- ...\n",
    "\n",
    "Answer.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "combine_prompt = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c683a-01f6-4ad2-8c42-7ebb321f37c9",
   "metadata": {},
   "source": [
    "### Map reduce and generate summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ee573e39-ad32-493b-8531-b3139282f7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_reduce_chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt,\n",
    "    combine_prompt=combine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fddedb8c-b63b-4841-ad77-bd4c650042ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 20,\n",
    "    # length_function = len,\n",
    "    # is_separator_regex = False,\n",
    ")\n",
    "texts = text_splitter.create_documents([docs[\"text\"]])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c5f6c6cd-1565-42a9-bcd9-dbbbf98a0373",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_reduce_outputs = map_reduce_chain({\"input_documents\": texts}, return_only_outputs=True)\n",
    "# map_reduce_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0450f2ff-900d-401e-bf67-52c525fe2291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Round 1:**\n",
      "\n",
      "**Entities:**\n",
      "- Dr. Andrew Wu\n",
      "- AI\n",
      "- Electricity\n",
      "- General purpose technology\n",
      "- Opportunities\n",
      "\n",
      "**Revised Summary:**\n",
      "Dr. Andrew Wu, an expert in AI, compares AI to electricity, stating that it is a general purpose technology with the potential to change many aspects of our lives. In his talk, he will discuss the various opportunities that AI presents.\n",
      "\n",
      "**Round 2:**\n",
      "\n",
      "**Entities:**\n",
      "- Supervised learning\n",
      "- Generative AI\n",
      "\n",
      "**Revised Summary:**\n",
      "Dr. Andrew Wu highlights the importance of supervised learning and generative AI in the field of AI. He explains that supervised learning is widely used in applications such as image recognition, speech recognition, and recommendation systems, while generative AI focuses on creating new content based on patterns learned from existing data.\n",
      "\n",
      "**Round 3:**\n",
      "\n",
      "**Entities:**\n",
      "- Large-scale supervised learning\n",
      "- Large AI models\n",
      "- Google Brain team\n",
      "\n",
      "**Revised Summary:**\n",
      "Over the last decade, large-scale supervised learning and the development of large AI models have driven significant progress in AI. The Google Brain team's primary mission was to build these large AI models, which have led to continuous improvement in performance.\n",
      "\n",
      "**Round 4:**\n",
      "\n",
      "**Entities:**\n",
      "- Large neural networks\n",
      "- Generative AI\n",
      "- Text generation\n",
      "- Supervised learning\n",
      "\n",
      "**Revised Summary:**\n",
      "Large neural networks and a lot of data have been instrumental in AI progress. The current focus is on adding generative AI to supervised learning, particularly in the field of text generation. The core of generative AI text generation lies in using supervised learning techniques.\n",
      "\n",
      "**Round 5:**\n",
      "\n",
      "**Entities:**\n",
      "- Large language models\n",
      "- Predicting the next word\n",
      "- RHDF\n",
      "- Workflow for supervised learning\n",
      "\n",
      "**Revised Summary:**\n",
      "The use of large language models in predicting the next word or sub-word has significantly advanced the field of AI. Techniques like RHDF are used to refine and improve the output of AI systems. Large language models have benefits for both consumers and developers, speeding up the development process. The workflow for supervised learning plays a key role in utilizing large language models.\n",
      "\n",
      "**Key Entities and Important Ideas:**\n",
      "- Dr. Andrew Wu\n",
      "- AI\n",
      "- Electricity\n",
      "- General purpose technology\n",
      "- Opportunities\n",
      "- Supervised learning\n",
      "- Generative AI\n",
      "- Large-scale supervised learning\n",
      "- Large AI models\n",
      "- Google Brain team\n",
      "- Large neural networks\n",
      "- Text generation\n",
      "- Large language models\n",
      "- Predicting the next word\n",
      "- RHDF\n",
      "- Workflow for supervised learning\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_outputs[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde75da-5c41-4073-8edc-4437f2fa1bf5",
   "metadata": {},
   "source": [
    "### Extract last summary, entities and ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "284add61-3587-4881-af59-e14eda65d969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "template = \"\"\"Extract the final summary, entities and ideas\n",
    "{summary}\n",
    "Answer:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"summary\"], template=template)\n",
    "final_report = LLMChain(llm=llm, prompt=prompt_template, output_key=\"final_report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da2ff3ae-8c3a-4f8c-9dcf-3abf3cc4d45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dr. Andrew Wu discusses the potential of AI as a general purpose technology, comparing it to electricity. He emphasizes the importance of supervised learning and generative AI in the field of AI, particularly in applications such as image recognition, speech recognition, and recommendation systems. The development of large AI models and large neural networks has driven significant progress in AI, with the Google Brain team playing a key role in this advancement. The focus now is on adding generative AI to supervised learning, specifically in the field of text generation. Large language models have greatly advanced AI, with techniques like RHDF used to refine and improve AI systems. The workflow for supervised learning is crucial in utilizing large language models. Overall, AI presents numerous opportunities and has the potential to greatly impact various aspects of our lives.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_report.run(map_reduce_outputs[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b509b23-17c2-4e85-b78e-fab635606de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2b5bbcd-9623-4f40-be14-7910ec3c875b",
   "metadata": {},
   "source": [
    "## Construct retreival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c1c2f-834b-482e-973f-72b7648f5c8a",
   "metadata": {},
   "source": [
    "### Preprocess docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4e96f0c9-e6c4-43c3-9f4c-ffb10aa76a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from langchain.schema import Document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "541f04ee-1ebe-4ce4-9824-536672baf8c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1577"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_documents_from_transcription(json_file, chunk_sizes):\n",
    "    \"\"\"\n",
    "    Concatenates words from a given JSON data structure with maximum chunk sizes.\n",
    "\n",
    "    Parameters:\n",
    "        json_file (str): The path to the JSON file.\n",
    "        chunk_sizes (list of int): The list of maximum number of words allowed in each concatenated chunk.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of nodes. Each node contains concatenated text and metadata (start_time, end_time).\n",
    "\n",
    "    \"\"\"\n",
    "    def add_document_to_chunks(word_list, start_time, end_time, chunks,chunk_size):\n",
    "        \"\"\"Helper function to add a new Document to chunks.\"\"\"\n",
    "        text = \" \".join(word_list)\n",
    "        doc = Document(page_content=text, metadata={'start': start_time, \n",
    "                                              \"end\": end_time,\n",
    "                                             \"chunk_size\":chunk_size})\n",
    "        chunks.append(doc)\n",
    "\n",
    "    concatenated_chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "    current_start_time = None\n",
    "    current_end_time = None\n",
    "\n",
    "    # Load JSON data\n",
    "    with open(json_file, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "\n",
    "    if not isinstance(chunk_sizes, list):\n",
    "        chunk_sizes = [chunk_sizes]\n",
    "    for chunk_size in chunk_sizes:\n",
    "        for segment in json_data[\"segments\"]:\n",
    "            add_document_to_chunks(word_list=[segment[\"text\"]], \n",
    "                                   start_time=segment[\"start\"], \n",
    "                                   end_time=segment[\"end\"], \n",
    "                                   chunks=concatenated_chunks, \n",
    "                                   chunk_size=len(segment[\"tokens\"])\n",
    "                                  )\n",
    "            for word_info in segment[\"words\"]:\n",
    "                if current_word_count + 1 > chunk_size:\n",
    "                    add_document_to_chunks(current_chunk, current_start_time, current_end_time, concatenated_chunks, chunk_size)\n",
    "                    current_chunk = []\n",
    "                    current_word_count = 0\n",
    "                    current_start_time = None\n",
    "\n",
    "                current_chunk.append(word_info[\"word\"].strip())\n",
    "                current_word_count += 1\n",
    "\n",
    "                if current_start_time is None:\n",
    "                    current_start_time = word_info[\"start\"]\n",
    "                current_end_time = word_info[\"end\"]\n",
    "\n",
    "        if current_chunk:\n",
    "            add_document_to_chunks(current_chunk, current_start_time, current_end_time, concatenated_chunks, len(segment[\"tokens\"]))\n",
    "\n",
    "    return concatenated_chunks\n",
    "\n",
    "\n",
    "# Example usage\n",
    "chunk_sizes = [128, 256, 512, 1024]\n",
    "docs = get_documents_from_transcription(json_file=\"transcriptions/youtube_5p248yoa3oE.json\", chunk_sizes=chunk_sizes)\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc78756b-2883-4b71-b15f-81e40d4b0997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a sample vectorDB\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# VectorDB\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents=docs, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "219d1a38-90ad-41b2-b495-b53225ac328d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x1562c7d00>, search_type='similarity', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "question = \"advice\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(), llm=llm\n",
    ")\n",
    "retriever_from_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7d4d83e8-b2d4-4025-9d7b-901c828e1359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\" AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world\", metadata={'chunk_size': 25, 'end': 1834.88, 'start': 1829.8}),\n",
       " Document(page_content=\" AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world\", metadata={'chunk_size': 25, 'end': 1834.88, 'start': 1829.8}),\n",
       " Document(page_content=\" AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world\", metadata={'chunk_size': 25, 'end': 1834.88, 'start': 1829.8}),\n",
       " Document(page_content=\" AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world\", metadata={'chunk_size': 25, 'end': 1834.88, 'start': 1829.8})]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.as_retriever().get_relevant_documents(query=\" Google brain team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "303c441d-5b30-404b-8c34-2382954fe576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"think we've always managed to help the companies build a strong technical team than partnering with subject matter experts often results in exciting new opportunities. And I want to share with you one other weird aspect of one of the weird lessons I've learned about, you know, building startups, which is I like to engage only when there's a concrete idea. And this runs counter to bother the advice you hear from the design thinking methodology, which often says don't rush to solutioning, right? Explore a lot of alternatives to avoid the solution. Honestly, we tried that. It was very slow. But what we've learned is that at the ideation stage, if someone comes to me and says, hey, Andrew, you should apply AI to financial services. Because I'm not a subject matter expert in financial services, it's very slow for me to learn enough about financial services that you can figure out what to do. I mean, eventually, you could get a good outcome, but it's a very labor intensive, very slow, very expensive process. So me to try to learn industry after industry. In contrast, one of my partners wrote his ideas that Tony Cheat, not really seriously, but you know, let's say the concrete idea is by GBT, let's eliminate commercials by automatically buying every product advertised in exchange for not having seen ads. It's not a good idea, but it is a concrete idea. And it turns out concrete ideas can be validated or falsified efficiently. They also give a team a clear direction to execute. And I've learned it in today's world, especially with the excitement and buzz and exposure to the AI of a lot of people, it turns out that there are a lot of subject matter experts in today's world that have deeply thought about a problem for months, sometimes even one or two years, but they've not yet had a build partner. And when we get together with them and hear and they share the idea of us, it allows us to work with them to very quickly go into validation and building. And I find that this works because there are a lot of people that have already done the design thinking thing of exploring a lot of ideas and winning down to really good ideas. And there are, I find that there's so many good ideas sitting out there that no one is working on that finding those good ideas that someone has already had and wants to share of us and wants to build partner for that turns out to be much more efficient engine. So, before I wrap up, we'll go to the question second. Just a few slides to talk about risks and social impact. So, AI is a very powerful technology to state something you probably guess. My team's and I, we only work on projects that move humanity forward. And we have multiple times, killed projects that we assess that we financially sound based on ethical grounds. It turns out I've been surprising. Sometimes this made\", metadata={'chunk_size': 512, 'end': 1905.18, 'start': 1735.96}),\n",
       " Document(page_content=\"are a lot of subject matter experts in today's world that have deeply thought about a problem for months, sometimes even one or two years, but they've not yet had a build partner. And when we get together with them and hear and they share the idea of us, it allows us to work with them to very quickly go into validation and building. And I find that this works because there are a lot of people that have already done the design thinking thing of exploring a lot of ideas and winning down to really good ideas. And there are, I find that there's so many good ideas sitting out there that no one is working on that finding those good ideas that someone has already had and wants to share of us and wants to build partner for that turns out to be much more efficient engine. So, before I wrap up, we'll go to the question second. Just a few slides to talk about risks and social impact. So, AI is a very powerful technology to state something you probably guess. My team's and I, we only work on projects that move humanity forward. And we have multiple times, killed projects that we assess that we financially sound based on ethical grounds. It turns out I've been surprising. Sometimes this made at the creativity of people to come up with good ideas, sorry to come up with really bad ideas that seem profitable, but really should not be built with a few projects\", metadata={'chunk_size': 256, 'end': 1916.48, 'start': 1832.54}),\n",
       " Document(page_content=\"one other weird aspect of one of the weird lessons I've learned about, you know, building startups, which is I like to engage only when there's a concrete idea. And this runs counter to bother the advice you hear from the design thinking methodology, which often says don't rush to solutioning, right? Explore a lot of alternatives to avoid the solution. Honestly, we tried that. It was very slow. But what we've learned is that at the ideation stage, if someone comes to me and says, hey, Andrew, you should apply AI to financial services. Because I'm not a subject matter expert in financial services, it's very slow for me to learn enough about financial services that you can figure out what to do. I mean, eventually, you could get a good outcome, but it's a very labor intensive, very slow, very expensive process. So me to try to learn industry after industry. In contrast, one of my partners wrote his ideas that Tony Cheat, not really seriously, but you know, let's say the concrete idea is by GBT, let's eliminate commercials by automatically buying every product advertised in exchange for not having seen ads. It's not a good idea, but it is a concrete idea. And it turns out concrete ideas can be validated or falsified efficiently. They also give a team a clear direction to execute. And I've learned it in today's world, especially with the excitement and buzz and exposure to the AI of a lot of people, it turns out that there\", metadata={'chunk_size': 256, 'end': 1832.54, 'start': 1746.52}),\n",
       " Document(page_content=\"of work that lies ahead of us is to find the very diverse use cases and to build them. There's a second trend I want to share with you, which relates to why AI is in more widely adopted yet. It feels like a bunch of us have been talking about AI for like 15 years or something. But if you look at where the value of AI is today, a lot of it is still very concentrated in consumer software internet. Once you go outside, you know, tech or consumer software internet, there's some air adoption but the law feels very early. So why is that? It turns out if you were to take all current and potential AI projects and sort them in decreasing order of value, then to the left of this curve, the head of this curve are the multi billion dollar projects like advertising or web search or for e -commerce, your product recommendations or company amazon. And it turns out that about 10, 15 years ago, you know, various of my friends and I, we figured out a recipe for how to hire say a hundred engineers to write one piece of software to serve more relevant ads and apply that one piece of software to bid end users and generate massive financial values. So that works. But once you go outside, consumer software internet, hardly anyone has a hundred million or a billion users that you can write and apply one piece of software to you. So once you go to other industries, as we go from the head of this curve on the left over to the long tail, these are some of the projects I see and I'm excited about. I was working with a piece of maker that was taking pictures of the pizza they were making because they needed to do things like make sure that the cheese is spread evenly. So this is about a five million dollar project. But that recipe of hiring a hundred engineers or dozens of engineers to work on a five million dollar project, that doesn't make sense. Or another very example, working with an agricultural company that, well, then we figured out that we used cameras to find out how tall is the wheat and wheat is often bento because of the wind or rain or something. And we can chop off the wheat at the right height. Then that results in more food for the farmer to sell and is also better for the environment. But this is another five million dollar project that that old recipe of having a large group of high school engineers to work on this one project that doesn't make sense. And similarly materials grading, cloth grading, sheet metal grading, many project like this. So whereas to the left in the head of this curve, there's a small number of, let's say, multi -billion dollar projects. And we know how to execute those, you know, still ring value. In other industries, I'm seeing a very long tail of tens of thousands of, let's call them five million dollar projects that until now have been very difficult to execute on because of the high cost of customization. The trend that I think is exciting is that the AI community has been building better tools that lets us aggregate these use cases and make it easy for the end user to do the customization. So specifically, I'm seeing a lot of exciting low code and no code tools that enable the user to customize the AI system. What does mean is this instead of me needing to worry that much about pictures of pizza, we have tools, we can start into C tools that can enable the IT department of the pizza making factory to train AI system on their own pictures of pizza to realize this five million dollars worth of value. And by the way, the pictures of pizza, you know, they don't exist on the internet. So Google and Bing don't have access to these pictures. We need tools that can be used by really the pizza factory themselves to build and deploy and maintain their own custom AI system that works on their own pictures of pizza. And broadly, the technology for enabling this, some of it is prompting, text prompting, visual prompting, but really large language models and similar tools like that. Or a technology called data centric AI whereby instead of asking the pizza factory to write a lot of code, you know, which is challenging, we can ask them to provide data which turns out to be more feasible. And I think the second trend is important because I think this is a key part of the recipe for taking the value of AI, which so far still feels very concentrated in the tech world and consume the software into that world and pushing this out to, you know, all industries really to the rest of the economy, which, you know, sometimes it's easy to forget. The rest of the economy is much bigger than the tech world. So, the two trends I shared, AI is a general purpose technology, lots of concrete use cases to be realized as well as local, no code, easy to use tools, enabling AI to be deployed in more industries. How do we go after these opportunities? So, about five years ago, there was a puzzle I wanted to solve, which is I felt that many valuable AI projects are now possible. I was thinking how do we get them done? And having led AI teams in, you know, Google and buy do in big tech companies, I had a hard time figuring out how I could operate a team in a big tech company to go off. There are a very diverse set of opportunities and everything from maritime shipping to education to financial services to healthcare and all and all. It's just very diverse use cases, very diverse, go to markets, very diverse, really, you know, customer bases and applications. And I felt that the most efficient\", metadata={'chunk_size': 1024, 'end': 1280.64, 'start': 945.94}),\n",
       " Document(page_content=\"the value of AI is today, a lot of it is still very concentrated in consumer software internet. Once you go outside, you know, tech or consumer software internet, there's some air adoption but the law feels very early. So why is that? It turns out if you were to take all current and potential AI projects and sort them in decreasing order of value, then to the left of this curve, the head of this curve are the multi billion dollar projects like advertising or web search or for e -commerce, your product recommendations or company amazon. And it turns out that about 10, 15 years ago, you know, various of my friends and I, we figured out a recipe for how to hire say a hundred engineers to write one piece of software to serve more relevant ads and apply that one piece of software to bid end users and generate massive financial values. So that works. But once you go outside, consumer software internet, hardly anyone has a hundred million or a billion users that you can write and apply one piece of software to you. So once you go to other industries, as we go from the head of this curve on the left over to the long tail, these are some of the projects I see and I'm excited about. I was working with a piece of maker that was taking pictures of the pizza they were making because they needed to do things like make sure that the cheese is\", metadata={'chunk_size': 256, 'end': 1046.62, 'start': 962.5}),\n",
       " Document(page_content='adoption but the law feels very early. So why is that? It turns out if you were to take all current and potential AI projects and sort them in decreasing order of value, then to the left of this curve, the head of this curve are the multi billion dollar projects like advertising or web search or for e -commerce, your product recommendations or company amazon. And it turns out that about 10, 15 years ago, you know, various of my friends and I, we figured out a recipe for how to hire say a hundred engineers to write one piece of software to serve more relevant ads and apply that one piece of software to bid end users and generate massive financial values. So that works. But', metadata={'chunk_size': 128, 'end': 1016.72, 'start': 972.84})]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_from_llm.get_relevant_documents(query=\"what are best IA projects or idea?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11efc3db-81f0-46af-8dd9-071ef1e5f3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizer",
   "language": "python",
   "name": "summarizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
